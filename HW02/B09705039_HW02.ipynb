{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1237d3d-5708-45fd-aec0-c0e1ae40d910",
   "metadata": {},
   "source": [
    "<h1>B09705039_劉惟恩_Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b5ce0-9e8b-4a57-8515-504abbc8b860",
   "metadata": {},
   "source": [
    "<h2>第一題 [Data Preprocessing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686d50e4-edaf-48bf-9411-2b09e00327ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce265f1a-febc-4b6a-b1dd-7c6f4a701aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column names to the same order as adult50kp\n",
    "adult50k = {}\n",
    "init_colnames = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"educational-num\", \n",
    "            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"salary\"]\n",
    "adult50k['num_col'] = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "adult50k['columnname'] = ['capital-loss', 'hours-per-week', 'capital-gain',\n",
    "       'educational-num', 'age', 'fnlwgt', 'relationship_Husband',\n",
    "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
    "       'relationship_Own-child', 'relationship_Unmarried',\n",
    "       'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
    "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
    "       'race_White', 'gender_Female', 'gender_Male',\n",
    "       'occupation_Adm-clerical', 'occupation_Craft-repair',\n",
    "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
    "       'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
    "       'occupation_Other-service', 'occupation_Priv-house-serv',\n",
    "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
    "       'occupation_Sales', 'occupation_Tech-support',\n",
    "       'occupation_Transport-moving', 'education_10th', 'education_11th',\n",
    "       'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
    "       'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
    "       'education_Assoc-voc', 'education_Bachelors',\n",
    "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
    "       'education_Preschool', 'education_Prof-school',\n",
    "       'education_Some-college', 'native-country_Cambodia',\n",
    "       'native-country_Canada', 'native-country_China',\n",
    "       'native-country_Columbia', 'native-country_Cuba',\n",
    "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
    "       'native-country_El-Salvador', 'native-country_England',\n",
    "       'native-country_France', 'native-country_Germany',\n",
    "       'native-country_Greece', 'native-country_Guatemala',\n",
    "       'native-country_Haiti', 'native-country_Honduras',\n",
    "       'native-country_Hong', 'native-country_Hungary',\n",
    "       'native-country_India', 'native-country_Iran',\n",
    "       'native-country_Ireland', 'native-country_Italy',\n",
    "       'native-country_Jamaica', 'native-country_Japan',\n",
    "       'native-country_Laos', 'native-country_Mexico',\n",
    "       'native-country_Nicaragua',\n",
    "       'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
    "       'native-country_Philippines', 'native-country_Poland',\n",
    "       'native-country_Portugal', 'native-country_Puerto-Rico',\n",
    "       'native-country_Scotland', 'native-country_South',\n",
    "       'native-country_Taiwan', 'native-country_Thailand',\n",
    "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
    "       'native-country_Vietnam', 'native-country_Yugoslavia',\n",
    "       'workclass_Federal-gov', 'workclass_Local-gov',\n",
    "       'workclass_Private', 'workclass_Self-emp-inc',\n",
    "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
    "       'workclass_Without-pay', 'marital-status_Divorced',\n",
    "       'marital-status_Married-AF-spouse',\n",
    "       'marital-status_Married-civ-spouse',\n",
    "       'marital-status_Married-spouse-absent',\n",
    "       'marital-status_Never-married', 'marital-status_Separated',\n",
    "       'marital-status_Widowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66947cb8-c3d5-4593-af3f-d455207d9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data \n",
    "    # read training data\n",
    "mock_train_data = pd.read_csv(\"./data/adult.data\", names=init_colnames, header=None)\n",
    "    # drop rows that have ? values\n",
    "mock_train_data = mock_train_data.replace(' ?', np.NaN)\n",
    "mock_train_data.dropna(inplace=True)\n",
    "    # one hot encoding\n",
    "mock_train_data = pd.get_dummies(mock_train_data)\n",
    "    # remove spaces from column names\n",
    "mock_train_data.columns = mock_train_data.columns.str.replace(' ', '')\n",
    "    # get y values\n",
    "adult50k['y_train'] = np.array(mock_train_data['salary_>50K'])\n",
    "mock_train_data = mock_train_data.drop(columns=['salary_<=50K', 'salary_>50K'])\n",
    "\n",
    "# Testing Data\n",
    "    # read testing data\n",
    "mock_test_data = pd.read_csv(\"./data/adult.test\", names=init_colnames, skiprows=1, header=None)\n",
    "    # drop rows that have ? values\n",
    "mock_test_data = mock_test_data.replace(' ?', np.NaN)\n",
    "mock_test_data.dropna(inplace=True)\n",
    "    # one hot encoding\n",
    "mock_test_data = pd.get_dummies(mock_test_data)\n",
    "    # remove spaces from column names\n",
    "mock_test_data.columns = mock_test_data.columns.str.replace(' ', '')\n",
    "    # get y values\n",
    "adult50k['y_test'] = np.array(mock_test_data['salary_>50K.'])\n",
    "mock_test_data = mock_test_data.drop(columns=['salary_<=50K.', 'salary_>50K.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab5c042-8113-4e0c-9e13-a114484a217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize data\n",
    "for i in adult50k['num_col']:\n",
    "    xscaler = preprocessing.StandardScaler().fit(np.array([mock_train_data[i]]).T)\n",
    "    mock_train_data[i] = xscaler.transform(np.array([mock_train_data[i]]).T).T.flatten()\n",
    "    mock_test_data[i] = xscaler.transform(np.array([mock_test_data[i]]).T).T.flatten()\n",
    "# Delete freq < 10 feature\n",
    "for i in mock_train_data.columns.values:\n",
    "    if i not in adult50k['num_col']:\n",
    "        if (mock_train_data[i].value_counts()[1]) <= 10:\n",
    "            mock_train_data.drop([i], axis=1, inplace = True)\n",
    "mock_test_data = mock_test_data[mock_train_data.columns.values]\n",
    "    \n",
    "# Training Data\n",
    "    # rearrange columns to the same order\n",
    "mock_train_data = mock_train_data[adult50k['columnname']]\n",
    "    # df to np array\n",
    "adult50k['x_train'] = mock_train_data.to_numpy()\n",
    "\n",
    "# Testing Data\n",
    "    # rearrange columns to the same order\n",
    "mock_test_data = mock_test_data[adult50k['columnname']]\n",
    "    # df to np array\n",
    "adult50k['x_test'] = mock_test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8db7466-f36f-4d7f-8164-9c9ba4f58dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>relationship_Husband</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>...</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <th>marital-status_Married-AF-spouse</th>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <th>marital-status_Married-spouse-absent</th>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <th>marital-status_Separated</th>\n",
       "      <th>marital-status_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.244682</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.870832</td>\n",
       "      <td>0.638972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>0.118931</td>\n",
       "      <td>-0.335252</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1.489374</td>\n",
       "      <td>-0.358575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-1.251511</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>1.881120</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1.032559</td>\n",
       "      <td>0.928841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       capital-loss  hours-per-week  capital-gain  educational-num       age  \\\n",
       "0         -0.218586       -0.077734      0.146092         1.128918  0.042796   \n",
       "1         -0.218586       -2.331531     -0.147445         1.128918  0.880288   \n",
       "2         -0.218586       -0.077734     -0.147445        -0.439738 -0.033340   \n",
       "3         -0.218586       -0.077734     -0.147445        -1.224066  1.108695   \n",
       "4         -0.218586       -0.077734     -0.147445         1.128918 -0.794697   \n",
       "...             ...             ...           ...              ...       ...   \n",
       "32556     -0.218586       -0.244682     -0.147445         0.736754 -0.870832   \n",
       "32557     -0.218586       -0.077734     -0.147445        -0.439738  0.118931   \n",
       "32558     -0.218586       -0.077734     -0.147445        -0.439738  1.489374   \n",
       "32559     -0.218586       -1.747213     -0.147445        -0.439738 -1.251511   \n",
       "32560     -0.218586       -0.077734      1.881120        -0.439738  1.032559   \n",
       "\n",
       "         fnlwgt  relationship_Husband  relationship_Not-in-family  \\\n",
       "0     -1.062722                     0                           1   \n",
       "1     -1.007871                     1                           0   \n",
       "2      0.244693                     0                           1   \n",
       "3      0.425240                     1                           0   \n",
       "4      1.406658                     0                           0   \n",
       "...         ...                   ...                         ...   \n",
       "32556  0.638972                     0                           0   \n",
       "32557 -0.335252                     1                           0   \n",
       "32558 -0.358575                     0                           0   \n",
       "32559  0.110705                     0                           0   \n",
       "32560  0.928841                     0                           0   \n",
       "\n",
       "       relationship_Other-relative  relationship_Own-child  ...  \\\n",
       "0                                0                       0  ...   \n",
       "1                                0                       0  ...   \n",
       "2                                0                       0  ...   \n",
       "3                                0                       0  ...   \n",
       "4                                0                       0  ...   \n",
       "...                            ...                     ...  ...   \n",
       "32556                            0                       0  ...   \n",
       "32557                            0                       0  ...   \n",
       "32558                            0                       0  ...   \n",
       "32559                            0                       1  ...   \n",
       "32560                            0                       0  ...   \n",
       "\n",
       "       workclass_Self-emp-not-inc  workclass_State-gov  workclass_Without-pay  \\\n",
       "0                               0                    1                      0   \n",
       "1                               1                    0                      0   \n",
       "2                               0                    0                      0   \n",
       "3                               0                    0                      0   \n",
       "4                               0                    0                      0   \n",
       "...                           ...                  ...                    ...   \n",
       "32556                           0                    0                      0   \n",
       "32557                           0                    0                      0   \n",
       "32558                           0                    0                      0   \n",
       "32559                           0                    0                      0   \n",
       "32560                           0                    0                      0   \n",
       "\n",
       "       marital-status_Divorced  marital-status_Married-AF-spouse  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            1                                 0   \n",
       "3                            0                                 0   \n",
       "4                            0                                 0   \n",
       "...                        ...                               ...   \n",
       "32556                        0                                 0   \n",
       "32557                        0                                 0   \n",
       "32558                        0                                 0   \n",
       "32559                        0                                 0   \n",
       "32560                        0                                 0   \n",
       "\n",
       "       marital-status_Married-civ-spouse  \\\n",
       "0                                      0   \n",
       "1                                      1   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "...                                  ...   \n",
       "32556                                  1   \n",
       "32557                                  1   \n",
       "32558                                  0   \n",
       "32559                                  0   \n",
       "32560                                  1   \n",
       "\n",
       "       marital-status_Married-spouse-absent  marital-status_Never-married  \\\n",
       "0                                         0                             1   \n",
       "1                                         0                             0   \n",
       "2                                         0                             0   \n",
       "3                                         0                             0   \n",
       "4                                         0                             0   \n",
       "...                                     ...                           ...   \n",
       "32556                                     0                             0   \n",
       "32557                                     0                             0   \n",
       "32558                                     0                             0   \n",
       "32559                                     0                             1   \n",
       "32560                                     0                             0   \n",
       "\n",
       "       marital-status_Separated  marital-status_Widowed  \n",
       "0                             0                       0  \n",
       "1                             0                       0  \n",
       "2                             0                       0  \n",
       "3                             0                       0  \n",
       "4                             0                       0  \n",
       "...                         ...                     ...  \n",
       "32556                         0                       0  \n",
       "32557                         0                       0  \n",
       "32558                         0                       1  \n",
       "32559                         0                       0  \n",
       "32560                         0                       0  \n",
       "\n",
       "[30162 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>relationship_Husband</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>...</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <th>marital-status_Married-AF-spouse</th>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <th>marital-status_Married-spouse-absent</th>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <th>marital-status_Separated</th>\n",
       "      <th>marital-status_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-1.023104</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.946320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.392858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.890601</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>0.423474</td>\n",
       "      <td>-0.278945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.912474</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-1.616231</td>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.084232</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.414018</td>\n",
       "      <td>0.524529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.411630</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.042796</td>\n",
       "      <td>0.242545</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>1.752835</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.423474</td>\n",
       "      <td>-1.002382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.261747</td>\n",
       "      <td>-0.072369</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       capital-loss  hours-per-week  capital-gain  educational-num       age  \\\n",
       "0         -0.218586       -0.077734     -0.147445        -1.224066 -1.023104   \n",
       "1         -0.218586        0.757005     -0.147445        -0.439738 -0.033340   \n",
       "2         -0.218586       -0.077734     -0.147445         0.736754 -0.794697   \n",
       "3         -0.218586       -0.077734      0.890601        -0.047574  0.423474   \n",
       "5         -0.218586       -0.912474     -0.147445        -1.616231 -0.337883   \n",
       "...             ...             ...           ...              ...       ...   \n",
       "16275     -0.218586       -0.077734     -0.147445         1.128918 -0.414018   \n",
       "16276     -0.218586       -0.411630     -0.147445         1.128918  0.042796   \n",
       "16278     -0.218586        0.757005     -0.147445         1.128918 -0.033340   \n",
       "16279     -0.218586       -0.077734      0.589098         1.128918  0.423474   \n",
       "16280     -0.218586        1.591745     -0.147445         1.128918 -0.261747   \n",
       "\n",
       "         fnlwgt  relationship_Husband  relationship_Not-in-family  \\\n",
       "0      0.350286                     0                           0   \n",
       "1     -0.946320                     1                           0   \n",
       "2      1.392858                     1                           0   \n",
       "3     -0.278945                     1                           0   \n",
       "5      0.084232                     0                           1   \n",
       "...         ...                   ...                         ...   \n",
       "16275  0.524529                     0                           0   \n",
       "16276  0.242545                     0                           1   \n",
       "16278  1.752835                     1                           0   \n",
       "16279 -1.002382                     0                           0   \n",
       "16280 -0.072369                     1                           0   \n",
       "\n",
       "       relationship_Other-relative  relationship_Own-child  ...  \\\n",
       "0                                0                       1  ...   \n",
       "1                                0                       0  ...   \n",
       "2                                0                       0  ...   \n",
       "3                                0                       0  ...   \n",
       "5                                0                       0  ...   \n",
       "...                            ...                     ...  ...   \n",
       "16275                            0                       1  ...   \n",
       "16276                            0                       0  ...   \n",
       "16278                            0                       0  ...   \n",
       "16279                            0                       1  ...   \n",
       "16280                            0                       0  ...   \n",
       "\n",
       "       workclass_Self-emp-not-inc  workclass_State-gov  workclass_Without-pay  \\\n",
       "0                               0                    0                      0   \n",
       "1                               0                    0                      0   \n",
       "2                               0                    0                      0   \n",
       "3                               0                    0                      0   \n",
       "5                               0                    0                      0   \n",
       "...                           ...                  ...                    ...   \n",
       "16275                           0                    0                      0   \n",
       "16276                           0                    0                      0   \n",
       "16278                           0                    0                      0   \n",
       "16279                           0                    0                      0   \n",
       "16280                           0                    0                      0   \n",
       "\n",
       "       marital-status_Divorced  marital-status_Married-AF-spouse  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            0                                 0   \n",
       "3                            0                                 0   \n",
       "5                            0                                 0   \n",
       "...                        ...                               ...   \n",
       "16275                        0                                 0   \n",
       "16276                        1                                 0   \n",
       "16278                        0                                 0   \n",
       "16279                        1                                 0   \n",
       "16280                        0                                 0   \n",
       "\n",
       "       marital-status_Married-civ-spouse  \\\n",
       "0                                      0   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "5                                      0   \n",
       "...                                  ...   \n",
       "16275                                  0   \n",
       "16276                                  0   \n",
       "16278                                  1   \n",
       "16279                                  0   \n",
       "16280                                  1   \n",
       "\n",
       "       marital-status_Married-spouse-absent  marital-status_Never-married  \\\n",
       "0                                         0                             1   \n",
       "1                                         0                             0   \n",
       "2                                         0                             0   \n",
       "3                                         0                             0   \n",
       "5                                         0                             1   \n",
       "...                                     ...                           ...   \n",
       "16275                                     0                             1   \n",
       "16276                                     0                             0   \n",
       "16278                                     0                             0   \n",
       "16279                                     0                             0   \n",
       "16280                                     0                             0   \n",
       "\n",
       "       marital-status_Separated  marital-status_Widowed  \n",
       "0                             0                       0  \n",
       "1                             0                       0  \n",
       "2                             0                       0  \n",
       "3                             0                       0  \n",
       "5                             0                       0  \n",
       "...                         ...                     ...  \n",
       "16275                         0                       0  \n",
       "16276                         0                       0  \n",
       "16278                         0                       0  \n",
       "16279                         0                       0  \n",
       "16280                         0                       0  \n",
       "\n",
       "[15060 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print final df of training and testing data\n",
    "display(mock_train_data)\n",
    "display(mock_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74f7d2-6258-4ace-8e49-71c06f8889c1",
   "metadata": {},
   "source": [
    "### Check if adult50k is exactly the same as adult50kp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5a9865-5246-45e0-98e9-61b37bd6659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e64943b-5105-4a73-b677-a78a1a7ac375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598d6a5-83bb-4ac3-85b1-221602eb8e9f",
   "metadata": {},
   "source": [
    "<h2>第二題 [ROC and AUC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74b5bed-6d72-47ec-941b-8bd598bd4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "# train prediction model\n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "# make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b705350-1258-46a2-a014-586f1e8321bb",
   "metadata": {},
   "source": [
    "<h3>Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91548f6e-69e3-45b5-a460-5cfc10fed6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# changing data into dataframe as the table in class\n",
    "data = {\"predict\": ypredprob[:,1],\n",
    "       \"actual\": adult50kp['y_test']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# sort prob in ascending order\n",
    "df = df.sort_values('predict', ascending=False)\n",
    "\n",
    "# calculate the amount of P and N\n",
    "P = df[df['actual']==1].shape[0]\n",
    "N = df[df['actual']==0].shape[0]\n",
    "\n",
    "# if actual is 1 add one to TP else actual is 0 add one to FP count rate\n",
    "X = []\n",
    "y = []\n",
    "current_X=0\n",
    "current_y=0\n",
    "y_count = 0\n",
    "x_count = 0\n",
    "for row in df.itertuples():\n",
    "    if row[2] == 1:\n",
    "        y_count += 1\n",
    "        current_y = y_count / P\n",
    "    else:\n",
    "        x_count += 1\n",
    "        current_X = x_count / N\n",
    "    X.append(current_X)\n",
    "    y.append(current_y)\n",
    "\n",
    "# plot curve \n",
    "plt.title('ROC Curve')\n",
    "# draw ROC curve\n",
    "plt.plot(X, y, color = 'red')\n",
    "# draw diagonal line\n",
    "plt.plot([0, 1], [0, 1],'g--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef71869-d702-45e1-951f-4f5107b629cc",
   "metadata": {},
   "source": [
    "<h3>Q2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "518e1a79-5fb3-4a17-94f2-71b85f4059e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.903490602398108\n"
     ]
    }
   ],
   "source": [
    "auc = 0\n",
    "for i in range(len(X) - 1):\n",
    "    auc += (1 / 2) * (y[i] + y[i + 1]) * (X[i + 1] - X[i])\n",
    "print(\"AUC =\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedb1b0-ed79-4e7d-823c-c009d8928ac6",
   "metadata": {},
   "source": [
    "<h2>第三題 [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54361d7f-c8e9-4994-9048-110975dd7b96",
   "metadata": {},
   "source": [
    "<h3>Q3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc485f4-0e54-4c3c-9a4e-b40c269ac244",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### gradient for the new E(w)\n",
    "$G = \\nabla E(w) = x_{train}^T(y - y_{train})^T + \\Lambda w,$\n",
    "\n",
    "where $y = \\frac{1}{1 + exp({-w^T x_{train}^T})}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa1715-cb34-4eb2-bbb0-176af8355a79",
   "metadata": {},
   "source": [
    "#### hessian matrix for the new E(w)\n",
    "$H = \\nabla \\nabla E(w) = x_{train}^T R x_{train} + \\Lambda I,$\n",
    "\n",
    "where $R =$ diagonal matrix with diagonal elements in $ y(1 - y),$\n",
    "\n",
    "where $y = \\frac{1}{1 + exp({-w^T x_{train}^T})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f51b7-2790-4014-84bb-b9a0ffb29ba8",
   "metadata": {},
   "source": [
    "<h3>Q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738e14e9-ad44-4a6d-8efb-809fcb950e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244b338b-62dd-47b4-b609-6e3255b9dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        self.reg_vec = np.diag(reg_vec)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "\n",
    "    def fit(self, x, y, verbal = False):\n",
    "        # Array preprocessing\n",
    "        if self.add_intercept == True:\n",
    "            x_train = np.concatenate([x, np.ones((x.shape[0], 1))], axis=1)\n",
    "        else:\n",
    "            x_train = np.array(x)\n",
    "        \n",
    "        # Ridge regression\n",
    "        reg_avg = np.trace(self.reg_vec) / self.reg_vec.shape[1]\n",
    "        self.w = np.dot(np.linalg.inv((reg_avg * np.eye(x_train.shape[1])) + np.dot(x_train.T, x_train)), np.dot(x_train.T, y[np.newaxis].T))\n",
    "            # calculate loss\n",
    "        y_arr = 1 / (1 + np.exp(np.dot(-self.w.T, x_train.T)))\n",
    "        self.L = (1/2) * (np.dot(np.dot(self.w.T, self.reg_vec), self.w)) - (np.dot(y, (np.log(y_arr)).T) + np.dot((1 - y), (np.log(1 - y_arr)).T))\n",
    "        \n",
    "        # Logistic Regression with L2 Regularization\n",
    "        for itr in range(self.max_iter):\n",
    "                # Newton-Raphson Method\n",
    "                    # Calculate Gradient\n",
    "            G = np.dot(x_train.T, (y_arr - y).T) + np.dot(self.reg_vec, self.w)\n",
    "                    # Calculate Hessian matrix\n",
    "            H = np.dot(np.dot(x_train.T, np.diag((y_arr * (1 - y_arr)).flatten())), x_train) + self.reg_vec\n",
    "                    # Calculate new W\n",
    "            tempW = self.w - np.dot(np.linalg.inv(H), G)\n",
    "                    \n",
    "                # calculate loss\n",
    "            temp_y_arr = 1 / (1 + np.exp(np.dot(-tempW.T, x_train.T)))\n",
    "            tempL = (1/2) * (np.dot(np.dot(tempW.T, self.reg_vec), tempW)) - (np.dot(y, (np.log(temp_y_arr)).T) + np.dot((1 - y), (np.log(1 - temp_y_arr)).T))\n",
    "            \n",
    "                # loss constraint\n",
    "            if abs(self.L - tempL) < self.tol:\n",
    "                if self.L > tempL:\n",
    "                    y_arr = temp_y_arr\n",
    "                    self.w = tempW\n",
    "                    self.L = tempL\n",
    "                break\n",
    "                \n",
    "                # save temp to result\n",
    "            y_arr = temp_y_arr\n",
    "            self.w = tempW\n",
    "            self.L = tempL\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        # add ones to the testing x\n",
    "        if self.add_intercept == True:\n",
    "            firstCol = np.ones((x.shape[0], 1))\n",
    "            ones_x_test = np.concatenate([x, firstCol], axis=1)\n",
    "        self.predict = np.dot(self.w.T, ones_x_test.T).flatten()\n",
    "        for i in range(len(self.predict)):\n",
    "            if self.predict[i] < 0.5:\n",
    "                self.predict[i] = 0\n",
    "            else:\n",
    "                self.predict[i] = 1\n",
    "        return self.predict, self.L.flatten(), self.w.T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e815d77-bdaf-4158-b7f8-834a5c9a5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "\n",
    "X_train = adult50kp[\"x_train\"]\n",
    "X_test = adult50kp[\"x_test\"]\n",
    "Y_train = adult50kp[\"y_train\"]\n",
    "Y_test = adult50kp[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a2290-b2b2-4b9a-8c7d-58af9c635c53",
   "metadata": {},
   "source": [
    "### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999dd80d-115e-45ce-87fd-47305e5a3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lambda\n",
    "lambda_vec = np.ones(X_train.shape[1] + 1)\n",
    "\n",
    "# Execute model\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(X_train, Y_train)\n",
    "ypred = logic1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb01fa4c-80d5-4d78-bf98-654cdb90d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      "[ 0.25831075  0.35295138  2.33390152  0.75114521  0.33352443  0.07923687\n",
      " -0.25930599 -0.03310592 -0.80209231 -1.16328375 -0.15748027  1.06974336\n",
      " -0.63384606  0.11673241 -0.23156738 -0.51712221 -0.07972165 -1.0994978\n",
      " -0.24602709  0.06196949  0.12668588  0.86265606 -0.91835284 -0.62122618\n",
      " -0.20074022 -0.75160098 -1.61011588  0.57582091  0.64899528  0.35374143\n",
      "  0.71721847 -0.02844947 -0.00095482 -0.1965409  -0.14635164  0.62694627\n",
      "  0.44820708  0.02459458  0.04692237 -0.49106775 -0.20303542 -0.16330368\n",
      " -0.01766235 -0.11132832 -0.09946182 -1.17391916  0.18070268 -0.069272\n",
      "  0.9764969   0.4609886  -0.49544042 -1.27203531  0.48677241 -0.89896373\n",
      " -0.06005426 -0.35084885  0.43281522  0.59412015  0.58215192 -0.62096228\n",
      " -0.05974804  0.09290352 -0.1518921  -0.00538529  0.03416091 -0.28908824\n",
      "  0.15605391  0.49540124  0.89094226  0.14915144  0.34248478 -0.31331216\n",
      " -0.35593911 -0.36249461 -0.66724748 -0.40883113  0.44748983  0.13776893\n",
      "  0.14135123 -0.11601542 -0.05610327 -0.93458304 -0.02925965 -0.29901296\n",
      " -0.15051125  0.35233187 -0.78584654  0.58020021  0.49704231 -0.19032074\n",
      " -0.00034772  0.1749938  -0.48820269 -0.31225962 -1.02643023 -0.72231083\n",
      "  1.44672469  1.15520745 -0.6802029  -1.2119563  -0.79833851 -0.53464848\n",
      " -1.34552489]\n",
      "Accuracy = 0.841434\n"
     ]
    }
   ],
   "source": [
    "# print w\n",
    "print(\"w:\")\n",
    "print(ypred[2])\n",
    "\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred[0])\n",
    "accuracy = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d575c2c-9720-4435-b58a-46ef03888847",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336c7645-6d0c-4d08-bc6a-fb58f9d7f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lambda\n",
    "lambda_vec = np.ones(X_train.shape[1])\n",
    "lambda_vec = np.concatenate([lambda_vec, np.array([0])])\n",
    "\n",
    "# Execute model\n",
    "logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(X_train, Y_train)\n",
    "ypred = logic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc0e0b9-ae98-4ed2-9848-dca2f9e904c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      "[ 0.25833063  0.35307341  2.33348255  0.7378757   0.33385106  0.07926886\n",
      " -0.04219572  0.1998764  -0.58360968 -0.93671312  0.07548468  1.28715744\n",
      " -0.37140327  0.39422898  0.04305748 -0.26147348  0.19559029 -0.42695771\n",
      "  0.42695771  0.16424528  0.22840772  0.96472553 -0.81743779 -0.52074423\n",
      " -0.09910239 -0.64944042 -1.55235098  0.6786798   0.75066429  0.45541098\n",
      "  0.81857112  0.07308911  0.0728464  -0.11752644 -0.06282948  0.67242506\n",
      "  0.5040869   0.08799091  0.11435013 -0.38483984 -0.10196309 -0.05145374\n",
      "  0.10741777 -0.01997934  0.01717544 -1.16567808  0.30082277  0.02715464\n",
      "  1.00831207  0.50210397 -0.45756662 -1.24002555  0.52780939 -0.86832688\n",
      " -0.02771494 -0.31412701  0.47343435  0.62981111  0.62405658 -0.5867506\n",
      " -0.0296708   0.12414401 -0.14376238  0.02434194  0.0621604  -0.24843986\n",
      "  0.19459429  0.52620501  0.93165615  0.18707696  0.37950109 -0.28749402\n",
      " -0.31137357 -0.33290534 -0.65117786 -0.38160106  0.48879121  0.17662205\n",
      "  0.17410342 -0.07343502 -0.0314651  -0.89846776  0.00653561 -0.27232555\n",
      " -0.12442075  0.39697177 -0.75318727  0.61067658  0.70544004  0.01789988\n",
      "  0.2090388   0.382747   -0.2795817  -0.10453082 -0.9310132  -0.52642474\n",
      "  1.61398954  1.36735898 -0.49235221 -1.01493649 -0.60567591 -0.34195917\n",
      " -3.17508577]\n",
      "Accuracy = 0.841169\n"
     ]
    }
   ],
   "source": [
    "# print w\n",
    "print(\"w:\")\n",
    "print(ypred[2])\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred[0])\n",
    "accuracy = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac45d8-a307-4846-aa91-e561426eb04f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb52ea9b-9d35-4172-a950-24963aeecc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lambda\n",
    "lambda_vec = []\n",
    "for i in adult50kp['columnname']:\n",
    "    if i in adult50kp['num_col']:\n",
    "        lambda_vec.append(1)\n",
    "    else:\n",
    "        lambda_vec.append(0.5)\n",
    "lambda_vec.append(0)\n",
    "lambda_vec = np.array(lambda_vec)\n",
    "\n",
    "# Execute model\n",
    "logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(X_train, Y_train)\n",
    "ypred = logic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f0d045a-fe22-467c-9452-328833859ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      "[ 0.25851661  0.3533387   2.33562764  0.7825921   0.33439916  0.07940036\n",
      " -0.08347988  0.23309134 -0.59278098 -0.9224849   0.11139573  1.25425869\n",
      " -0.38299462  0.41291781  0.04136013 -0.26411462  0.19283128 -0.42890321\n",
      "  0.42890321  0.23635122  0.30021361  1.03810521 -0.75216086 -0.4534137\n",
      " -0.02691157 -0.5825269  -2.00075382  0.75127891  0.82696617  0.52830705\n",
      "  0.89488994  0.14510375  0.18253094 -0.02583999  0.00991404  0.89862004\n",
      "  0.68517002  0.23294385  0.24519931 -0.38363083 -0.08029608 -0.06493444\n",
      "  0.0453608   0.03743376 -0.01295908 -2.09374319  0.25763304  0.06659781\n",
      "  1.18748312  0.55059265 -0.47576613 -1.45842154  0.5822242  -1.0627833\n",
      " -0.00957211 -0.31704572  0.52485137  0.73044517  0.67457228 -0.63624179\n",
      " -0.00967268  0.17339113 -0.2364757   0.0375474   0.10120874 -0.24679341\n",
      "  0.23800627  0.64228457  1.00567032  0.23258941  0.42267607 -0.35336167\n",
      " -0.29178766 -0.38125401 -0.96291964 -0.45007954  0.512985    0.22019382\n",
      "  0.22640627 -0.04989103 -0.01836864 -0.95953334  0.01656804 -0.32741555\n",
      " -0.14011404  0.42856024 -0.84476926  0.75121645  0.76670733  0.07638783\n",
      "  0.26824615  0.44314098 -0.2205815  -0.04631789 -1.28758289 -0.57187068\n",
      "  1.82502287  1.39622511 -0.54691696 -1.05894077 -0.65551468 -0.38800489\n",
      " -3.36269033]\n",
      "Accuracy = 0.841368\n"
     ]
    }
   ],
   "source": [
    "# print w\n",
    "print(\"w:\")\n",
    "print(ypred[2])\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred[0])\n",
    "accuracy = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54b4e3-dfd8-4a23-a51d-69433058fccb",
   "metadata": {},
   "source": [
    "<h3>Q3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f43e4c-5573-4cc2-8caa-1fdebb60d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split training data\n",
    "subtraining_data_x, tuning_data_x, subtraining_data_y, tuning_data_y = train_test_split(adult50kp[\"x_train\"], adult50kp[\"y_train\"], test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fa31dbe-c929-4e10-9bfc-d8be65b51538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1 = a_2 find best a\n",
    "    # set grids\n",
    "grids = [0.01, 0.05, 0.1, 0.3, 0.5, 1, 5, 10, 25, 50, 75, 100]\n",
    "highest_acc = 0\n",
    "best_a_grid = 0\n",
    "for a in grids:\n",
    "    # Set lambda\n",
    "    lambda_vec = []\n",
    "    for i in adult50kp['columnname']:\n",
    "        lambda_vec.append(a)\n",
    "    lambda_vec.append(0)\n",
    "    lambda_vec = np.array(lambda_vec)\n",
    "\n",
    "    # Execute model\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(subtraining_data_x, subtraining_data_y)\n",
    "    ypred = logic.predict(tuning_data_x)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    ncorrect = np.sum(tuning_data_y == ypred[0])\n",
    "    accuracy = ncorrect / tuning_data_y.shape[0]\n",
    "    \n",
    "    # Save best accuracy grid\n",
    "    if accuracy > highest_acc:\n",
    "        highest_acc = accuracy\n",
    "        best_a_grid = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776a08f8-e4ae-403e-bc95-9c9ebe24e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a_1 find best a_2\n",
    "# set grids\n",
    "highest_acc = 0\n",
    "best_a_2_grid = 0\n",
    "for a_2 in grids:\n",
    "    # Set lambda\n",
    "    lambda_vec = []\n",
    "    for i in adult50kp['columnname']:\n",
    "        if i in adult50kp['num_col']:\n",
    "            lambda_vec.append(best_a_grid)\n",
    "        else:\n",
    "            lambda_vec.append(a_2)\n",
    "    lambda_vec.append(0)\n",
    "    lambda_vec = np.array(lambda_vec)\n",
    "\n",
    "    # Execute model\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(subtraining_data_x, subtraining_data_y)\n",
    "    ypred = logic.predict(tuning_data_x)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    ncorrect = np.sum(tuning_data_y == ypred[0])\n",
    "    accuracy = ncorrect / tuning_data_y.shape[0]\n",
    "    \n",
    "    # Save best accuracy grid\n",
    "    if accuracy > highest_acc:\n",
    "        highest_acc = accuracy\n",
    "        best_a_2_grid = a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa29184f-ecf3-4d1f-8ecb-7fb8759fb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a_2 find best a_1\n",
    "# set grids\n",
    "highest_acc = 0\n",
    "best_a_1_grid = 0\n",
    "for a_1 in grids:\n",
    "    # Set lambda\n",
    "    lambda_vec = []\n",
    "    for i in adult50kp['columnname']:\n",
    "        if i in adult50kp['num_col']:\n",
    "            lambda_vec.append(a_1)\n",
    "        else:\n",
    "            lambda_vec.append(best_a_2_grid)\n",
    "    lambda_vec.append(0)\n",
    "    lambda_vec = np.array(lambda_vec)\n",
    "\n",
    "    # Execute model\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(subtraining_data_x, subtraining_data_y)\n",
    "    ypred = logic.predict(tuning_data_x)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    ncorrect = np.sum(tuning_data_y == ypred[0])\n",
    "    accuracy = ncorrect / tuning_data_y.shape[0]\n",
    "    \n",
    "    # Save best accuracy grid\n",
    "    if accuracy > highest_acc:\n",
    "        highest_acc = accuracy\n",
    "        best_a_1_grid = a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37656098-1a7a-4914-8db7-88ee6a17e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected a1 = 0.3\n",
      "selected a2 = 0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"selected a1 =\", best_a_1_grid)\n",
    "print(\"selected a2 =\", best_a_2_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd589d7-5fe5-41c1-91de-74a97df5b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.841434\n"
     ]
    }
   ],
   "source": [
    "# Set lambda\n",
    "lambda_vec = []\n",
    "for i in adult50kp['columnname']:\n",
    "    if i in adult50kp['num_col']:\n",
    "        lambda_vec.append(0.5)\n",
    "        # lambda_vec.append(best_a_1_grid)\n",
    "    else:\n",
    "        lambda_vec.append(0.5)\n",
    "        # lambda_vec.append(best_a_2_grid)\n",
    "lambda_vec.append(0)\n",
    "lambda_vec = np.array(lambda_vec)\n",
    "\n",
    "# Execute model\n",
    "logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(X_train, Y_train)\n",
    "ypred = logic.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred[0])\n",
    "accuracy = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e27a32-436a-4e0b-86bb-60e67fcbf35f",
   "metadata": {},
   "source": [
    "<h3>Q3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5af6a468-c2ab-4bb3-838c-f2d89683e6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3}\n",
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# hyperparameter tuning\n",
    "# Grid search and Logistic Regression with one hyperparameter\n",
    "grid = {\"C\": grids}\n",
    "logreg = LogisticRegression(penalty = \"l2\", solver = 'newton-cg', max_iter = 1000)\n",
    "logreg_cv = GridSearchCV(logreg, grid)\n",
    "logreg_cv.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "# make prediction\n",
    "ypred = logreg_cv.predict(adult50kp['x_test'])\n",
    "ypredprob = logreg_cv.predict_proba(adult50kp['x_test'])\n",
    "\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c1bf0-0352-4c99-b460-9dda3260b5d3",
   "metadata": {},
   "source": [
    "The hyperparameters chosen is the same as mylogistic_l2 model, they all suggest a1 and a2 to be 0.3, the accuracy is similar too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6421cbc-e25e-4785-8068-c9683880e5af",
   "metadata": {},
   "source": [
    "Reference:<br>\n",
    "Q2.1 https://ithelp.ithome.com.tw/articles/10229049<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
