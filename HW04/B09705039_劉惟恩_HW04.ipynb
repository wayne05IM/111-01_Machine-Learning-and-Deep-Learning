{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7fb0eb-db97-412e-acfc-13ed02fb6f23",
   "metadata": {},
   "source": [
    "# B09705039_劉惟恩_HW04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f95bb94-9ba4-4cc8-9792-28e7d7129622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "X_subtrain shape =  (417344, 90)\n",
      "X_valid shape =  (46371, 90)\n",
      "Y_subtrain shape =  (417344,)\n",
      "Y_valid shape =  (46371,)\n",
      "X_test shape =  (51630, 90)\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load data\n",
    "with open('msd_full.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    # standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "\n",
    "# validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"X_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"X_valid shape = \", X_valid.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)\n",
    "print(\"X_test shape = \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54dc81-3f0b-4117-9281-6f96c2ed91d1",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fbc9f8-ad99-4ef2-8392-a9dde5a31917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# OLS\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "# RMSE \n",
    "RMSE = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "# first 5 features\n",
    "first_5 = reg.coef_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26f56da-1bfc-4420-b1c6-5f86f07294b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.510160684544397\n",
      "First 5 features: [ 5.30975265 -2.88088114 -1.53234348  0.05737583 -0.33952889]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", RMSE)\n",
    "print(\"First 5 features:\", first_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7d70b-ae34-4083-9f22-4b885e3e1bd4",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2febfe83-86c3-4de1-8a8b-e284798a9b97",
   "metadata": {
    "id": "xybQNYCXYu13"
   },
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4ca61-7b46-413e-bfd3-2e05935e9f5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define Our Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdd204d-3b6d-425a-b2b5-97f08d3f50b5",
   "metadata": {
    "id": "-mjaJM0wprMs"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f42690-1b6b-43cf-bd16-eb80a0789271",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create our MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97ff3ec-b801-4147-8f46-8cfb7ffedc4f",
   "metadata": {
    "id": "Qn97_WvvrEkG"
   },
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        H = config['H']\n",
    "        D_in = input_dim\n",
    "        D_out = 1\n",
    "        self.layers = nn.Sequential(\n",
    "            # Layer 1\n",
    "            torch.nn.Linear(D_in, H),  \n",
    "            torch.nn.ReLU(),\n",
    "            # Layer 2\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            # Layer 3\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            # Layer 4\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            # Output Layer\n",
    "            torch.nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e33561-3153-4f36-9bb1-1f8146516fb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1911f5c-87e7-491e-b504-9341534ee6c7",
   "metadata": {
    "id": "k4Rq8_TztAhq"
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "    # Define your optimization algorithm. \n",
    "    if config['optimizer'] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            model.train() # Set your model to train mode.\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
    "            pred = model(x)             \n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            # loss_record.append(loss.detach().item())\n",
    "            if step % 100 == 0:\n",
    "                mean_train_loss = loss.detach().item()\n",
    "                step_arr.append(step)\n",
    "                train_loss.append(mean_train_loss)\n",
    "\n",
    "                model.eval() # Set your model to evaluation mode.\n",
    "                loss_record = []\n",
    "                for x, y in valid_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        pred = model(x)\n",
    "                        loss = criterion(pred, y)\n",
    "\n",
    "                    loss_record.append(loss.item())\n",
    "\n",
    "                mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "                valid_loss.append(mean_valid_loss)\n",
    "\n",
    "                print(f'Epoch [{epoch+1}/{n_epochs}], Step[{step}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "\n",
    "                if mean_valid_loss < best_loss:\n",
    "                    best_loss = mean_valid_loss\n",
    "                    best_step_count = step\n",
    "                    torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "                    print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1 * 100\n",
    "                \n",
    "                if early_stop_count >= config['early_stop']:\n",
    "                    print('\\nModel is not improving, so we halt the training session.')\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34d5434-ebe8-42c7-83c5-ca4e0a436267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    for x in test_loader:\n",
    "        x = x.to(device)                        \n",
    "        with torch.no_grad():                   \n",
    "            pred = model(x)                     \n",
    "            preds.append(pred.detach().cpu())   \n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf18507-d591-4bec-b6c8-bb80aeabb0b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868eda8e-dd41-4731-afd3-bd5c137735aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jc7ZfDot2t9",
    "outputId": "62d291db-61c8-424d-ec87-2cfce6dd330d"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = Dataset(X_subtrain, Y_subtrain), \\\n",
    "                                            Dataset(X_valid, Y_valid), \\\n",
    "                                            Dataset(X_test)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1000, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddf41f-67fc-4191-80ed-18a1b911e69b",
   "metadata": {},
   "source": [
    "Main training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cb2854-87c0-4368-82e9-ce2b150d8afa",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 108.8962, Valid loss: 119.3198\n",
      "Saving model with loss 119.320...\n",
      "Epoch [1/100], Step[200]: Train loss: 120.9847, Valid loss: 119.5186\n",
      "Epoch [1/100], Step[300]: Train loss: 118.4456, Valid loss: 119.4957\n",
      "Epoch [1/100], Step[400]: Train loss: 122.6091, Valid loss: 119.1775\n",
      "Saving model with loss 119.177...\n",
      "Epoch [2/100], Step[500]: Train loss: 128.5199, Valid loss: 119.3914\n",
      "Epoch [2/100], Step[600]: Train loss: 110.4010, Valid loss: 119.5541\n",
      "Epoch [2/100], Step[700]: Train loss: 120.7958, Valid loss: 119.2641\n",
      "Epoch [2/100], Step[800]: Train loss: 116.4359, Valid loss: 118.9398\n",
      "Saving model with loss 118.940...\n",
      "Epoch [3/100], Step[900]: Train loss: 116.2152, Valid loss: 119.6781\n",
      "Epoch [3/100], Step[1000]: Train loss: 137.5541, Valid loss: 119.1695\n",
      "Epoch [3/100], Step[1100]: Train loss: 136.2171, Valid loss: 119.1535\n",
      "Epoch [3/100], Step[1200]: Train loss: 130.1479, Valid loss: 119.2751\n",
      "Epoch [4/100], Step[1300]: Train loss: 116.1454, Valid loss: 119.3536\n",
      "Epoch [4/100], Step[1400]: Train loss: 122.4220, Valid loss: 119.5643\n",
      "Epoch [4/100], Step[1500]: Train loss: 128.2549, Valid loss: 119.4172\n",
      "Epoch [4/100], Step[1600]: Train loss: 107.1356, Valid loss: 119.1999\n",
      "Epoch [5/100], Step[1700]: Train loss: 106.3580, Valid loss: 119.5193\n",
      "Epoch [5/100], Step[1800]: Train loss: 120.1167, Valid loss: 119.1341\n",
      "Epoch [5/100], Step[1900]: Train loss: 104.8897, Valid loss: 119.4574\n",
      "Epoch [5/100], Step[2000]: Train loss: 137.1625, Valid loss: 119.0992\n",
      "Epoch [6/100], Step[2100]: Train loss: 123.6580, Valid loss: 119.3417\n",
      "Epoch [6/100], Step[2200]: Train loss: 103.5117, Valid loss: 119.7041\n",
      "Epoch [6/100], Step[2300]: Train loss: 110.8736, Valid loss: 119.5015\n",
      "Epoch [6/100], Step[2400]: Train loss: 133.6796, Valid loss: 119.3784\n",
      "Epoch [6/100], Step[2500]: Train loss: 122.0219, Valid loss: 119.0549\n",
      "Epoch [7/100], Step[2600]: Train loss: 121.8033, Valid loss: 119.3414\n",
      "Epoch [7/100], Step[2700]: Train loss: 106.0984, Valid loss: 119.0954\n",
      "Epoch [7/100], Step[2800]: Train loss: 103.2650, Valid loss: 119.1902\n",
      "Epoch [7/100], Step[2900]: Train loss: 138.6434, Valid loss: 119.6026\n",
      "Epoch [8/100], Step[3000]: Train loss: 119.4228, Valid loss: 119.2422\n",
      "Epoch [8/100], Step[3100]: Train loss: 122.4138, Valid loss: 119.3621\n",
      "Epoch [8/100], Step[3200]: Train loss: 130.6490, Valid loss: 119.5374\n",
      "Epoch [8/100], Step[3300]: Train loss: 117.1639, Valid loss: 119.3686\n",
      "Epoch [9/100], Step[3400]: Train loss: 123.5484, Valid loss: 119.4661\n",
      "Epoch [9/100], Step[3500]: Train loss: 115.9463, Valid loss: 119.4174\n",
      "Epoch [9/100], Step[3600]: Train loss: 127.1359, Valid loss: 119.1768\n",
      "Epoch [9/100], Step[3700]: Train loss: 111.7258, Valid loss: 119.5852\n",
      "Epoch [10/100], Step[3800]: Train loss: 124.9199, Valid loss: 119.1921\n",
      "Epoch [10/100], Step[3900]: Train loss: 130.4727, Valid loss: 119.4157\n",
      "Epoch [10/100], Step[4000]: Train loss: 120.0757, Valid loss: 119.3754\n",
      "Epoch [10/100], Step[4100]: Train loss: 127.1795, Valid loss: 119.5796\n",
      "Epoch [11/100], Step[4200]: Train loss: 126.8864, Valid loss: 119.4217\n",
      "Epoch [11/100], Step[4300]: Train loss: 119.1958, Valid loss: 119.3398\n",
      "Epoch [11/100], Step[4400]: Train loss: 104.8592, Valid loss: 119.5685\n",
      "Epoch [11/100], Step[4500]: Train loss: 139.1216, Valid loss: 119.2378\n",
      "Epoch [12/100], Step[4600]: Train loss: 125.9064, Valid loss: 119.4530\n",
      "Epoch [12/100], Step[4700]: Train loss: 114.4366, Valid loss: 119.3584\n",
      "Epoch [12/100], Step[4800]: Train loss: 140.1677, Valid loss: 119.3278\n",
      "Epoch [12/100], Step[4900]: Train loss: 120.3862, Valid loss: 119.4990\n",
      "Epoch [12/100], Step[5000]: Train loss: 123.3210, Valid loss: 119.0632\n",
      "Epoch [13/100], Step[5100]: Train loss: 124.4618, Valid loss: 119.0223\n",
      "Epoch [13/100], Step[5200]: Train loss: 110.3497, Valid loss: 119.2978\n",
      "Epoch [13/100], Step[5300]: Train loss: 134.2372, Valid loss: 119.0566\n",
      "Epoch [13/100], Step[5400]: Train loss: 116.4071, Valid loss: 119.1629\n",
      "Epoch [14/100], Step[5500]: Train loss: 109.7076, Valid loss: 119.3391\n",
      "Epoch [14/100], Step[5600]: Train loss: 123.1735, Valid loss: 119.5187\n",
      "Epoch [14/100], Step[5700]: Train loss: 136.9128, Valid loss: 119.1067\n",
      "Epoch [14/100], Step[5800]: Train loss: 109.8415, Valid loss: 119.1182\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 45,\n",
    "    'optimizer': \"SGD\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.00001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model2.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943fc4d5-99cd-41a0-998d-af8400c691d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ac965e-52f2-471b-acfe-a172bafc1f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 10.853115\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "\n",
    "# Change mse to rmse\n",
    "train_loss = np.sqrt(train_loss)\n",
    "valid_loss = np.sqrt(valid_loss)\n",
    "\n",
    "# Draw test, valid RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(step_arr, train_loss ,color = 'r', label=\"Training_RMSE\")\n",
    "plt.plot(step_arr, valid_loss ,color = 'g', label=\"Validation_RMSE\")\n",
    "plt.title(\"Training vs Validation RMSE\")\n",
    "plt.xlabel(\"step (batches)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce6eb5-2825-4b22-8408-e8d693602b1b",
   "metadata": {},
   "source": [
    "The Training and Validation RMSE chart indicates that this may be a bad model, since the Validation RMSE line doesn't decrease as the Training RMSE decreases. Learning rate may be too small or bad optimization so it stucks in a small interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b152c-dfbb-4435-aa79-d90dd900149a",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f111f-60ee-4bb5-b5e8-3b4e29798a9f",
   "metadata": {},
   "source": [
    "H = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf87130-ddc2-4f77-91a3-348e461cfa08",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 137.4203, Valid loss: 119.3198\n",
      "Saving model with loss 119.320...\n",
      "Epoch [1/100], Step[200]: Train loss: 122.8375, Valid loss: 119.4537\n",
      "Epoch [1/100], Step[300]: Train loss: 112.8199, Valid loss: 118.9645\n",
      "Saving model with loss 118.965...\n",
      "Epoch [1/100], Step[400]: Train loss: 116.8828, Valid loss: 119.1396\n",
      "Epoch [2/100], Step[500]: Train loss: 119.9847, Valid loss: 119.4945\n",
      "Epoch [2/100], Step[600]: Train loss: 110.6101, Valid loss: 119.1409\n",
      "Epoch [2/100], Step[700]: Train loss: 108.2575, Valid loss: 119.1559\n",
      "Epoch [2/100], Step[800]: Train loss: 121.5499, Valid loss: 119.3392\n",
      "Epoch [3/100], Step[900]: Train loss: 136.0451, Valid loss: 119.3951\n",
      "Epoch [3/100], Step[1000]: Train loss: 120.2909, Valid loss: 119.5201\n",
      "Epoch [3/100], Step[1100]: Train loss: 128.4163, Valid loss: 119.3521\n",
      "Epoch [3/100], Step[1200]: Train loss: 128.5140, Valid loss: 119.2770\n",
      "Epoch [4/100], Step[1300]: Train loss: 114.4646, Valid loss: 119.2292\n",
      "Epoch [4/100], Step[1400]: Train loss: 117.3568, Valid loss: 119.3366\n",
      "Epoch [4/100], Step[1500]: Train loss: 128.9221, Valid loss: 119.1745\n",
      "Epoch [4/100], Step[1600]: Train loss: 128.7763, Valid loss: 119.4376\n",
      "Epoch [5/100], Step[1700]: Train loss: 120.3713, Valid loss: 119.1201\n",
      "Epoch [5/100], Step[1800]: Train loss: 125.1194, Valid loss: 119.2411\n",
      "Epoch [5/100], Step[1900]: Train loss: 118.1275, Valid loss: 119.2232\n",
      "Epoch [5/100], Step[2000]: Train loss: 121.1310, Valid loss: 119.2853\n",
      "Epoch [6/100], Step[2100]: Train loss: 117.0691, Valid loss: 119.3319\n",
      "Epoch [6/100], Step[2200]: Train loss: 117.9622, Valid loss: 119.2604\n",
      "Epoch [6/100], Step[2300]: Train loss: 119.8303, Valid loss: 118.9507\n",
      "Saving model with loss 118.951...\n",
      "Epoch [6/100], Step[2400]: Train loss: 112.4011, Valid loss: 119.1870\n",
      "Epoch [6/100], Step[2500]: Train loss: 121.2054, Valid loss: 119.3401\n",
      "Epoch [7/100], Step[2600]: Train loss: 120.0464, Valid loss: 119.2324\n",
      "Epoch [7/100], Step[2700]: Train loss: 119.9959, Valid loss: 119.5837\n",
      "Epoch [7/100], Step[2800]: Train loss: 116.1013, Valid loss: 119.2697\n",
      "Epoch [7/100], Step[2900]: Train loss: 120.2297, Valid loss: 119.0389\n",
      "Epoch [8/100], Step[3000]: Train loss: 109.2992, Valid loss: 119.2850\n",
      "Epoch [8/100], Step[3100]: Train loss: 129.4642, Valid loss: 119.2920\n",
      "Epoch [8/100], Step[3200]: Train loss: 120.5535, Valid loss: 119.0607\n",
      "Epoch [8/100], Step[3300]: Train loss: 109.2392, Valid loss: 119.1846\n",
      "Epoch [9/100], Step[3400]: Train loss: 136.3222, Valid loss: 119.6560\n",
      "Epoch [9/100], Step[3500]: Train loss: 109.1203, Valid loss: 119.3587\n",
      "Epoch [9/100], Step[3600]: Train loss: 133.9173, Valid loss: 119.3546\n",
      "Epoch [9/100], Step[3700]: Train loss: 109.1539, Valid loss: 119.5382\n",
      "Epoch [10/100], Step[3800]: Train loss: 120.1546, Valid loss: 119.5693\n",
      "Epoch [10/100], Step[3900]: Train loss: 121.7867, Valid loss: 119.3641\n",
      "Epoch [10/100], Step[4000]: Train loss: 118.5546, Valid loss: 119.3782\n",
      "Epoch [10/100], Step[4100]: Train loss: 121.3002, Valid loss: 119.1276\n",
      "Epoch [11/100], Step[4200]: Train loss: 114.8968, Valid loss: 119.2068\n",
      "Epoch [11/100], Step[4300]: Train loss: 116.9225, Valid loss: 119.2130\n",
      "Epoch [11/100], Step[4400]: Train loss: 111.9102, Valid loss: 119.6446\n",
      "Epoch [11/100], Step[4500]: Train loss: 125.4755, Valid loss: 119.1381\n",
      "Epoch [12/100], Step[4600]: Train loss: 119.1595, Valid loss: 119.4809\n",
      "Epoch [12/100], Step[4700]: Train loss: 110.8386, Valid loss: 118.9795\n",
      "Epoch [12/100], Step[4800]: Train loss: 127.7314, Valid loss: 119.5129\n",
      "Epoch [12/100], Step[4900]: Train loss: 134.4365, Valid loss: 119.3376\n",
      "Epoch [12/100], Step[5000]: Train loss: 133.7900, Valid loss: 119.1803\n",
      "Epoch [13/100], Step[5100]: Train loss: 116.5400, Valid loss: 119.0702\n",
      "Epoch [13/100], Step[5200]: Train loss: 140.5388, Valid loss: 119.5421\n",
      "Epoch [13/100], Step[5300]: Train loss: 127.2373, Valid loss: 119.2066\n",
      "Epoch [13/100], Step[5400]: Train loss: 110.4623, Valid loss: 119.1462\n",
      "Epoch [14/100], Step[5500]: Train loss: 113.2350, Valid loss: 119.2256\n",
      "Epoch [14/100], Step[5600]: Train loss: 123.7296, Valid loss: 119.3772\n",
      "Epoch [14/100], Step[5700]: Train loss: 123.1129, Valid loss: 119.2876\n",
      "Epoch [14/100], Step[5800]: Train loss: 119.0105, Valid loss: 119.1346\n",
      "Epoch [15/100], Step[5900]: Train loss: 111.5888, Valid loss: 119.1547\n",
      "Epoch [15/100], Step[6000]: Train loss: 125.6733, Valid loss: 119.3504\n",
      "Epoch [15/100], Step[6100]: Train loss: 113.6533, Valid loss: 119.3511\n",
      "Epoch [15/100], Step[6200]: Train loss: 115.3377, Valid loss: 119.5272\n",
      "Epoch [16/100], Step[6300]: Train loss: 102.7666, Valid loss: 119.2261\n",
      "Epoch [16/100], Step[6400]: Train loss: 125.8109, Valid loss: 119.2259\n",
      "Epoch [16/100], Step[6500]: Train loss: 107.1543, Valid loss: 119.1613\n",
      "Epoch [16/100], Step[6600]: Train loss: 121.3809, Valid loss: 119.0035\n",
      "Epoch [17/100], Step[6700]: Train loss: 128.1657, Valid loss: 118.9109\n",
      "Saving model with loss 118.911...\n",
      "Epoch [17/100], Step[6800]: Train loss: 110.0483, Valid loss: 119.1116\n",
      "Epoch [17/100], Step[6900]: Train loss: 110.3733, Valid loss: 119.3016\n",
      "Epoch [17/100], Step[7000]: Train loss: 118.9774, Valid loss: 119.4058\n",
      "Epoch [17/100], Step[7100]: Train loss: 137.3515, Valid loss: 119.1133\n",
      "Epoch [18/100], Step[7200]: Train loss: 117.6476, Valid loss: 119.4594\n",
      "Epoch [18/100], Step[7300]: Train loss: 107.8170, Valid loss: 119.3849\n",
      "Epoch [18/100], Step[7400]: Train loss: 112.3377, Valid loss: 119.3147\n",
      "Epoch [18/100], Step[7500]: Train loss: 114.7363, Valid loss: 119.2013\n",
      "Epoch [19/100], Step[7600]: Train loss: 127.6225, Valid loss: 119.3764\n",
      "Epoch [19/100], Step[7700]: Train loss: 120.7281, Valid loss: 119.2619\n",
      "Epoch [19/100], Step[7800]: Train loss: 126.9540, Valid loss: 119.2044\n",
      "Epoch [19/100], Step[7900]: Train loss: 109.7691, Valid loss: 119.3794\n",
      "Epoch [20/100], Step[8000]: Train loss: 107.7134, Valid loss: 118.8689\n",
      "Saving model with loss 118.869...\n",
      "Epoch [20/100], Step[8100]: Train loss: 126.8642, Valid loss: 119.2659\n",
      "Epoch [20/100], Step[8200]: Train loss: 113.6862, Valid loss: 119.0097\n",
      "Epoch [20/100], Step[8300]: Train loss: 123.9732, Valid loss: 119.2968\n",
      "Epoch [21/100], Step[8400]: Train loss: 128.6250, Valid loss: 119.0347\n",
      "Epoch [21/100], Step[8500]: Train loss: 142.9093, Valid loss: 119.1660\n",
      "Epoch [21/100], Step[8600]: Train loss: 130.4386, Valid loss: 119.2336\n",
      "Epoch [21/100], Step[8700]: Train loss: 139.8453, Valid loss: 119.0130\n",
      "Epoch [22/100], Step[8800]: Train loss: 118.4735, Valid loss: 119.2422\n",
      "Epoch [22/100], Step[8900]: Train loss: 126.4356, Valid loss: 119.1618\n",
      "Epoch [22/100], Step[9000]: Train loss: 116.8759, Valid loss: 119.3531\n",
      "Epoch [22/100], Step[9100]: Train loss: 113.0662, Valid loss: 119.2007\n",
      "Epoch [23/100], Step[9200]: Train loss: 125.2687, Valid loss: 118.9997\n",
      "Epoch [23/100], Step[9300]: Train loss: 111.2039, Valid loss: 119.0389\n",
      "Epoch [23/100], Step[9400]: Train loss: 122.7950, Valid loss: 119.0863\n",
      "Epoch [23/100], Step[9500]: Train loss: 110.0951, Valid loss: 119.3741\n",
      "Epoch [23/100], Step[9600]: Train loss: 108.8422, Valid loss: 119.2178\n",
      "Epoch [24/100], Step[9700]: Train loss: 127.8186, Valid loss: 119.2685\n",
      "Epoch [24/100], Step[9800]: Train loss: 129.9643, Valid loss: 119.7563\n",
      "Epoch [24/100], Step[9900]: Train loss: 116.9997, Valid loss: 119.0828\n",
      "Epoch [24/100], Step[10000]: Train loss: 122.2841, Valid loss: 119.1414\n",
      "Epoch [25/100], Step[10100]: Train loss: 132.7400, Valid loss: 119.4209\n",
      "Epoch [25/100], Step[10200]: Train loss: 118.4502, Valid loss: 118.9333\n",
      "Epoch [25/100], Step[10300]: Train loss: 117.4939, Valid loss: 119.3255\n",
      "Epoch [25/100], Step[10400]: Train loss: 111.2779, Valid loss: 119.4224\n",
      "Epoch [26/100], Step[10500]: Train loss: 120.0102, Valid loss: 119.2013\n",
      "Epoch [26/100], Step[10600]: Train loss: 122.1206, Valid loss: 119.3294\n",
      "Epoch [26/100], Step[10700]: Train loss: 120.4987, Valid loss: 119.2540\n",
      "Epoch [26/100], Step[10800]: Train loss: 109.7814, Valid loss: 119.1057\n",
      "Epoch [27/100], Step[10900]: Train loss: 120.4589, Valid loss: 118.9782\n",
      "Epoch [27/100], Step[11000]: Train loss: 134.9086, Valid loss: 119.1010\n",
      "Epoch [27/100], Step[11100]: Train loss: 121.3065, Valid loss: 119.0545\n",
      "Epoch [27/100], Step[11200]: Train loss: 122.1411, Valid loss: 119.1284\n",
      "Epoch [28/100], Step[11300]: Train loss: 122.2671, Valid loss: 119.4218\n",
      "Epoch [28/100], Step[11400]: Train loss: 114.8865, Valid loss: 119.1981\n",
      "Epoch [28/100], Step[11500]: Train loss: 110.0684, Valid loss: 119.3698\n",
      "Epoch [28/100], Step[11600]: Train loss: 126.9022, Valid loss: 119.3737\n",
      "Epoch [28/100], Step[11700]: Train loss: 116.8452, Valid loss: 119.2880\n",
      "Epoch [29/100], Step[11800]: Train loss: 128.9548, Valid loss: 119.0445\n",
      "Epoch [29/100], Step[11900]: Train loss: 115.3626, Valid loss: 119.2877\n",
      "Epoch [29/100], Step[12000]: Train loss: 122.7951, Valid loss: 119.1334\n",
      "Epoch [29/100], Step[12100]: Train loss: 113.0595, Valid loss: 119.2746\n",
      "Epoch [30/100], Step[12200]: Train loss: 131.2951, Valid loss: 119.1042\n",
      "Epoch [30/100], Step[12300]: Train loss: 123.9742, Valid loss: 119.4628\n",
      "Epoch [30/100], Step[12400]: Train loss: 114.9531, Valid loss: 119.8016\n",
      "Epoch [30/100], Step[12500]: Train loss: 134.2313, Valid loss: 119.1893\n",
      "Epoch [31/100], Step[12600]: Train loss: 131.7510, Valid loss: 119.4921\n",
      "Epoch [31/100], Step[12700]: Train loss: 118.6119, Valid loss: 119.2492\n",
      "Epoch [31/100], Step[12800]: Train loss: 121.9189, Valid loss: 119.3547\n",
      "Epoch [31/100], Step[12900]: Train loss: 128.4809, Valid loss: 119.3354\n",
      "Epoch [32/100], Step[13000]: Train loss: 117.8903, Valid loss: 119.3350\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 90,\n",
    "    'optimizer': \"SGD\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.00001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model3-1.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cef93f2-6c0b-4fac-9dee-5be7f94d5892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 10.852602\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3b5c5-840f-4bdf-972b-eca6d31c89d3",
   "metadata": {},
   "source": [
    "H = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb60495a-6ff5-412f-ad74-f3dc8cd6293a",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 103.7431, Valid loss: 119.0743\n",
      "Saving model with loss 119.074...\n",
      "Epoch [1/100], Step[200]: Train loss: 140.2318, Valid loss: 119.2079\n",
      "Epoch [1/100], Step[300]: Train loss: 110.2134, Valid loss: 119.2712\n",
      "Epoch [1/100], Step[400]: Train loss: 121.1736, Valid loss: 119.2751\n",
      "Epoch [2/100], Step[500]: Train loss: 111.7628, Valid loss: 119.2256\n",
      "Epoch [2/100], Step[600]: Train loss: 117.2123, Valid loss: 119.6232\n",
      "Epoch [2/100], Step[700]: Train loss: 109.4865, Valid loss: 119.3130\n",
      "Epoch [2/100], Step[800]: Train loss: 125.5556, Valid loss: 119.4642\n",
      "Epoch [3/100], Step[900]: Train loss: 98.2916, Valid loss: 119.2957\n",
      "Epoch [3/100], Step[1000]: Train loss: 120.5994, Valid loss: 119.0867\n",
      "Epoch [3/100], Step[1100]: Train loss: 118.3205, Valid loss: 119.5170\n",
      "Epoch [3/100], Step[1200]: Train loss: 131.8839, Valid loss: 119.2263\n",
      "Epoch [4/100], Step[1300]: Train loss: 105.3552, Valid loss: 119.3021\n",
      "Epoch [4/100], Step[1400]: Train loss: 127.4461, Valid loss: 119.6037\n",
      "Epoch [4/100], Step[1500]: Train loss: 117.4604, Valid loss: 119.3406\n",
      "Epoch [4/100], Step[1600]: Train loss: 101.3396, Valid loss: 119.1460\n",
      "Epoch [5/100], Step[1700]: Train loss: 117.5978, Valid loss: 119.1629\n",
      "Epoch [5/100], Step[1800]: Train loss: 121.9511, Valid loss: 118.8164\n",
      "Saving model with loss 118.816...\n",
      "Epoch [5/100], Step[1900]: Train loss: 136.0583, Valid loss: 119.4336\n",
      "Epoch [5/100], Step[2000]: Train loss: 111.9399, Valid loss: 119.4431\n",
      "Epoch [6/100], Step[2100]: Train loss: 138.5826, Valid loss: 119.3990\n",
      "Epoch [6/100], Step[2200]: Train loss: 97.5794, Valid loss: 119.2000\n",
      "Epoch [6/100], Step[2300]: Train loss: 132.2466, Valid loss: 119.6235\n",
      "Epoch [6/100], Step[2400]: Train loss: 118.2082, Valid loss: 119.2242\n",
      "Epoch [6/100], Step[2500]: Train loss: 147.5180, Valid loss: 119.0060\n",
      "Epoch [7/100], Step[2600]: Train loss: 118.4701, Valid loss: 119.1568\n",
      "Epoch [7/100], Step[2700]: Train loss: 142.3530, Valid loss: 119.3571\n",
      "Epoch [7/100], Step[2800]: Train loss: 113.5605, Valid loss: 119.3748\n",
      "Epoch [7/100], Step[2900]: Train loss: 126.6486, Valid loss: 119.3932\n",
      "Epoch [8/100], Step[3000]: Train loss: 112.9009, Valid loss: 119.2498\n",
      "Epoch [8/100], Step[3100]: Train loss: 124.0052, Valid loss: 118.8341\n",
      "Epoch [8/100], Step[3200]: Train loss: 126.5005, Valid loss: 119.3066\n",
      "Epoch [8/100], Step[3300]: Train loss: 123.1623, Valid loss: 119.0800\n",
      "Epoch [9/100], Step[3400]: Train loss: 106.9949, Valid loss: 119.2636\n",
      "Epoch [9/100], Step[3500]: Train loss: 127.7264, Valid loss: 119.4833\n",
      "Epoch [9/100], Step[3600]: Train loss: 102.9605, Valid loss: 119.5670\n",
      "Epoch [9/100], Step[3700]: Train loss: 116.8356, Valid loss: 119.3241\n",
      "Epoch [10/100], Step[3800]: Train loss: 112.7098, Valid loss: 118.9748\n",
      "Epoch [10/100], Step[3900]: Train loss: 133.2462, Valid loss: 119.2228\n",
      "Epoch [10/100], Step[4000]: Train loss: 111.4314, Valid loss: 119.1690\n",
      "Epoch [10/100], Step[4100]: Train loss: 123.9160, Valid loss: 119.1125\n",
      "Epoch [11/100], Step[4200]: Train loss: 137.5318, Valid loss: 119.3189\n",
      "Epoch [11/100], Step[4300]: Train loss: 125.2996, Valid loss: 119.3895\n",
      "Epoch [11/100], Step[4400]: Train loss: 122.0132, Valid loss: 119.0918\n",
      "Epoch [11/100], Step[4500]: Train loss: 112.9684, Valid loss: 118.9942\n",
      "Epoch [12/100], Step[4600]: Train loss: 110.0186, Valid loss: 119.6140\n",
      "Epoch [12/100], Step[4700]: Train loss: 121.9520, Valid loss: 119.2334\n",
      "Epoch [12/100], Step[4800]: Train loss: 124.2332, Valid loss: 119.3937\n",
      "Epoch [12/100], Step[4900]: Train loss: 124.1431, Valid loss: 119.2523\n",
      "Epoch [12/100], Step[5000]: Train loss: 117.7664, Valid loss: 119.4445\n",
      "Epoch [13/100], Step[5100]: Train loss: 118.5380, Valid loss: 119.4152\n",
      "Epoch [13/100], Step[5200]: Train loss: 122.8172, Valid loss: 119.1768\n",
      "Epoch [13/100], Step[5300]: Train loss: 121.9004, Valid loss: 119.3092\n",
      "Epoch [13/100], Step[5400]: Train loss: 122.1173, Valid loss: 119.2235\n",
      "Epoch [14/100], Step[5500]: Train loss: 120.3445, Valid loss: 119.0994\n",
      "Epoch [14/100], Step[5600]: Train loss: 112.3872, Valid loss: 119.4641\n",
      "Epoch [14/100], Step[5700]: Train loss: 117.4466, Valid loss: 119.3543\n",
      "Epoch [14/100], Step[5800]: Train loss: 125.4727, Valid loss: 119.3768\n",
      "Epoch [15/100], Step[5900]: Train loss: 125.3278, Valid loss: 119.3295\n",
      "Epoch [15/100], Step[6000]: Train loss: 113.5493, Valid loss: 119.2438\n",
      "Epoch [15/100], Step[6100]: Train loss: 129.0747, Valid loss: 119.0582\n",
      "Epoch [15/100], Step[6200]: Train loss: 121.0288, Valid loss: 119.3375\n",
      "Epoch [16/100], Step[6300]: Train loss: 117.1480, Valid loss: 119.2344\n",
      "Epoch [16/100], Step[6400]: Train loss: 126.1941, Valid loss: 119.5639\n",
      "Epoch [16/100], Step[6500]: Train loss: 108.9343, Valid loss: 118.7673\n",
      "Saving model with loss 118.767...\n",
      "Epoch [16/100], Step[6600]: Train loss: 106.5819, Valid loss: 119.2271\n",
      "Epoch [17/100], Step[6700]: Train loss: 131.3827, Valid loss: 119.0985\n",
      "Epoch [17/100], Step[6800]: Train loss: 123.7562, Valid loss: 119.3504\n",
      "Epoch [17/100], Step[6900]: Train loss: 109.2238, Valid loss: 119.2263\n",
      "Epoch [17/100], Step[7000]: Train loss: 119.3189, Valid loss: 119.3634\n",
      "Epoch [17/100], Step[7100]: Train loss: 120.9190, Valid loss: 119.6052\n",
      "Epoch [18/100], Step[7200]: Train loss: 115.0239, Valid loss: 119.2381\n",
      "Epoch [18/100], Step[7300]: Train loss: 113.6241, Valid loss: 119.3389\n",
      "Epoch [18/100], Step[7400]: Train loss: 117.7666, Valid loss: 118.9486\n",
      "Epoch [18/100], Step[7500]: Train loss: 110.9114, Valid loss: 119.6633\n",
      "Epoch [19/100], Step[7600]: Train loss: 121.2527, Valid loss: 119.3809\n",
      "Epoch [19/100], Step[7700]: Train loss: 104.1130, Valid loss: 119.4091\n",
      "Epoch [19/100], Step[7800]: Train loss: 124.2436, Valid loss: 119.0471\n",
      "Epoch [19/100], Step[7900]: Train loss: 119.9647, Valid loss: 119.0565\n",
      "Epoch [20/100], Step[8000]: Train loss: 111.8844, Valid loss: 119.1872\n",
      "Epoch [20/100], Step[8100]: Train loss: 135.3254, Valid loss: 119.4059\n",
      "Epoch [20/100], Step[8200]: Train loss: 116.2577, Valid loss: 119.3094\n",
      "Epoch [20/100], Step[8300]: Train loss: 118.6782, Valid loss: 119.2889\n",
      "Epoch [21/100], Step[8400]: Train loss: 143.2523, Valid loss: 119.0712\n",
      "Epoch [21/100], Step[8500]: Train loss: 122.5113, Valid loss: 119.3554\n",
      "Epoch [21/100], Step[8600]: Train loss: 118.4727, Valid loss: 119.4602\n",
      "Epoch [21/100], Step[8700]: Train loss: 114.7820, Valid loss: 119.1254\n",
      "Epoch [22/100], Step[8800]: Train loss: 130.5456, Valid loss: 119.1420\n",
      "Epoch [22/100], Step[8900]: Train loss: 112.3368, Valid loss: 119.1571\n",
      "Epoch [22/100], Step[9000]: Train loss: 110.1343, Valid loss: 118.9106\n",
      "Epoch [22/100], Step[9100]: Train loss: 134.9539, Valid loss: 119.0122\n",
      "Epoch [23/100], Step[9200]: Train loss: 120.9867, Valid loss: 119.3204\n",
      "Epoch [23/100], Step[9300]: Train loss: 114.0590, Valid loss: 119.1687\n",
      "Epoch [23/100], Step[9400]: Train loss: 118.3587, Valid loss: 119.3691\n",
      "Epoch [23/100], Step[9500]: Train loss: 124.4373, Valid loss: 119.1619\n",
      "Epoch [23/100], Step[9600]: Train loss: 106.4917, Valid loss: 119.3199\n",
      "Epoch [24/100], Step[9700]: Train loss: 119.3124, Valid loss: 119.6345\n",
      "Epoch [24/100], Step[9800]: Train loss: 127.0762, Valid loss: 119.0824\n",
      "Epoch [24/100], Step[9900]: Train loss: 116.8471, Valid loss: 118.9956\n",
      "Epoch [24/100], Step[10000]: Train loss: 120.3019, Valid loss: 119.2242\n",
      "Epoch [25/100], Step[10100]: Train loss: 128.9806, Valid loss: 119.1685\n",
      "Epoch [25/100], Step[10200]: Train loss: 113.7073, Valid loss: 119.3115\n",
      "Epoch [25/100], Step[10300]: Train loss: 122.9034, Valid loss: 119.3134\n",
      "Epoch [25/100], Step[10400]: Train loss: 108.3452, Valid loss: 118.9860\n",
      "Epoch [26/100], Step[10500]: Train loss: 109.9582, Valid loss: 119.0803\n",
      "Epoch [26/100], Step[10600]: Train loss: 108.5518, Valid loss: 119.5139\n",
      "Epoch [26/100], Step[10700]: Train loss: 115.3474, Valid loss: 119.2773\n",
      "Epoch [26/100], Step[10800]: Train loss: 116.0372, Valid loss: 118.9552\n",
      "Epoch [27/100], Step[10900]: Train loss: 129.7137, Valid loss: 119.0027\n",
      "Epoch [27/100], Step[11000]: Train loss: 110.3085, Valid loss: 119.5475\n",
      "Epoch [27/100], Step[11100]: Train loss: 135.5647, Valid loss: 119.0571\n",
      "Epoch [27/100], Step[11200]: Train loss: 127.6709, Valid loss: 119.1892\n",
      "Epoch [28/100], Step[11300]: Train loss: 117.8472, Valid loss: 119.6862\n",
      "Epoch [28/100], Step[11400]: Train loss: 130.5794, Valid loss: 119.0988\n",
      "Epoch [28/100], Step[11500]: Train loss: 122.2367, Valid loss: 119.0152\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 180,\n",
    "    'optimizer': \"SGD\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.00001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model3-2.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888cdc32-5b6e-44d9-afa2-12295e1f2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 10.850921\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ab320-34cb-4396-99b6-50f9e2e13802",
   "metadata": {},
   "source": [
    "The test RMSE decreases as H increases. So we should pick H = 180 for the lowest RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80dc4b1-cf09-4dea-8d2b-4d54d6321458",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b151ca-b3d5-4f19-8456-67b17b804c18",
   "metadata": {},
   "source": [
    "H = 45, 90, 180 Weight Decay = 0.1, 0.2, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68f4763f-95e3-47fa-bfa4-c7594d8e9f9c",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 112.9320, Valid loss: 119.0585\n",
      "Saving model with loss 119.058...\n",
      "Epoch [1/100], Step[200]: Train loss: 124.8216, Valid loss: 119.2890\n",
      "Epoch [1/100], Step[300]: Train loss: 113.8580, Valid loss: 118.9456\n",
      "Saving model with loss 118.946...\n",
      "Epoch [1/100], Step[400]: Train loss: 124.5668, Valid loss: 119.4016\n",
      "Epoch [2/100], Step[500]: Train loss: 124.2085, Valid loss: 119.1222\n",
      "Epoch [2/100], Step[600]: Train loss: 129.5255, Valid loss: 119.0315\n",
      "Epoch [2/100], Step[700]: Train loss: 118.0732, Valid loss: 119.0127\n",
      "Epoch [2/100], Step[800]: Train loss: 111.0058, Valid loss: 119.1592\n",
      "Epoch [3/100], Step[900]: Train loss: 111.8871, Valid loss: 119.2148\n",
      "Epoch [3/100], Step[1000]: Train loss: 127.9857, Valid loss: 118.9696\n",
      "Epoch [3/100], Step[1100]: Train loss: 119.0730, Valid loss: 119.2385\n",
      "Epoch [3/100], Step[1200]: Train loss: 114.0680, Valid loss: 119.4213\n",
      "Epoch [4/100], Step[1300]: Train loss: 114.2674, Valid loss: 119.3049\n",
      "Epoch [4/100], Step[1400]: Train loss: 128.0444, Valid loss: 119.0493\n",
      "Epoch [4/100], Step[1500]: Train loss: 121.2558, Valid loss: 119.2406\n",
      "Epoch [4/100], Step[1600]: Train loss: 123.1181, Valid loss: 119.2722\n",
      "Epoch [5/100], Step[1700]: Train loss: 129.4949, Valid loss: 119.1443\n",
      "Epoch [5/100], Step[1800]: Train loss: 134.8891, Valid loss: 119.2126\n",
      "Epoch [5/100], Step[1900]: Train loss: 123.9038, Valid loss: 119.9096\n",
      "Epoch [5/100], Step[2000]: Train loss: 109.6321, Valid loss: 119.3910\n",
      "Epoch [6/100], Step[2100]: Train loss: 130.1077, Valid loss: 119.3690\n",
      "Epoch [6/100], Step[2200]: Train loss: 114.4043, Valid loss: 119.0002\n",
      "Epoch [6/100], Step[2300]: Train loss: 116.0437, Valid loss: 119.2833\n",
      "Epoch [6/100], Step[2400]: Train loss: 119.1358, Valid loss: 119.1883\n",
      "Epoch [6/100], Step[2500]: Train loss: 114.1253, Valid loss: 119.2178\n",
      "Epoch [7/100], Step[2600]: Train loss: 124.5712, Valid loss: 119.1438\n",
      "Epoch [7/100], Step[2700]: Train loss: 118.6962, Valid loss: 119.0740\n",
      "Epoch [7/100], Step[2800]: Train loss: 107.7407, Valid loss: 119.1369\n",
      "Epoch [7/100], Step[2900]: Train loss: 108.5090, Valid loss: 119.2793\n",
      "Epoch [8/100], Step[3000]: Train loss: 117.7186, Valid loss: 119.5072\n",
      "Epoch [8/100], Step[3100]: Train loss: 111.2944, Valid loss: 119.0719\n",
      "Epoch [8/100], Step[3200]: Train loss: 120.0610, Valid loss: 119.5128\n",
      "Epoch [8/100], Step[3300]: Train loss: 116.0455, Valid loss: 119.3721\n",
      "Epoch [9/100], Step[3400]: Train loss: 122.5090, Valid loss: 118.9400\n",
      "Saving model with loss 118.940...\n",
      "Epoch [9/100], Step[3500]: Train loss: 127.7780, Valid loss: 119.6023\n",
      "Epoch [9/100], Step[3600]: Train loss: 129.9597, Valid loss: 118.9394\n",
      "Saving model with loss 118.939...\n",
      "Epoch [9/100], Step[3700]: Train loss: 122.9406, Valid loss: 119.6085\n",
      "Epoch [10/100], Step[3800]: Train loss: 114.4968, Valid loss: 119.3163\n",
      "Epoch [10/100], Step[3900]: Train loss: 118.8692, Valid loss: 119.4638\n",
      "Epoch [10/100], Step[4000]: Train loss: 112.2075, Valid loss: 119.0070\n",
      "Epoch [10/100], Step[4100]: Train loss: 121.3948, Valid loss: 119.2529\n",
      "Epoch [11/100], Step[4200]: Train loss: 132.5855, Valid loss: 119.4145\n",
      "Epoch [11/100], Step[4300]: Train loss: 114.3753, Valid loss: 119.1991\n",
      "Epoch [11/100], Step[4400]: Train loss: 116.6413, Valid loss: 119.3807\n",
      "Epoch [11/100], Step[4500]: Train loss: 120.8583, Valid loss: 119.2111\n",
      "Epoch [12/100], Step[4600]: Train loss: 113.9732, Valid loss: 119.3296\n",
      "Epoch [12/100], Step[4700]: Train loss: 114.7041, Valid loss: 119.3114\n",
      "Epoch [12/100], Step[4800]: Train loss: 123.7087, Valid loss: 119.2067\n",
      "Epoch [12/100], Step[4900]: Train loss: 134.3137, Valid loss: 118.8484\n",
      "Saving model with loss 118.848...\n",
      "Epoch [12/100], Step[5000]: Train loss: 109.5174, Valid loss: 119.0262\n",
      "Epoch [13/100], Step[5100]: Train loss: 109.2391, Valid loss: 119.0089\n",
      "Epoch [13/100], Step[5200]: Train loss: 117.9959, Valid loss: 119.1320\n",
      "Epoch [13/100], Step[5300]: Train loss: 116.0980, Valid loss: 119.2000\n",
      "Epoch [13/100], Step[5400]: Train loss: 131.8953, Valid loss: 119.4217\n",
      "Epoch [14/100], Step[5500]: Train loss: 122.8379, Valid loss: 118.9168\n",
      "Epoch [14/100], Step[5600]: Train loss: 118.6838, Valid loss: 119.6451\n",
      "Epoch [14/100], Step[5700]: Train loss: 109.7371, Valid loss: 119.4670\n",
      "Epoch [14/100], Step[5800]: Train loss: 134.6370, Valid loss: 119.1564\n",
      "Epoch [15/100], Step[5900]: Train loss: 121.7066, Valid loss: 119.2903\n",
      "Epoch [15/100], Step[6000]: Train loss: 114.1177, Valid loss: 119.0561\n",
      "Epoch [15/100], Step[6100]: Train loss: 123.6294, Valid loss: 119.2417\n",
      "Epoch [15/100], Step[6200]: Train loss: 115.0542, Valid loss: 119.0058\n",
      "Epoch [16/100], Step[6300]: Train loss: 126.0993, Valid loss: 119.1088\n",
      "Epoch [16/100], Step[6400]: Train loss: 127.0283, Valid loss: 119.4069\n",
      "Epoch [16/100], Step[6500]: Train loss: 105.1706, Valid loss: 119.1822\n",
      "Epoch [16/100], Step[6600]: Train loss: 125.5247, Valid loss: 119.2324\n",
      "Epoch [17/100], Step[6700]: Train loss: 141.2695, Valid loss: 119.2458\n",
      "Epoch [17/100], Step[6800]: Train loss: 126.7620, Valid loss: 119.3754\n",
      "Epoch [17/100], Step[6900]: Train loss: 119.7865, Valid loss: 119.1847\n",
      "Epoch [17/100], Step[7000]: Train loss: 130.9396, Valid loss: 119.4239\n",
      "Epoch [17/100], Step[7100]: Train loss: 135.4927, Valid loss: 119.0652\n",
      "Epoch [18/100], Step[7200]: Train loss: 120.7651, Valid loss: 119.0824\n",
      "Epoch [18/100], Step[7300]: Train loss: 107.1576, Valid loss: 119.2840\n",
      "Epoch [18/100], Step[7400]: Train loss: 123.0624, Valid loss: 119.2602\n",
      "Epoch [18/100], Step[7500]: Train loss: 121.8517, Valid loss: 119.4815\n",
      "Epoch [19/100], Step[7600]: Train loss: 124.5444, Valid loss: 119.1015\n",
      "Epoch [19/100], Step[7700]: Train loss: 116.8543, Valid loss: 119.3766\n",
      "Epoch [19/100], Step[7800]: Train loss: 130.8991, Valid loss: 119.0710\n",
      "Epoch [19/100], Step[7900]: Train loss: 117.1969, Valid loss: 119.2087\n",
      "Epoch [20/100], Step[8000]: Train loss: 120.8843, Valid loss: 119.3906\n",
      "Epoch [20/100], Step[8100]: Train loss: 116.4027, Valid loss: 119.0408\n",
      "Epoch [20/100], Step[8200]: Train loss: 112.0071, Valid loss: 119.2840\n",
      "Epoch [20/100], Step[8300]: Train loss: 112.5675, Valid loss: 119.1244\n",
      "Epoch [21/100], Step[8400]: Train loss: 121.0586, Valid loss: 119.0463\n",
      "Epoch [21/100], Step[8500]: Train loss: 124.3694, Valid loss: 118.9614\n",
      "Epoch [21/100], Step[8600]: Train loss: 126.5299, Valid loss: 119.1846\n",
      "Epoch [21/100], Step[8700]: Train loss: 123.1137, Valid loss: 119.3220\n",
      "Epoch [22/100], Step[8800]: Train loss: 116.2620, Valid loss: 118.9858\n",
      "Epoch [22/100], Step[8900]: Train loss: 139.0778, Valid loss: 119.2666\n",
      "Epoch [22/100], Step[9000]: Train loss: 137.7234, Valid loss: 119.3259\n",
      "Epoch [22/100], Step[9100]: Train loss: 119.1863, Valid loss: 119.0374\n",
      "Epoch [23/100], Step[9200]: Train loss: 123.6919, Valid loss: 119.3747\n",
      "Epoch [23/100], Step[9300]: Train loss: 120.2746, Valid loss: 119.2455\n",
      "Epoch [23/100], Step[9400]: Train loss: 122.6360, Valid loss: 119.2751\n",
      "Epoch [23/100], Step[9500]: Train loss: 114.9106, Valid loss: 119.2396\n",
      "Epoch [23/100], Step[9600]: Train loss: 117.9610, Valid loss: 119.2772\n",
      "Epoch [24/100], Step[9700]: Train loss: 125.2577, Valid loss: 119.3225\n",
      "Epoch [24/100], Step[9800]: Train loss: 117.3024, Valid loss: 119.2294\n",
      "Epoch [24/100], Step[9900]: Train loss: 119.2807, Valid loss: 119.2728\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 116.9829, Valid loss: 119.5828\n",
      "Saving model with loss 119.583...\n",
      "Epoch [1/100], Step[200]: Train loss: 120.6229, Valid loss: 119.4709\n",
      "Saving model with loss 119.471...\n",
      "Epoch [1/100], Step[300]: Train loss: 118.0672, Valid loss: 119.1274\n",
      "Saving model with loss 119.127...\n",
      "Epoch [1/100], Step[400]: Train loss: 126.2205, Valid loss: 119.2188\n",
      "Epoch [2/100], Step[500]: Train loss: 117.0115, Valid loss: 119.4607\n",
      "Epoch [2/100], Step[600]: Train loss: 109.5588, Valid loss: 119.3795\n",
      "Epoch [2/100], Step[700]: Train loss: 121.3154, Valid loss: 119.1453\n",
      "Epoch [2/100], Step[800]: Train loss: 115.1354, Valid loss: 119.6871\n",
      "Epoch [3/100], Step[900]: Train loss: 113.4154, Valid loss: 119.3093\n",
      "Epoch [3/100], Step[1000]: Train loss: 124.6719, Valid loss: 119.6775\n",
      "Epoch [3/100], Step[1100]: Train loss: 105.6275, Valid loss: 119.5246\n",
      "Epoch [3/100], Step[1200]: Train loss: 116.4296, Valid loss: 119.0718\n",
      "Saving model with loss 119.072...\n",
      "Epoch [4/100], Step[1300]: Train loss: 113.9357, Valid loss: 119.5822\n",
      "Epoch [4/100], Step[1400]: Train loss: 120.3092, Valid loss: 119.3444\n",
      "Epoch [4/100], Step[1500]: Train loss: 116.3427, Valid loss: 119.2320\n",
      "Epoch [4/100], Step[1600]: Train loss: 117.8205, Valid loss: 119.2092\n",
      "Epoch [5/100], Step[1700]: Train loss: 121.5536, Valid loss: 119.1495\n",
      "Epoch [5/100], Step[1800]: Train loss: 121.2226, Valid loss: 119.1638\n",
      "Epoch [5/100], Step[1900]: Train loss: 116.4604, Valid loss: 119.3107\n",
      "Epoch [5/100], Step[2000]: Train loss: 120.4083, Valid loss: 119.0982\n",
      "Epoch [6/100], Step[2100]: Train loss: 115.0100, Valid loss: 119.0139\n",
      "Saving model with loss 119.014...\n",
      "Epoch [6/100], Step[2200]: Train loss: 122.6311, Valid loss: 119.5503\n",
      "Epoch [6/100], Step[2300]: Train loss: 122.0942, Valid loss: 119.5399\n",
      "Epoch [6/100], Step[2400]: Train loss: 131.1061, Valid loss: 119.1795\n",
      "Epoch [6/100], Step[2500]: Train loss: 115.7366, Valid loss: 119.4450\n",
      "Epoch [7/100], Step[2600]: Train loss: 131.2199, Valid loss: 119.3984\n",
      "Epoch [7/100], Step[2700]: Train loss: 118.0745, Valid loss: 119.2256\n",
      "Epoch [7/100], Step[2800]: Train loss: 116.1450, Valid loss: 119.1137\n",
      "Epoch [7/100], Step[2900]: Train loss: 119.3927, Valid loss: 119.3007\n",
      "Epoch [8/100], Step[3000]: Train loss: 110.2872, Valid loss: 119.1771\n",
      "Epoch [8/100], Step[3100]: Train loss: 114.3044, Valid loss: 119.2646\n",
      "Epoch [8/100], Step[3200]: Train loss: 110.6467, Valid loss: 119.4311\n",
      "Epoch [8/100], Step[3300]: Train loss: 116.0016, Valid loss: 119.3402\n",
      "Epoch [9/100], Step[3400]: Train loss: 108.2768, Valid loss: 119.3136\n",
      "Epoch [9/100], Step[3500]: Train loss: 125.2234, Valid loss: 118.8854\n",
      "Saving model with loss 118.885...\n",
      "Epoch [9/100], Step[3600]: Train loss: 127.6534, Valid loss: 119.5856\n",
      "Epoch [9/100], Step[3700]: Train loss: 119.5672, Valid loss: 119.3706\n",
      "Epoch [10/100], Step[3800]: Train loss: 118.2164, Valid loss: 119.2382\n",
      "Epoch [10/100], Step[3900]: Train loss: 130.8248, Valid loss: 119.4468\n",
      "Epoch [10/100], Step[4000]: Train loss: 131.0108, Valid loss: 119.3055\n",
      "Epoch [10/100], Step[4100]: Train loss: 113.1061, Valid loss: 119.6431\n",
      "Epoch [11/100], Step[4200]: Train loss: 134.8530, Valid loss: 119.3058\n",
      "Epoch [11/100], Step[4300]: Train loss: 122.7173, Valid loss: 119.4040\n",
      "Epoch [11/100], Step[4400]: Train loss: 118.6680, Valid loss: 119.1065\n",
      "Epoch [11/100], Step[4500]: Train loss: 120.0328, Valid loss: 119.6380\n",
      "Epoch [12/100], Step[4600]: Train loss: 123.7078, Valid loss: 119.1025\n",
      "Epoch [12/100], Step[4700]: Train loss: 113.5391, Valid loss: 119.2899\n",
      "Epoch [12/100], Step[4800]: Train loss: 133.0471, Valid loss: 119.0576\n",
      "Epoch [12/100], Step[4900]: Train loss: 123.7056, Valid loss: 119.0812\n",
      "Epoch [12/100], Step[5000]: Train loss: 112.6643, Valid loss: 119.3225\n",
      "Epoch [13/100], Step[5100]: Train loss: 120.6353, Valid loss: 119.3035\n",
      "Epoch [13/100], Step[5200]: Train loss: 119.8623, Valid loss: 119.0987\n",
      "Epoch [13/100], Step[5300]: Train loss: 113.2721, Valid loss: 119.2264\n",
      "Epoch [13/100], Step[5400]: Train loss: 125.8381, Valid loss: 119.1455\n",
      "Epoch [14/100], Step[5500]: Train loss: 120.8295, Valid loss: 119.6456\n",
      "Epoch [14/100], Step[5600]: Train loss: 115.7543, Valid loss: 119.3916\n",
      "Epoch [14/100], Step[5700]: Train loss: 122.0157, Valid loss: 119.0090\n",
      "Epoch [14/100], Step[5800]: Train loss: 114.6715, Valid loss: 119.2423\n",
      "Epoch [15/100], Step[5900]: Train loss: 124.4022, Valid loss: 119.3062\n",
      "Epoch [15/100], Step[6000]: Train loss: 125.9363, Valid loss: 118.8976\n",
      "Epoch [15/100], Step[6100]: Train loss: 120.2554, Valid loss: 119.2257\n",
      "Epoch [15/100], Step[6200]: Train loss: 115.5596, Valid loss: 118.7989\n",
      "Saving model with loss 118.799...\n",
      "Epoch [16/100], Step[6300]: Train loss: 114.3092, Valid loss: 119.2489\n",
      "Epoch [16/100], Step[6400]: Train loss: 120.8289, Valid loss: 119.1935\n",
      "Epoch [16/100], Step[6500]: Train loss: 127.5191, Valid loss: 119.2671\n",
      "Epoch [16/100], Step[6600]: Train loss: 104.5486, Valid loss: 119.5031\n",
      "Epoch [17/100], Step[6700]: Train loss: 130.3725, Valid loss: 119.4618\n",
      "Epoch [17/100], Step[6800]: Train loss: 106.1865, Valid loss: 119.3793\n",
      "Epoch [17/100], Step[6900]: Train loss: 128.9175, Valid loss: 119.1715\n",
      "Epoch [17/100], Step[7000]: Train loss: 108.7369, Valid loss: 119.4535\n",
      "Epoch [17/100], Step[7100]: Train loss: 127.8421, Valid loss: 119.5094\n",
      "Epoch [18/100], Step[7200]: Train loss: 122.4494, Valid loss: 119.1344\n",
      "Epoch [18/100], Step[7300]: Train loss: 118.4764, Valid loss: 119.2310\n",
      "Epoch [18/100], Step[7400]: Train loss: 118.4484, Valid loss: 119.2141\n",
      "Epoch [18/100], Step[7500]: Train loss: 128.2762, Valid loss: 119.1348\n",
      "Epoch [19/100], Step[7600]: Train loss: 112.5517, Valid loss: 119.0168\n",
      "Epoch [19/100], Step[7700]: Train loss: 113.5565, Valid loss: 119.3724\n",
      "Epoch [19/100], Step[7800]: Train loss: 117.4102, Valid loss: 119.5597\n",
      "Epoch [19/100], Step[7900]: Train loss: 118.4682, Valid loss: 119.2795\n",
      "Epoch [20/100], Step[8000]: Train loss: 117.6042, Valid loss: 118.7761\n",
      "Saving model with loss 118.776...\n",
      "Epoch [20/100], Step[8100]: Train loss: 136.1170, Valid loss: 119.1909\n",
      "Epoch [20/100], Step[8200]: Train loss: 119.1870, Valid loss: 119.1184\n",
      "Epoch [20/100], Step[8300]: Train loss: 106.2411, Valid loss: 119.1193\n",
      "Epoch [21/100], Step[8400]: Train loss: 117.1967, Valid loss: 119.0265\n",
      "Epoch [21/100], Step[8500]: Train loss: 132.0416, Valid loss: 118.9886\n",
      "Epoch [21/100], Step[8600]: Train loss: 114.8475, Valid loss: 119.3312\n",
      "Epoch [21/100], Step[8700]: Train loss: 117.7965, Valid loss: 119.1869\n",
      "Epoch [22/100], Step[8800]: Train loss: 117.6890, Valid loss: 119.2688\n",
      "Epoch [22/100], Step[8900]: Train loss: 127.6100, Valid loss: 119.3190\n",
      "Epoch [22/100], Step[9000]: Train loss: 121.2091, Valid loss: 119.5531\n",
      "Epoch [22/100], Step[9100]: Train loss: 113.1909, Valid loss: 119.2402\n",
      "Epoch [23/100], Step[9200]: Train loss: 122.6680, Valid loss: 119.1521\n",
      "Epoch [23/100], Step[9300]: Train loss: 124.2286, Valid loss: 119.1881\n",
      "Epoch [23/100], Step[9400]: Train loss: 137.2828, Valid loss: 119.1008\n",
      "Epoch [23/100], Step[9500]: Train loss: 124.7751, Valid loss: 119.1460\n",
      "Epoch [23/100], Step[9600]: Train loss: 120.1694, Valid loss: 119.2074\n",
      "Epoch [24/100], Step[9700]: Train loss: 113.6441, Valid loss: 119.1545\n",
      "Epoch [24/100], Step[9800]: Train loss: 130.2515, Valid loss: 119.1963\n",
      "Epoch [24/100], Step[9900]: Train loss: 128.0585, Valid loss: 119.3372\n",
      "Epoch [24/100], Step[10000]: Train loss: 136.9058, Valid loss: 119.0153\n",
      "Epoch [25/100], Step[10100]: Train loss: 116.2841, Valid loss: 119.1891\n",
      "Epoch [25/100], Step[10200]: Train loss: 125.2364, Valid loss: 119.5261\n",
      "Epoch [25/100], Step[10300]: Train loss: 107.0734, Valid loss: 119.2188\n",
      "Epoch [25/100], Step[10400]: Train loss: 105.8359, Valid loss: 119.3444\n",
      "Epoch [26/100], Step[10500]: Train loss: 117.6021, Valid loss: 119.1625\n",
      "Epoch [26/100], Step[10600]: Train loss: 127.0160, Valid loss: 119.2885\n",
      "Epoch [26/100], Step[10700]: Train loss: 113.7901, Valid loss: 119.1715\n",
      "Epoch [26/100], Step[10800]: Train loss: 106.3831, Valid loss: 119.2434\n",
      "Epoch [27/100], Step[10900]: Train loss: 133.5163, Valid loss: 119.2441\n",
      "Epoch [27/100], Step[11000]: Train loss: 111.0642, Valid loss: 118.8781\n",
      "Epoch [27/100], Step[11100]: Train loss: 130.3230, Valid loss: 118.9218\n",
      "Epoch [27/100], Step[11200]: Train loss: 119.2947, Valid loss: 119.2658\n",
      "Epoch [28/100], Step[11300]: Train loss: 119.6945, Valid loss: 119.2610\n",
      "Epoch [28/100], Step[11400]: Train loss: 122.9147, Valid loss: 119.0024\n",
      "Epoch [28/100], Step[11500]: Train loss: 110.9101, Valid loss: 119.2011\n",
      "Epoch [28/100], Step[11600]: Train loss: 125.0491, Valid loss: 119.3682\n",
      "Epoch [28/100], Step[11700]: Train loss: 122.5052, Valid loss: 119.1957\n",
      "Epoch [29/100], Step[11800]: Train loss: 131.0181, Valid loss: 119.0417\n",
      "Epoch [29/100], Step[11900]: Train loss: 102.3472, Valid loss: 118.8611\n",
      "Epoch [29/100], Step[12000]: Train loss: 112.1400, Valid loss: 119.1545\n",
      "Epoch [29/100], Step[12100]: Train loss: 130.0067, Valid loss: 119.3070\n",
      "Epoch [30/100], Step[12200]: Train loss: 118.5664, Valid loss: 118.9337\n",
      "Epoch [30/100], Step[12300]: Train loss: 109.3908, Valid loss: 119.0234\n",
      "Epoch [30/100], Step[12400]: Train loss: 118.8989, Valid loss: 118.9880\n",
      "Epoch [30/100], Step[12500]: Train loss: 108.3596, Valid loss: 119.3918\n",
      "Epoch [31/100], Step[12600]: Train loss: 103.6365, Valid loss: 119.0857\n",
      "Epoch [31/100], Step[12700]: Train loss: 104.9605, Valid loss: 119.3022\n",
      "Epoch [31/100], Step[12800]: Train loss: 116.4559, Valid loss: 118.9419\n",
      "Epoch [31/100], Step[12900]: Train loss: 126.2585, Valid loss: 119.2428\n",
      "Epoch [32/100], Step[13000]: Train loss: 114.6152, Valid loss: 119.2910\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 135.5770, Valid loss: 119.3033\n",
      "Saving model with loss 119.303...\n",
      "Epoch [1/100], Step[200]: Train loss: 126.0227, Valid loss: 119.3705\n",
      "Epoch [1/100], Step[300]: Train loss: 121.1699, Valid loss: 119.2624\n",
      "Saving model with loss 119.262...\n",
      "Epoch [1/100], Step[400]: Train loss: 106.8291, Valid loss: 119.0722\n",
      "Saving model with loss 119.072...\n",
      "Epoch [2/100], Step[500]: Train loss: 118.9549, Valid loss: 119.4209\n",
      "Epoch [2/100], Step[600]: Train loss: 124.4468, Valid loss: 119.2921\n",
      "Epoch [2/100], Step[700]: Train loss: 123.3608, Valid loss: 119.4032\n",
      "Epoch [2/100], Step[800]: Train loss: 119.6666, Valid loss: 119.1602\n",
      "Epoch [3/100], Step[900]: Train loss: 115.7357, Valid loss: 119.4313\n",
      "Epoch [3/100], Step[1000]: Train loss: 121.0543, Valid loss: 119.0082\n",
      "Saving model with loss 119.008...\n",
      "Epoch [3/100], Step[1100]: Train loss: 120.7079, Valid loss: 119.3668\n",
      "Epoch [3/100], Step[1200]: Train loss: 117.6460, Valid loss: 119.1001\n",
      "Epoch [4/100], Step[1300]: Train loss: 122.3671, Valid loss: 119.2357\n",
      "Epoch [4/100], Step[1400]: Train loss: 119.0455, Valid loss: 119.2938\n",
      "Epoch [4/100], Step[1500]: Train loss: 117.6505, Valid loss: 119.1578\n",
      "Epoch [4/100], Step[1600]: Train loss: 120.6659, Valid loss: 119.1884\n",
      "Epoch [5/100], Step[1700]: Train loss: 110.2790, Valid loss: 119.2053\n",
      "Epoch [5/100], Step[1800]: Train loss: 123.2968, Valid loss: 119.1481\n",
      "Epoch [5/100], Step[1900]: Train loss: 117.1710, Valid loss: 119.1592\n",
      "Epoch [5/100], Step[2000]: Train loss: 118.9235, Valid loss: 118.8514\n",
      "Saving model with loss 118.851...\n",
      "Epoch [6/100], Step[2100]: Train loss: 121.7393, Valid loss: 118.9546\n",
      "Epoch [6/100], Step[2200]: Train loss: 116.1008, Valid loss: 118.9538\n",
      "Epoch [6/100], Step[2300]: Train loss: 126.6743, Valid loss: 119.2972\n",
      "Epoch [6/100], Step[2400]: Train loss: 99.2332, Valid loss: 119.0297\n",
      "Epoch [6/100], Step[2500]: Train loss: 118.1626, Valid loss: 119.4438\n",
      "Epoch [7/100], Step[2600]: Train loss: 116.4784, Valid loss: 119.3188\n",
      "Epoch [7/100], Step[2700]: Train loss: 122.3144, Valid loss: 119.4720\n",
      "Epoch [7/100], Step[2800]: Train loss: 128.4310, Valid loss: 119.3244\n",
      "Epoch [7/100], Step[2900]: Train loss: 125.2065, Valid loss: 119.4670\n",
      "Epoch [8/100], Step[3000]: Train loss: 114.9687, Valid loss: 119.4460\n",
      "Epoch [8/100], Step[3100]: Train loss: 125.7822, Valid loss: 119.2817\n",
      "Epoch [8/100], Step[3200]: Train loss: 125.8873, Valid loss: 119.4595\n",
      "Epoch [8/100], Step[3300]: Train loss: 102.2840, Valid loss: 119.2382\n",
      "Epoch [9/100], Step[3400]: Train loss: 118.0823, Valid loss: 119.3671\n",
      "Epoch [9/100], Step[3500]: Train loss: 128.6016, Valid loss: 118.9538\n",
      "Epoch [9/100], Step[3600]: Train loss: 103.9518, Valid loss: 119.4679\n",
      "Epoch [9/100], Step[3700]: Train loss: 111.1738, Valid loss: 119.2520\n",
      "Epoch [10/100], Step[3800]: Train loss: 114.7118, Valid loss: 119.1419\n",
      "Epoch [10/100], Step[3900]: Train loss: 120.8452, Valid loss: 119.3457\n",
      "Epoch [10/100], Step[4000]: Train loss: 121.4227, Valid loss: 119.1327\n",
      "Epoch [10/100], Step[4100]: Train loss: 117.6777, Valid loss: 119.3887\n",
      "Epoch [11/100], Step[4200]: Train loss: 119.8788, Valid loss: 119.2567\n",
      "Epoch [11/100], Step[4300]: Train loss: 117.2409, Valid loss: 119.2551\n",
      "Epoch [11/100], Step[4400]: Train loss: 113.9583, Valid loss: 119.2582\n",
      "Epoch [11/100], Step[4500]: Train loss: 104.9513, Valid loss: 119.1688\n",
      "Epoch [12/100], Step[4600]: Train loss: 118.9062, Valid loss: 119.0184\n",
      "Epoch [12/100], Step[4700]: Train loss: 110.2426, Valid loss: 119.0862\n",
      "Epoch [12/100], Step[4800]: Train loss: 113.5540, Valid loss: 119.2329\n",
      "Epoch [12/100], Step[4900]: Train loss: 135.0374, Valid loss: 118.9148\n",
      "Epoch [12/100], Step[5000]: Train loss: 122.2012, Valid loss: 119.0484\n",
      "Epoch [13/100], Step[5100]: Train loss: 110.3418, Valid loss: 118.9619\n",
      "Epoch [13/100], Step[5200]: Train loss: 128.6718, Valid loss: 119.1334\n",
      "Epoch [13/100], Step[5300]: Train loss: 102.9312, Valid loss: 119.2976\n",
      "Epoch [13/100], Step[5400]: Train loss: 113.1390, Valid loss: 119.2256\n",
      "Epoch [14/100], Step[5500]: Train loss: 110.5779, Valid loss: 119.4463\n",
      "Epoch [14/100], Step[5600]: Train loss: 114.4857, Valid loss: 119.2734\n",
      "Epoch [14/100], Step[5700]: Train loss: 130.0773, Valid loss: 119.2598\n",
      "Epoch [14/100], Step[5800]: Train loss: 122.5505, Valid loss: 119.3743\n",
      "Epoch [15/100], Step[5900]: Train loss: 120.7079, Valid loss: 119.0929\n",
      "Epoch [15/100], Step[6000]: Train loss: 116.6235, Valid loss: 119.0941\n",
      "Epoch [15/100], Step[6100]: Train loss: 116.2872, Valid loss: 119.3880\n",
      "Epoch [15/100], Step[6200]: Train loss: 119.8064, Valid loss: 118.9624\n",
      "Epoch [16/100], Step[6300]: Train loss: 126.4647, Valid loss: 119.3400\n",
      "Epoch [16/100], Step[6400]: Train loss: 117.1096, Valid loss: 119.0220\n",
      "Epoch [16/100], Step[6500]: Train loss: 109.7653, Valid loss: 119.3204\n",
      "Epoch [16/100], Step[6600]: Train loss: 128.5764, Valid loss: 119.2603\n",
      "Epoch [17/100], Step[6700]: Train loss: 112.2873, Valid loss: 119.1310\n",
      "Epoch [17/100], Step[6800]: Train loss: 113.2012, Valid loss: 119.4047\n",
      "Epoch [17/100], Step[6900]: Train loss: 121.7740, Valid loss: 119.5095\n",
      "Epoch [17/100], Step[7000]: Train loss: 119.4626, Valid loss: 119.0553\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 139.1269, Valid loss: 119.4128\n",
      "Saving model with loss 119.413...\n",
      "Epoch [1/100], Step[200]: Train loss: 122.5668, Valid loss: 119.5230\n",
      "Epoch [1/100], Step[300]: Train loss: 117.8884, Valid loss: 118.8578\n",
      "Saving model with loss 118.858...\n",
      "Epoch [1/100], Step[400]: Train loss: 126.7267, Valid loss: 119.5372\n",
      "Epoch [2/100], Step[500]: Train loss: 130.7948, Valid loss: 119.2187\n",
      "Epoch [2/100], Step[600]: Train loss: 108.4475, Valid loss: 119.4405\n",
      "Epoch [2/100], Step[700]: Train loss: 127.4110, Valid loss: 119.4761\n",
      "Epoch [2/100], Step[800]: Train loss: 127.3632, Valid loss: 119.4866\n",
      "Epoch [3/100], Step[900]: Train loss: 130.2237, Valid loss: 119.2132\n",
      "Epoch [3/100], Step[1000]: Train loss: 122.0197, Valid loss: 119.0641\n",
      "Epoch [3/100], Step[1100]: Train loss: 109.9755, Valid loss: 119.4391\n",
      "Epoch [3/100], Step[1200]: Train loss: 105.1085, Valid loss: 119.3665\n",
      "Epoch [4/100], Step[1300]: Train loss: 117.2144, Valid loss: 119.4276\n",
      "Epoch [4/100], Step[1400]: Train loss: 114.8772, Valid loss: 119.2885\n",
      "Epoch [4/100], Step[1500]: Train loss: 121.9303, Valid loss: 119.3228\n",
      "Epoch [4/100], Step[1600]: Train loss: 119.0310, Valid loss: 119.6209\n",
      "Epoch [5/100], Step[1700]: Train loss: 121.6666, Valid loss: 119.5648\n",
      "Epoch [5/100], Step[1800]: Train loss: 126.7285, Valid loss: 119.3276\n",
      "Epoch [5/100], Step[1900]: Train loss: 108.4575, Valid loss: 119.2161\n",
      "Epoch [5/100], Step[2000]: Train loss: 108.1619, Valid loss: 119.1881\n",
      "Epoch [6/100], Step[2100]: Train loss: 115.3825, Valid loss: 119.0798\n",
      "Epoch [6/100], Step[2200]: Train loss: 130.9135, Valid loss: 119.1422\n",
      "Epoch [6/100], Step[2300]: Train loss: 106.3503, Valid loss: 119.3498\n",
      "Epoch [6/100], Step[2400]: Train loss: 114.1950, Valid loss: 118.8582\n",
      "Epoch [6/100], Step[2500]: Train loss: 111.6084, Valid loss: 119.3089\n",
      "Epoch [7/100], Step[2600]: Train loss: 110.9475, Valid loss: 119.5800\n",
      "Epoch [7/100], Step[2700]: Train loss: 131.3636, Valid loss: 119.6309\n",
      "Epoch [7/100], Step[2800]: Train loss: 118.2019, Valid loss: 119.4747\n",
      "Epoch [7/100], Step[2900]: Train loss: 98.9132, Valid loss: 119.3410\n",
      "Epoch [8/100], Step[3000]: Train loss: 121.9715, Valid loss: 119.0990\n",
      "Epoch [8/100], Step[3100]: Train loss: 115.7961, Valid loss: 118.9211\n",
      "Epoch [8/100], Step[3200]: Train loss: 123.8978, Valid loss: 119.5092\n",
      "Epoch [8/100], Step[3300]: Train loss: 115.8416, Valid loss: 119.1507\n",
      "Epoch [9/100], Step[3400]: Train loss: 109.8373, Valid loss: 119.0326\n",
      "Epoch [9/100], Step[3500]: Train loss: 123.4931, Valid loss: 119.4821\n",
      "Epoch [9/100], Step[3600]: Train loss: 114.5156, Valid loss: 118.9383\n",
      "Epoch [9/100], Step[3700]: Train loss: 119.1291, Valid loss: 119.1399\n",
      "Epoch [10/100], Step[3800]: Train loss: 125.7899, Valid loss: 119.3445\n",
      "Epoch [10/100], Step[3900]: Train loss: 116.5448, Valid loss: 119.1307\n",
      "Epoch [10/100], Step[4000]: Train loss: 109.8680, Valid loss: 119.0529\n",
      "Epoch [10/100], Step[4100]: Train loss: 145.5489, Valid loss: 118.9408\n",
      "Epoch [11/100], Step[4200]: Train loss: 105.9663, Valid loss: 119.4766\n",
      "Epoch [11/100], Step[4300]: Train loss: 118.9412, Valid loss: 119.0756\n",
      "Epoch [11/100], Step[4400]: Train loss: 113.7192, Valid loss: 119.5239\n",
      "Epoch [11/100], Step[4500]: Train loss: 117.0746, Valid loss: 119.2010\n",
      "Epoch [12/100], Step[4600]: Train loss: 125.9336, Valid loss: 119.2409\n",
      "Epoch [12/100], Step[4700]: Train loss: 119.2463, Valid loss: 119.2892\n",
      "Epoch [12/100], Step[4800]: Train loss: 114.0663, Valid loss: 119.2661\n",
      "Epoch [12/100], Step[4900]: Train loss: 110.5165, Valid loss: 119.1280\n",
      "Epoch [12/100], Step[5000]: Train loss: 112.1090, Valid loss: 119.2893\n",
      "Epoch [13/100], Step[5100]: Train loss: 115.2675, Valid loss: 119.1348\n",
      "Epoch [13/100], Step[5200]: Train loss: 135.2809, Valid loss: 119.6689\n",
      "Epoch [13/100], Step[5300]: Train loss: 117.9956, Valid loss: 119.3744\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 124.1563, Valid loss: 119.2604\n",
      "Saving model with loss 119.260...\n",
      "Epoch [1/100], Step[200]: Train loss: 117.7859, Valid loss: 119.1981\n",
      "Saving model with loss 119.198...\n",
      "Epoch [1/100], Step[300]: Train loss: 130.5359, Valid loss: 119.3310\n",
      "Epoch [1/100], Step[400]: Train loss: 133.3698, Valid loss: 119.3127\n",
      "Epoch [2/100], Step[500]: Train loss: 125.9142, Valid loss: 119.2783\n",
      "Epoch [2/100], Step[600]: Train loss: 127.0353, Valid loss: 119.5953\n",
      "Epoch [2/100], Step[700]: Train loss: 116.4855, Valid loss: 119.4213\n",
      "Epoch [2/100], Step[800]: Train loss: 135.5851, Valid loss: 119.0645\n",
      "Saving model with loss 119.064...\n",
      "Epoch [3/100], Step[900]: Train loss: 111.7493, Valid loss: 119.2379\n",
      "Epoch [3/100], Step[1000]: Train loss: 112.0494, Valid loss: 119.2907\n",
      "Epoch [3/100], Step[1100]: Train loss: 124.5906, Valid loss: 119.0300\n",
      "Saving model with loss 119.030...\n",
      "Epoch [3/100], Step[1200]: Train loss: 126.9932, Valid loss: 119.3945\n",
      "Epoch [4/100], Step[1300]: Train loss: 105.8641, Valid loss: 119.0804\n",
      "Epoch [4/100], Step[1400]: Train loss: 140.3320, Valid loss: 119.4174\n",
      "Epoch [4/100], Step[1500]: Train loss: 117.0154, Valid loss: 118.8886\n",
      "Saving model with loss 118.889...\n",
      "Epoch [4/100], Step[1600]: Train loss: 122.2516, Valid loss: 119.5747\n",
      "Epoch [5/100], Step[1700]: Train loss: 119.8349, Valid loss: 119.3591\n",
      "Epoch [5/100], Step[1800]: Train loss: 122.5749, Valid loss: 118.9330\n",
      "Epoch [5/100], Step[1900]: Train loss: 122.6311, Valid loss: 119.6365\n",
      "Epoch [5/100], Step[2000]: Train loss: 135.5252, Valid loss: 119.1042\n",
      "Epoch [6/100], Step[2100]: Train loss: 130.4150, Valid loss: 119.1974\n",
      "Epoch [6/100], Step[2200]: Train loss: 130.6599, Valid loss: 119.4100\n",
      "Epoch [6/100], Step[2300]: Train loss: 124.4391, Valid loss: 119.2027\n",
      "Epoch [6/100], Step[2400]: Train loss: 120.7734, Valid loss: 119.1641\n",
      "Epoch [6/100], Step[2500]: Train loss: 124.4218, Valid loss: 119.5836\n",
      "Epoch [7/100], Step[2600]: Train loss: 123.4563, Valid loss: 119.3685\n",
      "Epoch [7/100], Step[2700]: Train loss: 130.9277, Valid loss: 119.4234\n",
      "Epoch [7/100], Step[2800]: Train loss: 112.1607, Valid loss: 118.9592\n",
      "Epoch [7/100], Step[2900]: Train loss: 107.4794, Valid loss: 119.0932\n",
      "Epoch [8/100], Step[3000]: Train loss: 110.1394, Valid loss: 119.5733\n",
      "Epoch [8/100], Step[3100]: Train loss: 123.6575, Valid loss: 119.4149\n",
      "Epoch [8/100], Step[3200]: Train loss: 119.7711, Valid loss: 119.5827\n",
      "Epoch [8/100], Step[3300]: Train loss: 121.4013, Valid loss: 119.2022\n",
      "Epoch [9/100], Step[3400]: Train loss: 124.9664, Valid loss: 119.2984\n",
      "Epoch [9/100], Step[3500]: Train loss: 123.9271, Valid loss: 119.2522\n",
      "Epoch [9/100], Step[3600]: Train loss: 125.6198, Valid loss: 119.4917\n",
      "Epoch [9/100], Step[3700]: Train loss: 125.0270, Valid loss: 118.9794\n",
      "Epoch [10/100], Step[3800]: Train loss: 101.8265, Valid loss: 118.9711\n",
      "Epoch [10/100], Step[3900]: Train loss: 115.4324, Valid loss: 119.4379\n",
      "Epoch [10/100], Step[4000]: Train loss: 138.3039, Valid loss: 119.1882\n",
      "Epoch [10/100], Step[4100]: Train loss: 116.9716, Valid loss: 119.3170\n",
      "Epoch [11/100], Step[4200]: Train loss: 96.4016, Valid loss: 119.1904\n",
      "Epoch [11/100], Step[4300]: Train loss: 110.7969, Valid loss: 119.6199\n",
      "Epoch [11/100], Step[4400]: Train loss: 124.1176, Valid loss: 119.1247\n",
      "Epoch [11/100], Step[4500]: Train loss: 140.7376, Valid loss: 119.1110\n",
      "Epoch [12/100], Step[4600]: Train loss: 119.6870, Valid loss: 119.3645\n",
      "Epoch [12/100], Step[4700]: Train loss: 136.8265, Valid loss: 119.3314\n",
      "Epoch [12/100], Step[4800]: Train loss: 113.7124, Valid loss: 118.9596\n",
      "Epoch [12/100], Step[4900]: Train loss: 112.7856, Valid loss: 119.3673\n",
      "Epoch [12/100], Step[5000]: Train loss: 125.5459, Valid loss: 119.2563\n",
      "Epoch [13/100], Step[5100]: Train loss: 116.2300, Valid loss: 119.2804\n",
      "Epoch [13/100], Step[5200]: Train loss: 130.7838, Valid loss: 119.0241\n",
      "Epoch [13/100], Step[5300]: Train loss: 111.9933, Valid loss: 119.3169\n",
      "Epoch [13/100], Step[5400]: Train loss: 115.7924, Valid loss: 119.1203\n",
      "Epoch [14/100], Step[5500]: Train loss: 118.4152, Valid loss: 118.9840\n",
      "Epoch [14/100], Step[5600]: Train loss: 117.3473, Valid loss: 119.0778\n",
      "Epoch [14/100], Step[5700]: Train loss: 129.2481, Valid loss: 119.5398\n",
      "Epoch [14/100], Step[5800]: Train loss: 133.6941, Valid loss: 119.3536\n",
      "Epoch [15/100], Step[5900]: Train loss: 118.8515, Valid loss: 119.1343\n",
      "Epoch [15/100], Step[6000]: Train loss: 124.6364, Valid loss: 119.4738\n",
      "Epoch [15/100], Step[6100]: Train loss: 110.8284, Valid loss: 119.2533\n",
      "Epoch [15/100], Step[6200]: Train loss: 109.1981, Valid loss: 119.5537\n",
      "Epoch [16/100], Step[6300]: Train loss: 116.7125, Valid loss: 119.1813\n",
      "Epoch [16/100], Step[6400]: Train loss: 110.5150, Valid loss: 119.3213\n",
      "Epoch [16/100], Step[6500]: Train loss: 125.0002, Valid loss: 119.3893\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 114.8615, Valid loss: 119.1461\n",
      "Saving model with loss 119.146...\n",
      "Epoch [1/100], Step[200]: Train loss: 136.2455, Valid loss: 119.1776\n",
      "Epoch [1/100], Step[300]: Train loss: 127.9649, Valid loss: 119.5877\n",
      "Epoch [1/100], Step[400]: Train loss: 133.1548, Valid loss: 119.6438\n",
      "Epoch [2/100], Step[500]: Train loss: 108.1118, Valid loss: 119.6918\n",
      "Epoch [2/100], Step[600]: Train loss: 122.8812, Valid loss: 119.3306\n",
      "Epoch [2/100], Step[700]: Train loss: 112.7080, Valid loss: 119.3944\n",
      "Epoch [2/100], Step[800]: Train loss: 123.4524, Valid loss: 119.3197\n",
      "Epoch [3/100], Step[900]: Train loss: 128.6702, Valid loss: 119.3986\n",
      "Epoch [3/100], Step[1000]: Train loss: 114.3852, Valid loss: 119.0114\n",
      "Saving model with loss 119.011...\n",
      "Epoch [3/100], Step[1100]: Train loss: 116.0741, Valid loss: 119.0442\n",
      "Epoch [3/100], Step[1200]: Train loss: 129.5309, Valid loss: 119.0395\n",
      "Epoch [4/100], Step[1300]: Train loss: 114.2548, Valid loss: 119.1192\n",
      "Epoch [4/100], Step[1400]: Train loss: 120.6784, Valid loss: 119.1953\n",
      "Epoch [4/100], Step[1500]: Train loss: 110.9529, Valid loss: 119.3759\n",
      "Epoch [4/100], Step[1600]: Train loss: 108.6786, Valid loss: 119.4177\n",
      "Epoch [5/100], Step[1700]: Train loss: 121.0436, Valid loss: 119.1459\n",
      "Epoch [5/100], Step[1800]: Train loss: 116.7143, Valid loss: 119.3587\n",
      "Epoch [5/100], Step[1900]: Train loss: 137.3430, Valid loss: 119.2605\n",
      "Epoch [5/100], Step[2000]: Train loss: 115.7161, Valid loss: 119.0136\n",
      "Epoch [6/100], Step[2100]: Train loss: 120.3385, Valid loss: 119.6023\n",
      "Epoch [6/100], Step[2200]: Train loss: 125.9845, Valid loss: 119.1962\n",
      "Epoch [6/100], Step[2300]: Train loss: 120.5424, Valid loss: 119.5510\n",
      "Epoch [6/100], Step[2400]: Train loss: 133.9621, Valid loss: 119.3465\n",
      "Epoch [6/100], Step[2500]: Train loss: 138.6036, Valid loss: 119.3254\n",
      "Epoch [7/100], Step[2600]: Train loss: 134.8216, Valid loss: 119.2310\n",
      "Epoch [7/100], Step[2700]: Train loss: 106.8949, Valid loss: 119.3665\n",
      "Epoch [7/100], Step[2800]: Train loss: 105.8544, Valid loss: 119.1482\n",
      "Epoch [7/100], Step[2900]: Train loss: 118.3908, Valid loss: 119.5016\n",
      "Epoch [8/100], Step[3000]: Train loss: 114.2077, Valid loss: 119.4541\n",
      "Epoch [8/100], Step[3100]: Train loss: 118.4210, Valid loss: 119.4520\n",
      "Epoch [8/100], Step[3200]: Train loss: 117.2703, Valid loss: 119.3149\n",
      "Epoch [8/100], Step[3300]: Train loss: 114.2478, Valid loss: 119.5304\n",
      "Epoch [9/100], Step[3400]: Train loss: 113.6956, Valid loss: 119.6639\n",
      "Epoch [9/100], Step[3500]: Train loss: 126.2267, Valid loss: 119.1396\n",
      "Epoch [9/100], Step[3600]: Train loss: 119.8489, Valid loss: 119.1275\n",
      "Epoch [9/100], Step[3700]: Train loss: 112.2318, Valid loss: 119.8047\n",
      "Epoch [10/100], Step[3800]: Train loss: 130.1009, Valid loss: 119.5985\n",
      "Epoch [10/100], Step[3900]: Train loss: 127.3613, Valid loss: 119.2861\n",
      "Epoch [10/100], Step[4000]: Train loss: 136.6605, Valid loss: 119.2211\n",
      "Epoch [10/100], Step[4100]: Train loss: 113.3222, Valid loss: 119.0725\n",
      "Epoch [11/100], Step[4200]: Train loss: 114.9788, Valid loss: 119.6842\n",
      "Epoch [11/100], Step[4300]: Train loss: 117.2535, Valid loss: 119.2268\n",
      "Epoch [11/100], Step[4400]: Train loss: 112.4401, Valid loss: 119.3027\n",
      "Epoch [11/100], Step[4500]: Train loss: 123.1398, Valid loss: 119.3560\n",
      "Epoch [12/100], Step[4600]: Train loss: 111.6935, Valid loss: 119.0531\n",
      "Epoch [12/100], Step[4700]: Train loss: 118.6135, Valid loss: 119.4655\n",
      "Epoch [12/100], Step[4800]: Train loss: 125.4375, Valid loss: 119.1635\n",
      "Epoch [12/100], Step[4900]: Train loss: 120.4181, Valid loss: 119.4711\n",
      "Epoch [12/100], Step[5000]: Train loss: 121.4742, Valid loss: 119.0714\n",
      "Epoch [13/100], Step[5100]: Train loss: 119.0862, Valid loss: 119.4948\n",
      "Epoch [13/100], Step[5200]: Train loss: 124.2478, Valid loss: 119.4376\n",
      "Epoch [13/100], Step[5300]: Train loss: 117.2704, Valid loss: 119.1868\n",
      "Epoch [13/100], Step[5400]: Train loss: 118.0718, Valid loss: 119.0855\n",
      "Epoch [14/100], Step[5500]: Train loss: 135.2291, Valid loss: 119.1834\n",
      "Epoch [14/100], Step[5600]: Train loss: 105.2364, Valid loss: 119.3033\n",
      "Epoch [14/100], Step[5700]: Train loss: 123.5348, Valid loss: 119.0130\n",
      "Epoch [14/100], Step[5800]: Train loss: 120.8237, Valid loss: 119.2445\n",
      "Epoch [15/100], Step[5900]: Train loss: 94.9284, Valid loss: 119.1831\n",
      "Epoch [15/100], Step[6000]: Train loss: 117.6136, Valid loss: 119.6016\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 121.5416, Valid loss: 119.4276\n",
      "Saving model with loss 119.428...\n",
      "Epoch [1/100], Step[200]: Train loss: 103.1789, Valid loss: 119.0837\n",
      "Saving model with loss 119.084...\n",
      "Epoch [1/100], Step[300]: Train loss: 102.7624, Valid loss: 118.9800\n",
      "Saving model with loss 118.980...\n",
      "Epoch [1/100], Step[400]: Train loss: 120.4068, Valid loss: 119.0059\n",
      "Epoch [2/100], Step[500]: Train loss: 110.9731, Valid loss: 119.1937\n",
      "Epoch [2/100], Step[600]: Train loss: 130.2221, Valid loss: 119.2954\n",
      "Epoch [2/100], Step[700]: Train loss: 116.5386, Valid loss: 119.1821\n",
      "Epoch [2/100], Step[800]: Train loss: 122.9732, Valid loss: 119.5598\n",
      "Epoch [3/100], Step[900]: Train loss: 110.0293, Valid loss: 119.4828\n",
      "Epoch [3/100], Step[1000]: Train loss: 110.8428, Valid loss: 119.0403\n",
      "Epoch [3/100], Step[1100]: Train loss: 112.9037, Valid loss: 119.3242\n",
      "Epoch [3/100], Step[1200]: Train loss: 131.2616, Valid loss: 119.1402\n",
      "Epoch [4/100], Step[1300]: Train loss: 133.3967, Valid loss: 118.9507\n",
      "Saving model with loss 118.951...\n",
      "Epoch [4/100], Step[1400]: Train loss: 113.4043, Valid loss: 119.2951\n",
      "Epoch [4/100], Step[1500]: Train loss: 112.0968, Valid loss: 119.5179\n",
      "Epoch [4/100], Step[1600]: Train loss: 125.3248, Valid loss: 118.9407\n",
      "Saving model with loss 118.941...\n",
      "Epoch [5/100], Step[1700]: Train loss: 116.9122, Valid loss: 119.2494\n",
      "Epoch [5/100], Step[1800]: Train loss: 123.8486, Valid loss: 119.4653\n",
      "Epoch [5/100], Step[1900]: Train loss: 118.3214, Valid loss: 119.3270\n",
      "Epoch [5/100], Step[2000]: Train loss: 107.2835, Valid loss: 119.3963\n",
      "Epoch [6/100], Step[2100]: Train loss: 113.7883, Valid loss: 119.3497\n",
      "Epoch [6/100], Step[2200]: Train loss: 114.1038, Valid loss: 119.4647\n",
      "Epoch [6/100], Step[2300]: Train loss: 117.3203, Valid loss: 119.5178\n",
      "Epoch [6/100], Step[2400]: Train loss: 113.2885, Valid loss: 119.2178\n",
      "Epoch [6/100], Step[2500]: Train loss: 115.8085, Valid loss: 119.1421\n",
      "Epoch [7/100], Step[2600]: Train loss: 134.5163, Valid loss: 119.5056\n",
      "Epoch [7/100], Step[2700]: Train loss: 113.6140, Valid loss: 119.2203\n",
      "Epoch [7/100], Step[2800]: Train loss: 133.0998, Valid loss: 119.3110\n",
      "Epoch [7/100], Step[2900]: Train loss: 113.9563, Valid loss: 119.0858\n",
      "Epoch [8/100], Step[3000]: Train loss: 110.5462, Valid loss: 119.2192\n",
      "Epoch [8/100], Step[3100]: Train loss: 121.4771, Valid loss: 118.8636\n",
      "Saving model with loss 118.864...\n",
      "Epoch [8/100], Step[3200]: Train loss: 113.6925, Valid loss: 119.3157\n",
      "Epoch [8/100], Step[3300]: Train loss: 112.7258, Valid loss: 119.0652\n",
      "Epoch [9/100], Step[3400]: Train loss: 118.3183, Valid loss: 119.1017\n",
      "Epoch [9/100], Step[3500]: Train loss: 110.0619, Valid loss: 118.9561\n",
      "Epoch [9/100], Step[3600]: Train loss: 104.5393, Valid loss: 119.0885\n",
      "Epoch [9/100], Step[3700]: Train loss: 119.1808, Valid loss: 119.1847\n",
      "Epoch [10/100], Step[3800]: Train loss: 112.9288, Valid loss: 118.9372\n",
      "Epoch [10/100], Step[3900]: Train loss: 102.1352, Valid loss: 119.0252\n",
      "Epoch [10/100], Step[4000]: Train loss: 123.8935, Valid loss: 119.1980\n",
      "Epoch [10/100], Step[4100]: Train loss: 110.7479, Valid loss: 119.1869\n",
      "Epoch [11/100], Step[4200]: Train loss: 124.0400, Valid loss: 119.0607\n",
      "Epoch [11/100], Step[4300]: Train loss: 111.9913, Valid loss: 119.0186\n",
      "Epoch [11/100], Step[4400]: Train loss: 123.0985, Valid loss: 119.2012\n",
      "Epoch [11/100], Step[4500]: Train loss: 114.9116, Valid loss: 119.4607\n",
      "Epoch [12/100], Step[4600]: Train loss: 112.8427, Valid loss: 119.3355\n",
      "Epoch [12/100], Step[4700]: Train loss: 117.5700, Valid loss: 119.5007\n",
      "Epoch [12/100], Step[4800]: Train loss: 125.6187, Valid loss: 119.1370\n",
      "Epoch [12/100], Step[4900]: Train loss: 114.6090, Valid loss: 119.1444\n",
      "Epoch [12/100], Step[5000]: Train loss: 103.2368, Valid loss: 119.0275\n",
      "Epoch [13/100], Step[5100]: Train loss: 123.7631, Valid loss: 119.2321\n",
      "Epoch [13/100], Step[5200]: Train loss: 112.6147, Valid loss: 119.6354\n",
      "Epoch [13/100], Step[5300]: Train loss: 125.0668, Valid loss: 119.5319\n",
      "Epoch [13/100], Step[5400]: Train loss: 124.7075, Valid loss: 119.4543\n",
      "Epoch [14/100], Step[5500]: Train loss: 120.2668, Valid loss: 119.0664\n",
      "Epoch [14/100], Step[5600]: Train loss: 129.0968, Valid loss: 119.6595\n",
      "Epoch [14/100], Step[5700]: Train loss: 111.2166, Valid loss: 119.2789\n",
      "Epoch [14/100], Step[5800]: Train loss: 118.4404, Valid loss: 118.9520\n",
      "Epoch [15/100], Step[5900]: Train loss: 108.1140, Valid loss: 119.1902\n",
      "Epoch [15/100], Step[6000]: Train loss: 124.0960, Valid loss: 119.3528\n",
      "Epoch [15/100], Step[6100]: Train loss: 117.9394, Valid loss: 119.6286\n",
      "Epoch [15/100], Step[6200]: Train loss: 125.4877, Valid loss: 119.0876\n",
      "Epoch [16/100], Step[6300]: Train loss: 137.1602, Valid loss: 119.1891\n",
      "Epoch [16/100], Step[6400]: Train loss: 111.1541, Valid loss: 119.5105\n",
      "Epoch [16/100], Step[6500]: Train loss: 112.8738, Valid loss: 119.3740\n",
      "Epoch [16/100], Step[6600]: Train loss: 109.8058, Valid loss: 119.0837\n",
      "Epoch [17/100], Step[6700]: Train loss: 126.3824, Valid loss: 119.3700\n",
      "Epoch [17/100], Step[6800]: Train loss: 137.3845, Valid loss: 119.0104\n",
      "Epoch [17/100], Step[6900]: Train loss: 108.4838, Valid loss: 119.4163\n",
      "Epoch [17/100], Step[7000]: Train loss: 119.5798, Valid loss: 119.3062\n",
      "Epoch [17/100], Step[7100]: Train loss: 121.2626, Valid loss: 119.0242\n",
      "Epoch [18/100], Step[7200]: Train loss: 132.2785, Valid loss: 119.2999\n",
      "Epoch [18/100], Step[7300]: Train loss: 112.5639, Valid loss: 119.2689\n",
      "Epoch [18/100], Step[7400]: Train loss: 137.9230, Valid loss: 119.1301\n",
      "Epoch [18/100], Step[7500]: Train loss: 128.8421, Valid loss: 119.3706\n",
      "Epoch [19/100], Step[7600]: Train loss: 116.5040, Valid loss: 119.0156\n",
      "Epoch [19/100], Step[7700]: Train loss: 125.8120, Valid loss: 119.1225\n",
      "Epoch [19/100], Step[7800]: Train loss: 131.9167, Valid loss: 119.3406\n",
      "Epoch [19/100], Step[7900]: Train loss: 111.7963, Valid loss: 119.1459\n",
      "Epoch [20/100], Step[8000]: Train loss: 129.4698, Valid loss: 119.3324\n",
      "Epoch [20/100], Step[8100]: Train loss: 123.7264, Valid loss: 119.4966\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 114.8460, Valid loss: 119.4570\n",
      "Saving model with loss 119.457...\n",
      "Epoch [1/100], Step[200]: Train loss: 110.7830, Valid loss: 119.2419\n",
      "Saving model with loss 119.242...\n",
      "Epoch [1/100], Step[300]: Train loss: 121.0127, Valid loss: 119.1234\n",
      "Saving model with loss 119.123...\n",
      "Epoch [1/100], Step[400]: Train loss: 139.6111, Valid loss: 119.3124\n",
      "Epoch [2/100], Step[500]: Train loss: 121.3620, Valid loss: 119.3379\n",
      "Epoch [2/100], Step[600]: Train loss: 138.3382, Valid loss: 119.2420\n",
      "Epoch [2/100], Step[700]: Train loss: 129.0894, Valid loss: 119.0628\n",
      "Saving model with loss 119.063...\n",
      "Epoch [2/100], Step[800]: Train loss: 119.6306, Valid loss: 119.2599\n",
      "Epoch [3/100], Step[900]: Train loss: 119.0055, Valid loss: 119.2602\n",
      "Epoch [3/100], Step[1000]: Train loss: 126.2962, Valid loss: 118.9480\n",
      "Saving model with loss 118.948...\n",
      "Epoch [3/100], Step[1100]: Train loss: 129.9549, Valid loss: 119.2413\n",
      "Epoch [3/100], Step[1200]: Train loss: 127.5460, Valid loss: 119.3796\n",
      "Epoch [4/100], Step[1300]: Train loss: 112.1052, Valid loss: 119.1410\n",
      "Epoch [4/100], Step[1400]: Train loss: 118.9482, Valid loss: 119.4457\n",
      "Epoch [4/100], Step[1500]: Train loss: 116.2019, Valid loss: 119.2485\n",
      "Epoch [4/100], Step[1600]: Train loss: 121.9630, Valid loss: 119.4495\n",
      "Epoch [5/100], Step[1700]: Train loss: 136.7914, Valid loss: 119.4754\n",
      "Epoch [5/100], Step[1800]: Train loss: 123.6776, Valid loss: 119.5974\n",
      "Epoch [5/100], Step[1900]: Train loss: 120.3773, Valid loss: 119.0072\n",
      "Epoch [5/100], Step[2000]: Train loss: 109.4741, Valid loss: 119.2688\n",
      "Epoch [6/100], Step[2100]: Train loss: 121.9182, Valid loss: 119.2588\n",
      "Epoch [6/100], Step[2200]: Train loss: 103.8751, Valid loss: 119.0709\n",
      "Epoch [6/100], Step[2300]: Train loss: 113.8267, Valid loss: 119.2791\n",
      "Epoch [6/100], Step[2400]: Train loss: 106.7210, Valid loss: 119.3634\n",
      "Epoch [6/100], Step[2500]: Train loss: 118.4093, Valid loss: 119.5790\n",
      "Epoch [7/100], Step[2600]: Train loss: 106.6929, Valid loss: 118.9709\n",
      "Epoch [7/100], Step[2700]: Train loss: 128.0508, Valid loss: 119.2982\n",
      "Epoch [7/100], Step[2800]: Train loss: 115.4261, Valid loss: 119.4812\n",
      "Epoch [7/100], Step[2900]: Train loss: 125.5890, Valid loss: 119.1877\n",
      "Epoch [8/100], Step[3000]: Train loss: 121.1731, Valid loss: 118.9513\n",
      "Epoch [8/100], Step[3100]: Train loss: 112.2711, Valid loss: 119.1850\n",
      "Epoch [8/100], Step[3200]: Train loss: 118.2283, Valid loss: 119.0082\n",
      "Epoch [8/100], Step[3300]: Train loss: 100.3828, Valid loss: 119.5512\n",
      "Epoch [9/100], Step[3400]: Train loss: 134.3576, Valid loss: 119.3158\n",
      "Epoch [9/100], Step[3500]: Train loss: 111.5164, Valid loss: 119.3329\n",
      "Epoch [9/100], Step[3600]: Train loss: 116.8800, Valid loss: 118.9468\n",
      "Saving model with loss 118.947...\n",
      "Epoch [9/100], Step[3700]: Train loss: 130.2641, Valid loss: 119.3062\n",
      "Epoch [10/100], Step[3800]: Train loss: 120.9962, Valid loss: 119.1327\n",
      "Epoch [10/100], Step[3900]: Train loss: 136.2734, Valid loss: 118.9993\n",
      "Epoch [10/100], Step[4000]: Train loss: 129.0202, Valid loss: 119.0655\n",
      "Epoch [10/100], Step[4100]: Train loss: 105.1919, Valid loss: 119.2146\n",
      "Epoch [11/100], Step[4200]: Train loss: 127.7957, Valid loss: 119.1862\n",
      "Epoch [11/100], Step[4300]: Train loss: 129.4344, Valid loss: 119.6053\n",
      "Epoch [11/100], Step[4400]: Train loss: 117.2070, Valid loss: 119.0791\n",
      "Epoch [11/100], Step[4500]: Train loss: 139.5900, Valid loss: 119.0382\n",
      "Epoch [12/100], Step[4600]: Train loss: 116.3598, Valid loss: 119.2383\n",
      "Epoch [12/100], Step[4700]: Train loss: 133.5764, Valid loss: 119.0739\n",
      "Epoch [12/100], Step[4800]: Train loss: 131.5705, Valid loss: 119.1391\n",
      "Epoch [12/100], Step[4900]: Train loss: 114.5612, Valid loss: 119.2439\n",
      "Epoch [12/100], Step[5000]: Train loss: 121.4832, Valid loss: 119.1743\n",
      "Epoch [13/100], Step[5100]: Train loss: 119.0806, Valid loss: 119.3433\n",
      "Epoch [13/100], Step[5200]: Train loss: 124.8362, Valid loss: 118.9820\n",
      "Epoch [13/100], Step[5300]: Train loss: 131.6412, Valid loss: 118.9989\n",
      "Epoch [13/100], Step[5400]: Train loss: 116.9645, Valid loss: 119.2065\n",
      "Epoch [14/100], Step[5500]: Train loss: 104.5209, Valid loss: 119.3206\n",
      "Epoch [14/100], Step[5600]: Train loss: 107.7151, Valid loss: 119.6528\n",
      "Epoch [14/100], Step[5700]: Train loss: 118.2604, Valid loss: 119.3487\n",
      "Epoch [14/100], Step[5800]: Train loss: 111.8007, Valid loss: 119.4110\n",
      "Epoch [15/100], Step[5900]: Train loss: 115.9154, Valid loss: 119.2113\n",
      "Epoch [15/100], Step[6000]: Train loss: 121.2223, Valid loss: 119.1507\n",
      "Epoch [15/100], Step[6100]: Train loss: 122.9209, Valid loss: 119.0386\n",
      "Epoch [15/100], Step[6200]: Train loss: 108.2829, Valid loss: 119.2005\n",
      "Epoch [16/100], Step[6300]: Train loss: 123.0954, Valid loss: 119.2386\n",
      "Epoch [16/100], Step[6400]: Train loss: 127.4685, Valid loss: 119.1632\n",
      "Epoch [16/100], Step[6500]: Train loss: 112.3274, Valid loss: 118.9899\n",
      "Epoch [16/100], Step[6600]: Train loss: 117.8524, Valid loss: 119.2168\n",
      "Epoch [17/100], Step[6700]: Train loss: 123.6693, Valid loss: 119.3782\n",
      "Epoch [17/100], Step[6800]: Train loss: 100.0055, Valid loss: 119.2437\n",
      "Epoch [17/100], Step[6900]: Train loss: 122.6034, Valid loss: 119.1698\n",
      "Epoch [17/100], Step[7000]: Train loss: 121.0887, Valid loss: 119.1676\n",
      "Epoch [17/100], Step[7100]: Train loss: 120.1698, Valid loss: 119.2915\n",
      "Epoch [18/100], Step[7200]: Train loss: 119.0364, Valid loss: 119.1373\n",
      "Epoch [18/100], Step[7300]: Train loss: 123.1044, Valid loss: 119.1715\n",
      "Epoch [18/100], Step[7400]: Train loss: 118.9357, Valid loss: 119.2740\n",
      "Epoch [18/100], Step[7500]: Train loss: 119.5978, Valid loss: 119.1406\n",
      "Epoch [19/100], Step[7600]: Train loss: 130.1017, Valid loss: 119.2505\n",
      "Epoch [19/100], Step[7700]: Train loss: 111.2750, Valid loss: 119.4877\n",
      "Epoch [19/100], Step[7800]: Train loss: 106.0468, Valid loss: 119.4467\n",
      "Epoch [19/100], Step[7900]: Train loss: 112.8955, Valid loss: 119.4361\n",
      "Epoch [20/100], Step[8000]: Train loss: 129.8980, Valid loss: 119.2833\n",
      "Epoch [20/100], Step[8100]: Train loss: 113.1868, Valid loss: 119.4836\n",
      "Epoch [20/100], Step[8200]: Train loss: 120.6378, Valid loss: 119.0975\n",
      "Epoch [20/100], Step[8300]: Train loss: 128.5314, Valid loss: 119.0582\n",
      "Epoch [21/100], Step[8400]: Train loss: 138.2709, Valid loss: 119.2522\n",
      "Epoch [21/100], Step[8500]: Train loss: 122.5663, Valid loss: 119.5184\n",
      "Epoch [21/100], Step[8600]: Train loss: 116.7766, Valid loss: 119.0883\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 99.4622, Valid loss: 119.2223\n",
      "Saving model with loss 119.222...\n",
      "Epoch [1/100], Step[200]: Train loss: 160.8096, Valid loss: 119.2403\n",
      "Epoch [1/100], Step[300]: Train loss: 128.5848, Valid loss: 119.2529\n",
      "Epoch [1/100], Step[400]: Train loss: 121.9399, Valid loss: 118.8784\n",
      "Saving model with loss 118.878...\n",
      "Epoch [2/100], Step[500]: Train loss: 125.8283, Valid loss: 119.1823\n",
      "Epoch [2/100], Step[600]: Train loss: 124.7726, Valid loss: 119.4050\n",
      "Epoch [2/100], Step[700]: Train loss: 118.5856, Valid loss: 119.2062\n",
      "Epoch [2/100], Step[800]: Train loss: 117.0728, Valid loss: 119.4320\n",
      "Epoch [3/100], Step[900]: Train loss: 134.9858, Valid loss: 118.9182\n",
      "Epoch [3/100], Step[1000]: Train loss: 124.8550, Valid loss: 119.1663\n",
      "Epoch [3/100], Step[1100]: Train loss: 126.8838, Valid loss: 119.1334\n",
      "Epoch [3/100], Step[1200]: Train loss: 117.6358, Valid loss: 119.5071\n",
      "Epoch [4/100], Step[1300]: Train loss: 105.0887, Valid loss: 119.2005\n",
      "Epoch [4/100], Step[1400]: Train loss: 122.8649, Valid loss: 119.1591\n",
      "Epoch [4/100], Step[1500]: Train loss: 119.1855, Valid loss: 119.1922\n",
      "Epoch [4/100], Step[1600]: Train loss: 127.2943, Valid loss: 119.3176\n",
      "Epoch [5/100], Step[1700]: Train loss: 129.6874, Valid loss: 119.1974\n",
      "Epoch [5/100], Step[1800]: Train loss: 125.3606, Valid loss: 119.1912\n",
      "Epoch [5/100], Step[1900]: Train loss: 125.9589, Valid loss: 119.2769\n",
      "Epoch [5/100], Step[2000]: Train loss: 107.3892, Valid loss: 119.3188\n",
      "Epoch [6/100], Step[2100]: Train loss: 129.8828, Valid loss: 119.5411\n",
      "Epoch [6/100], Step[2200]: Train loss: 138.4164, Valid loss: 119.3662\n",
      "Epoch [6/100], Step[2300]: Train loss: 133.1013, Valid loss: 119.1568\n",
      "Epoch [6/100], Step[2400]: Train loss: 117.2936, Valid loss: 118.9635\n",
      "Epoch [6/100], Step[2500]: Train loss: 126.7855, Valid loss: 119.5443\n",
      "Epoch [7/100], Step[2600]: Train loss: 120.4815, Valid loss: 119.5286\n",
      "Epoch [7/100], Step[2700]: Train loss: 132.1398, Valid loss: 119.4249\n",
      "Epoch [7/100], Step[2800]: Train loss: 114.7195, Valid loss: 119.2792\n",
      "Epoch [7/100], Step[2900]: Train loss: 116.0613, Valid loss: 119.6199\n",
      "Epoch [8/100], Step[3000]: Train loss: 112.7312, Valid loss: 118.8973\n",
      "Epoch [8/100], Step[3100]: Train loss: 118.3023, Valid loss: 119.4068\n",
      "Epoch [8/100], Step[3200]: Train loss: 123.3806, Valid loss: 119.2828\n",
      "Epoch [8/100], Step[3300]: Train loss: 141.1809, Valid loss: 119.4639\n",
      "Epoch [9/100], Step[3400]: Train loss: 110.4701, Valid loss: 119.2678\n",
      "Epoch [9/100], Step[3500]: Train loss: 110.5637, Valid loss: 119.2115\n",
      "Epoch [9/100], Step[3600]: Train loss: 110.8958, Valid loss: 119.1411\n",
      "Epoch [9/100], Step[3700]: Train loss: 139.9718, Valid loss: 119.1892\n",
      "Epoch [10/100], Step[3800]: Train loss: 121.4635, Valid loss: 119.3864\n",
      "Epoch [10/100], Step[3900]: Train loss: 128.1703, Valid loss: 119.3771\n",
      "Epoch [10/100], Step[4000]: Train loss: 112.1845, Valid loss: 119.3800\n",
      "Epoch [10/100], Step[4100]: Train loss: 112.4425, Valid loss: 119.1360\n",
      "Epoch [11/100], Step[4200]: Train loss: 130.2730, Valid loss: 119.1499\n",
      "Epoch [11/100], Step[4300]: Train loss: 114.3321, Valid loss: 119.0329\n",
      "Epoch [11/100], Step[4400]: Train loss: 118.1623, Valid loss: 119.1673\n",
      "Epoch [11/100], Step[4500]: Train loss: 129.6092, Valid loss: 119.1128\n",
      "Epoch [12/100], Step[4600]: Train loss: 123.2509, Valid loss: 119.3558\n",
      "Epoch [12/100], Step[4700]: Train loss: 117.3845, Valid loss: 119.4028\n",
      "Epoch [12/100], Step[4800]: Train loss: 108.7248, Valid loss: 119.3081\n",
      "Epoch [12/100], Step[4900]: Train loss: 119.4249, Valid loss: 119.4484\n",
      "Epoch [12/100], Step[5000]: Train loss: 111.6501, Valid loss: 119.4526\n",
      "Epoch [13/100], Step[5100]: Train loss: 123.8508, Valid loss: 119.1828\n",
      "Epoch [13/100], Step[5200]: Train loss: 111.1559, Valid loss: 119.3804\n",
      "Epoch [13/100], Step[5300]: Train loss: 114.2690, Valid loss: 118.9525\n",
      "Epoch [13/100], Step[5400]: Train loss: 113.0014, Valid loss: 119.0760\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "h_arr = []\n",
    "wd_arr = []\n",
    "test_RMSE_arr = []\n",
    "for h in [45,90,180]:\n",
    "    for wd in [0.1, 0.2, 0.4]:\n",
    "        # config\n",
    "        device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        config = {\n",
    "            'H': h,\n",
    "            'optimizer': \"SGD\",\n",
    "            'weight_decay': wd,\n",
    "            'n_epochs': 100,     # Number of epochs.            \n",
    "            'learning_rate': 0.00001,              \n",
    "            'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "            'save_path': './models/model' + '4_' + str(h) + \"_\" + str(wd) + '.ckpt'  # Your model will be saved here.\n",
    "        }\n",
    "\n",
    "        # training\n",
    "        model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "        step_arr = []\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        trainer(train_loader, valid_loader, model, config, device)\n",
    "        \n",
    "        # testing\n",
    "        model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "        model.load_state_dict(torch.load(config['save_path']))\n",
    "        preds = predict(test_loader, model, device)\n",
    "        test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "        \n",
    "        # append to array\n",
    "        h_arr.append(h)\n",
    "        wd_arr.append(wd)\n",
    "        test_RMSE_arr.append(test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c51abd3c-f5f8-45c5-81a4-b5bef1af535c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.850842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.852477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.854154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.853562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.852452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.852136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.851992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.851075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>180</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.852359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H  Weight Decay  test RMSE\n",
       "0   45           0.1  10.850842\n",
       "1   45           0.2  10.852477\n",
       "2   45           0.4  10.854154\n",
       "3   90           0.1  10.853562\n",
       "4   90           0.2  10.852452\n",
       "5   90           0.4  10.852136\n",
       "6  180           0.1  10.851992\n",
       "7  180           0.2  10.851075\n",
       "8  180           0.4  10.852359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"H\": h_arr,\n",
    "       \"Weight Decay\": wd_arr,\n",
    "       \"test RMSE\": test_RMSE_arr}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019ab91-73aa-4a30-acbc-29ed13b18916",
   "metadata": {},
   "source": [
    "According to the chart above, we should pick H = 45 with low weight decay. However, all of them have very similar test RMSE, which implies the optimization is not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54ce6b-b648-4221-9f30-c6fccfd4f5d3",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6318c2f-621e-4a27-aa77-b6ed95853e32",
   "metadata": {
    "id": "Qn97_WvvrEkG"
   },
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        H = config['H']\n",
    "        D_in = input_dim\n",
    "        D_out = 1\n",
    "        self.layers = nn.Sequential(\n",
    "            # Layer 1\n",
    "            torch.nn.Linear(D_in, H),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            # Layer 2\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            # Layer 3\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            # Layer 4\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            # Output Layer\n",
    "            torch.nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cd4620e-a518-411c-8c61-3dbd449793e7",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 88.5691, Valid loss: 88.5393\n",
      "Saving model with loss 88.539...\n",
      "Epoch [1/100], Step[200]: Train loss: 94.4283, Valid loss: 82.5569\n",
      "Saving model with loss 82.557...\n",
      "Epoch [1/100], Step[300]: Train loss: 83.7328, Valid loss: 80.7486\n",
      "Saving model with loss 80.749...\n",
      "Epoch [1/100], Step[400]: Train loss: 88.9798, Valid loss: 80.2941\n",
      "Saving model with loss 80.294...\n",
      "Epoch [2/100], Step[500]: Train loss: 80.3855, Valid loss: 78.5708\n",
      "Saving model with loss 78.571...\n",
      "Epoch [2/100], Step[600]: Train loss: 81.4339, Valid loss: 78.7190\n",
      "Epoch [2/100], Step[700]: Train loss: 94.8027, Valid loss: 78.2034\n",
      "Saving model with loss 78.203...\n",
      "Epoch [2/100], Step[800]: Train loss: 78.3812, Valid loss: 77.5149\n",
      "Saving model with loss 77.515...\n",
      "Epoch [3/100], Step[900]: Train loss: 83.4298, Valid loss: 77.2824\n",
      "Saving model with loss 77.282...\n",
      "Epoch [3/100], Step[1000]: Train loss: 88.2018, Valid loss: 77.2720\n",
      "Saving model with loss 77.272...\n",
      "Epoch [3/100], Step[1100]: Train loss: 87.6373, Valid loss: 77.0504\n",
      "Saving model with loss 77.050...\n",
      "Epoch [3/100], Step[1200]: Train loss: 80.7257, Valid loss: 76.8307\n",
      "Saving model with loss 76.831...\n",
      "Epoch [4/100], Step[1300]: Train loss: 78.2081, Valid loss: 76.9987\n",
      "Epoch [4/100], Step[1400]: Train loss: 80.7903, Valid loss: 76.4957\n",
      "Saving model with loss 76.496...\n",
      "Epoch [4/100], Step[1500]: Train loss: 77.8013, Valid loss: 76.5470\n",
      "Epoch [4/100], Step[1600]: Train loss: 76.4705, Valid loss: 76.1610\n",
      "Saving model with loss 76.161...\n",
      "Epoch [5/100], Step[1700]: Train loss: 81.6177, Valid loss: 76.2794\n",
      "Epoch [5/100], Step[1800]: Train loss: 82.7333, Valid loss: 76.1555\n",
      "Saving model with loss 76.155...\n",
      "Epoch [5/100], Step[1900]: Train loss: 78.4794, Valid loss: 76.3056\n",
      "Epoch [5/100], Step[2000]: Train loss: 86.5341, Valid loss: 75.8251\n",
      "Saving model with loss 75.825...\n",
      "Epoch [6/100], Step[2100]: Train loss: 84.6367, Valid loss: 75.7512\n",
      "Saving model with loss 75.751...\n",
      "Epoch [6/100], Step[2200]: Train loss: 89.9538, Valid loss: 75.9173\n",
      "Epoch [6/100], Step[2300]: Train loss: 71.8130, Valid loss: 75.8715\n",
      "Epoch [6/100], Step[2400]: Train loss: 76.1108, Valid loss: 75.8286\n",
      "Epoch [6/100], Step[2500]: Train loss: 85.3737, Valid loss: 76.0163\n",
      "Epoch [7/100], Step[2600]: Train loss: 73.8014, Valid loss: 75.6555\n",
      "Saving model with loss 75.655...\n",
      "Epoch [7/100], Step[2700]: Train loss: 77.8515, Valid loss: 75.9678\n",
      "Epoch [7/100], Step[2800]: Train loss: 90.8787, Valid loss: 75.3760\n",
      "Saving model with loss 75.376...\n",
      "Epoch [7/100], Step[2900]: Train loss: 87.3710, Valid loss: 75.3301\n",
      "Saving model with loss 75.330...\n",
      "Epoch [8/100], Step[3000]: Train loss: 99.1851, Valid loss: 75.8279\n",
      "Epoch [8/100], Step[3100]: Train loss: 80.7568, Valid loss: 75.5346\n",
      "Epoch [8/100], Step[3200]: Train loss: 74.1278, Valid loss: 75.4220\n",
      "Epoch [8/100], Step[3300]: Train loss: 78.6038, Valid loss: 75.2915\n",
      "Saving model with loss 75.292...\n",
      "Epoch [9/100], Step[3400]: Train loss: 80.6552, Valid loss: 74.9598\n",
      "Saving model with loss 74.960...\n",
      "Epoch [9/100], Step[3500]: Train loss: 88.9292, Valid loss: 75.3733\n",
      "Epoch [9/100], Step[3600]: Train loss: 78.1549, Valid loss: 75.3871\n",
      "Epoch [9/100], Step[3700]: Train loss: 84.0125, Valid loss: 75.0914\n",
      "Epoch [10/100], Step[3800]: Train loss: 77.9176, Valid loss: 74.9249\n",
      "Saving model with loss 74.925...\n",
      "Epoch [10/100], Step[3900]: Train loss: 85.9043, Valid loss: 75.0565\n",
      "Epoch [10/100], Step[4000]: Train loss: 72.5640, Valid loss: 75.0060\n",
      "Epoch [10/100], Step[4100]: Train loss: 68.7416, Valid loss: 75.4314\n",
      "Epoch [11/100], Step[4200]: Train loss: 75.9124, Valid loss: 75.1161\n",
      "Epoch [11/100], Step[4300]: Train loss: 77.2409, Valid loss: 75.0913\n",
      "Epoch [11/100], Step[4400]: Train loss: 68.0511, Valid loss: 74.6735\n",
      "Saving model with loss 74.673...\n",
      "Epoch [11/100], Step[4500]: Train loss: 81.5294, Valid loss: 75.1337\n",
      "Epoch [12/100], Step[4600]: Train loss: 82.4659, Valid loss: 75.0056\n",
      "Epoch [12/100], Step[4700]: Train loss: 87.9268, Valid loss: 74.8075\n",
      "Epoch [12/100], Step[4800]: Train loss: 72.7308, Valid loss: 75.0773\n",
      "Epoch [12/100], Step[4900]: Train loss: 74.4139, Valid loss: 74.7163\n",
      "Epoch [12/100], Step[5000]: Train loss: 80.0018, Valid loss: 74.5890\n",
      "Saving model with loss 74.589...\n",
      "Epoch [13/100], Step[5100]: Train loss: 70.4004, Valid loss: 75.1169\n",
      "Epoch [13/100], Step[5200]: Train loss: 83.1652, Valid loss: 74.7799\n",
      "Epoch [13/100], Step[5300]: Train loss: 69.3417, Valid loss: 74.6460\n",
      "Epoch [13/100], Step[5400]: Train loss: 79.2965, Valid loss: 74.7356\n",
      "Epoch [14/100], Step[5500]: Train loss: 83.7242, Valid loss: 74.7986\n",
      "Epoch [14/100], Step[5600]: Train loss: 79.7948, Valid loss: 74.9415\n",
      "Epoch [14/100], Step[5700]: Train loss: 78.7544, Valid loss: 74.8689\n",
      "Epoch [14/100], Step[5800]: Train loss: 76.6946, Valid loss: 74.9896\n",
      "Epoch [15/100], Step[5900]: Train loss: 80.3131, Valid loss: 74.6154\n",
      "Epoch [15/100], Step[6000]: Train loss: 91.8515, Valid loss: 74.5913\n",
      "Epoch [15/100], Step[6100]: Train loss: 75.6809, Valid loss: 74.5847\n",
      "Saving model with loss 74.585...\n",
      "Epoch [15/100], Step[6200]: Train loss: 87.4551, Valid loss: 74.7366\n",
      "Epoch [16/100], Step[6300]: Train loss: 84.0390, Valid loss: 74.6726\n",
      "Epoch [16/100], Step[6400]: Train loss: 74.8085, Valid loss: 75.7662\n",
      "Epoch [16/100], Step[6500]: Train loss: 72.8702, Valid loss: 74.2086\n",
      "Saving model with loss 74.209...\n",
      "Epoch [16/100], Step[6600]: Train loss: 81.0826, Valid loss: 74.3361\n",
      "Epoch [17/100], Step[6700]: Train loss: 86.4014, Valid loss: 74.5375\n",
      "Epoch [17/100], Step[6800]: Train loss: 71.5878, Valid loss: 74.4277\n",
      "Epoch [17/100], Step[6900]: Train loss: 73.3234, Valid loss: 74.6321\n",
      "Epoch [17/100], Step[7000]: Train loss: 82.6067, Valid loss: 74.3177\n",
      "Epoch [17/100], Step[7100]: Train loss: 78.0546, Valid loss: 74.3807\n",
      "Epoch [18/100], Step[7200]: Train loss: 59.4543, Valid loss: 74.7723\n",
      "Epoch [18/100], Step[7300]: Train loss: 80.6344, Valid loss: 74.3776\n",
      "Epoch [18/100], Step[7400]: Train loss: 84.6651, Valid loss: 75.1303\n",
      "Epoch [18/100], Step[7500]: Train loss: 83.1812, Valid loss: 74.2530\n",
      "Epoch [19/100], Step[7600]: Train loss: 77.4946, Valid loss: 74.3410\n",
      "Epoch [19/100], Step[7700]: Train loss: 71.3012, Valid loss: 74.9012\n",
      "Epoch [19/100], Step[7800]: Train loss: 75.8245, Valid loss: 74.2352\n",
      "Epoch [19/100], Step[7900]: Train loss: 81.0199, Valid loss: 74.6553\n",
      "Epoch [20/100], Step[8000]: Train loss: 87.5142, Valid loss: 74.5001\n",
      "Epoch [20/100], Step[8100]: Train loss: 79.9530, Valid loss: 74.3661\n",
      "Epoch [20/100], Step[8200]: Train loss: 79.2263, Valid loss: 74.3174\n",
      "Epoch [20/100], Step[8300]: Train loss: 70.9479, Valid loss: 74.2793\n",
      "Epoch [21/100], Step[8400]: Train loss: 76.1280, Valid loss: 74.5235\n",
      "Epoch [21/100], Step[8500]: Train loss: 72.5368, Valid loss: 74.2593\n",
      "Epoch [21/100], Step[8600]: Train loss: 80.0795, Valid loss: 74.4936\n",
      "Epoch [21/100], Step[8700]: Train loss: 81.9075, Valid loss: 74.4556\n",
      "Epoch [22/100], Step[8800]: Train loss: 65.5443, Valid loss: 74.3137\n",
      "Epoch [22/100], Step[8900]: Train loss: 76.2606, Valid loss: 74.4826\n",
      "Epoch [22/100], Step[9000]: Train loss: 91.8358, Valid loss: 74.1285\n",
      "Saving model with loss 74.128...\n",
      "Epoch [22/100], Step[9100]: Train loss: 86.8959, Valid loss: 74.6192\n",
      "Epoch [23/100], Step[9200]: Train loss: 76.4402, Valid loss: 74.8063\n",
      "Epoch [23/100], Step[9300]: Train loss: 78.8940, Valid loss: 74.6257\n",
      "Epoch [23/100], Step[9400]: Train loss: 79.2358, Valid loss: 74.1923\n",
      "Epoch [23/100], Step[9500]: Train loss: 90.4898, Valid loss: 74.3848\n",
      "Epoch [23/100], Step[9600]: Train loss: 84.5563, Valid loss: 74.2608\n",
      "Epoch [24/100], Step[9700]: Train loss: 73.0934, Valid loss: 74.5120\n",
      "Epoch [24/100], Step[9800]: Train loss: 79.6429, Valid loss: 74.4448\n",
      "Epoch [24/100], Step[9900]: Train loss: 81.7245, Valid loss: 74.8345\n",
      "Epoch [24/100], Step[10000]: Train loss: 77.7619, Valid loss: 74.2212\n",
      "Epoch [25/100], Step[10100]: Train loss: 72.8648, Valid loss: 74.1423\n",
      "Epoch [25/100], Step[10200]: Train loss: 83.0651, Valid loss: 74.0690\n",
      "Saving model with loss 74.069...\n",
      "Epoch [25/100], Step[10300]: Train loss: 76.4157, Valid loss: 74.5897\n",
      "Epoch [25/100], Step[10400]: Train loss: 75.4936, Valid loss: 74.8815\n",
      "Epoch [26/100], Step[10500]: Train loss: 74.4515, Valid loss: 74.2143\n",
      "Epoch [26/100], Step[10600]: Train loss: 67.9803, Valid loss: 74.3726\n",
      "Epoch [26/100], Step[10700]: Train loss: 74.8383, Valid loss: 74.5860\n",
      "Epoch [26/100], Step[10800]: Train loss: 71.0388, Valid loss: 74.1426\n",
      "Epoch [27/100], Step[10900]: Train loss: 81.5336, Valid loss: 74.3826\n",
      "Epoch [27/100], Step[11000]: Train loss: 74.8340, Valid loss: 74.4336\n",
      "Epoch [27/100], Step[11100]: Train loss: 77.3331, Valid loss: 74.4795\n",
      "Epoch [27/100], Step[11200]: Train loss: 76.2629, Valid loss: 74.5262\n",
      "Epoch [28/100], Step[11300]: Train loss: 82.0580, Valid loss: 74.3558\n",
      "Epoch [28/100], Step[11400]: Train loss: 73.2824, Valid loss: 74.1326\n",
      "Epoch [28/100], Step[11500]: Train loss: 84.9240, Valid loss: 74.2734\n",
      "Epoch [28/100], Step[11600]: Train loss: 71.9557, Valid loss: 74.0089\n",
      "Saving model with loss 74.009...\n",
      "Epoch [28/100], Step[11700]: Train loss: 76.2938, Valid loss: 74.2491\n",
      "Epoch [29/100], Step[11800]: Train loss: 77.2933, Valid loss: 74.2608\n",
      "Epoch [29/100], Step[11900]: Train loss: 71.5816, Valid loss: 74.2592\n",
      "Epoch [29/100], Step[12000]: Train loss: 84.5976, Valid loss: 74.0192\n",
      "Epoch [29/100], Step[12100]: Train loss: 80.8331, Valid loss: 74.2058\n",
      "Epoch [30/100], Step[12200]: Train loss: 69.0956, Valid loss: 73.9232\n",
      "Saving model with loss 73.923...\n",
      "Epoch [30/100], Step[12300]: Train loss: 82.6627, Valid loss: 74.4507\n",
      "Epoch [30/100], Step[12400]: Train loss: 75.1478, Valid loss: 74.0305\n",
      "Epoch [30/100], Step[12500]: Train loss: 79.5900, Valid loss: 74.0864\n",
      "Epoch [31/100], Step[12600]: Train loss: 77.6954, Valid loss: 74.0139\n",
      "Epoch [31/100], Step[12700]: Train loss: 85.9464, Valid loss: 74.0818\n",
      "Epoch [31/100], Step[12800]: Train loss: 73.7035, Valid loss: 74.6106\n",
      "Epoch [31/100], Step[12900]: Train loss: 78.2544, Valid loss: 74.4579\n",
      "Epoch [32/100], Step[13000]: Train loss: 80.2573, Valid loss: 74.1778\n",
      "Epoch [32/100], Step[13100]: Train loss: 72.8544, Valid loss: 74.0244\n",
      "Epoch [32/100], Step[13200]: Train loss: 89.6173, Valid loss: 74.1484\n",
      "Epoch [32/100], Step[13300]: Train loss: 73.9616, Valid loss: 74.2889\n",
      "Epoch [33/100], Step[13400]: Train loss: 79.9163, Valid loss: 74.1834\n",
      "Epoch [33/100], Step[13500]: Train loss: 87.1293, Valid loss: 73.9131\n",
      "Saving model with loss 73.913...\n",
      "Epoch [33/100], Step[13600]: Train loss: 72.5909, Valid loss: 73.9556\n",
      "Epoch [33/100], Step[13700]: Train loss: 70.6577, Valid loss: 73.8161\n",
      "Saving model with loss 73.816...\n",
      "Epoch [34/100], Step[13800]: Train loss: 76.1584, Valid loss: 73.9779\n",
      "Epoch [34/100], Step[13900]: Train loss: 81.7032, Valid loss: 74.4950\n",
      "Epoch [34/100], Step[14000]: Train loss: 65.5048, Valid loss: 73.8379\n",
      "Epoch [34/100], Step[14100]: Train loss: 80.2338, Valid loss: 74.3081\n",
      "Epoch [34/100], Step[14200]: Train loss: 84.1949, Valid loss: 74.0780\n",
      "Epoch [35/100], Step[14300]: Train loss: 78.1871, Valid loss: 74.1257\n",
      "Epoch [35/100], Step[14400]: Train loss: 68.2113, Valid loss: 74.2101\n",
      "Epoch [35/100], Step[14500]: Train loss: 76.6044, Valid loss: 74.1143\n",
      "Epoch [35/100], Step[14600]: Train loss: 77.6541, Valid loss: 73.9282\n",
      "Epoch [36/100], Step[14700]: Train loss: 84.1997, Valid loss: 74.2979\n",
      "Epoch [36/100], Step[14800]: Train loss: 66.1621, Valid loss: 74.1321\n",
      "Epoch [36/100], Step[14900]: Train loss: 74.5080, Valid loss: 74.0217\n",
      "Epoch [36/100], Step[15000]: Train loss: 77.5018, Valid loss: 74.2839\n",
      "Epoch [37/100], Step[15100]: Train loss: 71.8638, Valid loss: 73.9491\n",
      "Epoch [37/100], Step[15200]: Train loss: 73.6724, Valid loss: 74.2553\n",
      "Epoch [37/100], Step[15300]: Train loss: 83.0471, Valid loss: 73.9631\n",
      "Epoch [37/100], Step[15400]: Train loss: 77.3753, Valid loss: 73.7030\n",
      "Saving model with loss 73.703...\n",
      "Epoch [38/100], Step[15500]: Train loss: 76.0163, Valid loss: 74.3801\n",
      "Epoch [38/100], Step[15600]: Train loss: 80.1764, Valid loss: 73.9083\n",
      "Epoch [38/100], Step[15700]: Train loss: 80.7034, Valid loss: 74.2542\n",
      "Epoch [38/100], Step[15800]: Train loss: 70.9876, Valid loss: 74.0325\n",
      "Epoch [39/100], Step[15900]: Train loss: 78.1928, Valid loss: 74.0970\n",
      "Epoch [39/100], Step[16000]: Train loss: 80.1240, Valid loss: 73.8601\n",
      "Epoch [39/100], Step[16100]: Train loss: 73.1271, Valid loss: 74.1088\n",
      "Epoch [39/100], Step[16200]: Train loss: 66.8867, Valid loss: 73.9722\n",
      "Epoch [39/100], Step[16300]: Train loss: 78.0674, Valid loss: 73.8669\n",
      "Epoch [40/100], Step[16400]: Train loss: 72.5275, Valid loss: 74.1814\n",
      "Epoch [40/100], Step[16500]: Train loss: 82.3928, Valid loss: 73.9453\n",
      "Epoch [40/100], Step[16600]: Train loss: 74.3815, Valid loss: 74.0444\n",
      "Epoch [40/100], Step[16700]: Train loss: 81.3775, Valid loss: 74.2730\n",
      "Epoch [41/100], Step[16800]: Train loss: 72.6242, Valid loss: 73.5172\n",
      "Saving model with loss 73.517...\n",
      "Epoch [41/100], Step[16900]: Train loss: 80.1834, Valid loss: 73.9911\n",
      "Epoch [41/100], Step[17000]: Train loss: 80.2601, Valid loss: 74.1523\n",
      "Epoch [41/100], Step[17100]: Train loss: 78.5043, Valid loss: 73.7771\n",
      "Epoch [42/100], Step[17200]: Train loss: 70.7362, Valid loss: 73.7152\n",
      "Epoch [42/100], Step[17300]: Train loss: 75.4749, Valid loss: 73.8417\n",
      "Epoch [42/100], Step[17400]: Train loss: 74.4722, Valid loss: 74.0004\n",
      "Epoch [42/100], Step[17500]: Train loss: 75.5530, Valid loss: 73.7521\n",
      "Epoch [43/100], Step[17600]: Train loss: 73.4120, Valid loss: 74.0977\n",
      "Epoch [43/100], Step[17700]: Train loss: 81.5498, Valid loss: 74.0036\n",
      "Epoch [43/100], Step[17800]: Train loss: 79.2324, Valid loss: 73.9052\n",
      "Epoch [43/100], Step[17900]: Train loss: 79.9722, Valid loss: 74.5145\n",
      "Epoch [44/100], Step[18000]: Train loss: 64.4037, Valid loss: 74.2773\n",
      "Epoch [44/100], Step[18100]: Train loss: 84.1234, Valid loss: 73.9815\n",
      "Epoch [44/100], Step[18200]: Train loss: 80.4687, Valid loss: 73.7129\n",
      "Epoch [44/100], Step[18300]: Train loss: 72.5023, Valid loss: 73.8208\n",
      "Epoch [45/100], Step[18400]: Train loss: 75.7568, Valid loss: 73.8715\n",
      "Epoch [45/100], Step[18500]: Train loss: 75.5504, Valid loss: 73.7031\n",
      "Epoch [45/100], Step[18600]: Train loss: 77.8785, Valid loss: 74.0479\n",
      "Epoch [45/100], Step[18700]: Train loss: 71.4479, Valid loss: 73.8247\n",
      "Epoch [45/100], Step[18800]: Train loss: 79.9827, Valid loss: 73.9688\n",
      "Epoch [46/100], Step[18900]: Train loss: 70.1345, Valid loss: 73.9416\n",
      "Epoch [46/100], Step[19000]: Train loss: 82.3513, Valid loss: 73.6171\n",
      "Epoch [46/100], Step[19100]: Train loss: 91.6967, Valid loss: 73.7841\n",
      "Epoch [46/100], Step[19200]: Train loss: 78.5538, Valid loss: 74.3475\n",
      "Epoch [47/100], Step[19300]: Train loss: 74.3644, Valid loss: 73.7704\n",
      "Epoch [47/100], Step[19400]: Train loss: 77.3469, Valid loss: 74.2421\n",
      "Epoch [47/100], Step[19500]: Train loss: 75.7496, Valid loss: 74.0071\n",
      "Epoch [47/100], Step[19600]: Train loss: 79.9513, Valid loss: 73.8783\n",
      "Epoch [48/100], Step[19700]: Train loss: 78.7750, Valid loss: 74.3094\n",
      "Epoch [48/100], Step[19800]: Train loss: 85.0044, Valid loss: 74.2810\n",
      "Epoch [48/100], Step[19900]: Train loss: 72.7195, Valid loss: 74.4884\n",
      "Epoch [48/100], Step[20000]: Train loss: 82.1577, Valid loss: 74.2258\n",
      "Epoch [49/100], Step[20100]: Train loss: 77.3074, Valid loss: 74.0771\n",
      "Epoch [49/100], Step[20200]: Train loss: 80.4905, Valid loss: 73.9356\n",
      "Epoch [49/100], Step[20300]: Train loss: 80.0605, Valid loss: 74.1978\n",
      "Epoch [49/100], Step[20400]: Train loss: 69.4467, Valid loss: 73.7902\n",
      "Epoch [50/100], Step[20500]: Train loss: 79.8925, Valid loss: 74.0858\n",
      "Epoch [50/100], Step[20600]: Train loss: 78.2255, Valid loss: 73.9650\n",
      "Epoch [50/100], Step[20700]: Train loss: 69.6134, Valid loss: 74.0409\n",
      "Epoch [50/100], Step[20800]: Train loss: 69.7173, Valid loss: 73.8692\n",
      "Epoch [50/100], Step[20900]: Train loss: 68.7056, Valid loss: 73.5422\n",
      "Epoch [51/100], Step[21000]: Train loss: 85.8306, Valid loss: 74.4176\n",
      "Epoch [51/100], Step[21100]: Train loss: 76.9300, Valid loss: 74.2756\n",
      "Epoch [51/100], Step[21200]: Train loss: 84.9316, Valid loss: 73.9229\n",
      "Epoch [51/100], Step[21300]: Train loss: 73.0276, Valid loss: 73.9410\n",
      "Epoch [52/100], Step[21400]: Train loss: 79.5305, Valid loss: 74.0324\n",
      "Epoch [52/100], Step[21500]: Train loss: 70.7655, Valid loss: 73.7224\n",
      "Epoch [52/100], Step[21600]: Train loss: 81.0347, Valid loss: 73.6638\n",
      "Epoch [52/100], Step[21700]: Train loss: 80.9070, Valid loss: 73.9556\n",
      "Epoch [53/100], Step[21800]: Train loss: 66.5816, Valid loss: 73.6221\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 90,\n",
    "    'optimizer': \"Adam\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model5.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5463f6e7-f204-4795-9788-2d14607242e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95672ba3-aa4a-440b-ac02-31f6bc60c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 8.772996\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "\n",
    "# Change mse to rmse\n",
    "train_loss = np.sqrt(train_loss)\n",
    "valid_loss = np.sqrt(valid_loss)\n",
    "\n",
    "# Draw test, valid RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(step_arr, train_loss ,color = 'r', label=\"Training_RMSE\")\n",
    "plt.plot(step_arr, valid_loss ,color = 'g', label=\"Validation_RMSE\")\n",
    "plt.title(\"Training vs Validation RMSE\")\n",
    "plt.xlabel(\"step (batches)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bc541-5ae9-426c-b203-b122b506f11c",
   "metadata": {},
   "source": [
    "This is obviously way better than the previous models, and we can see significant decrease of Validation RMSE with the Training RMSE decreases and finally stablizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee75e4-660d-4fd5-8205-dcf65744d99c",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7b02a-8213-4297-9a7b-4981d3dec85a",
   "metadata": {},
   "source": [
    "H = 20, 45, 180, 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64831bf-b886-4e0c-8843-1c4e091d1087",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 109.2591, Valid loss: 112.4306\n",
      "Saving model with loss 112.431...\n",
      "Epoch [1/100], Step[200]: Train loss: 90.8071, Valid loss: 97.8137\n",
      "Saving model with loss 97.814...\n",
      "Epoch [1/100], Step[300]: Train loss: 105.4750, Valid loss: 91.1357\n",
      "Saving model with loss 91.136...\n",
      "Epoch [1/100], Step[400]: Train loss: 100.6136, Valid loss: 89.0132\n",
      "Saving model with loss 89.013...\n",
      "Epoch [2/100], Step[500]: Train loss: 86.6712, Valid loss: 87.3832\n",
      "Saving model with loss 87.383...\n",
      "Epoch [2/100], Step[600]: Train loss: 92.6837, Valid loss: 85.7146\n",
      "Saving model with loss 85.715...\n",
      "Epoch [2/100], Step[700]: Train loss: 85.1781, Valid loss: 85.8432\n",
      "Epoch [2/100], Step[800]: Train loss: 91.4784, Valid loss: 85.3131\n",
      "Saving model with loss 85.313...\n",
      "Epoch [3/100], Step[900]: Train loss: 88.7411, Valid loss: 85.0992\n",
      "Saving model with loss 85.099...\n",
      "Epoch [3/100], Step[1000]: Train loss: 82.7051, Valid loss: 85.1593\n",
      "Epoch [3/100], Step[1100]: Train loss: 102.8499, Valid loss: 84.8740\n",
      "Saving model with loss 84.874...\n",
      "Epoch [3/100], Step[1200]: Train loss: 91.5301, Valid loss: 84.4595\n",
      "Saving model with loss 84.459...\n",
      "Epoch [4/100], Step[1300]: Train loss: 101.4746, Valid loss: 84.0171\n",
      "Saving model with loss 84.017...\n",
      "Epoch [4/100], Step[1400]: Train loss: 98.5480, Valid loss: 84.1833\n",
      "Epoch [4/100], Step[1500]: Train loss: 87.2529, Valid loss: 83.8842\n",
      "Saving model with loss 83.884...\n",
      "Epoch [4/100], Step[1600]: Train loss: 104.6776, Valid loss: 83.4592\n",
      "Saving model with loss 83.459...\n",
      "Epoch [5/100], Step[1700]: Train loss: 90.7866, Valid loss: 83.1170\n",
      "Saving model with loss 83.117...\n",
      "Epoch [5/100], Step[1800]: Train loss: 97.2288, Valid loss: 83.3331\n",
      "Epoch [5/100], Step[1900]: Train loss: 91.7129, Valid loss: 83.1471\n",
      "Epoch [5/100], Step[2000]: Train loss: 98.6239, Valid loss: 82.7592\n",
      "Saving model with loss 82.759...\n",
      "Epoch [6/100], Step[2100]: Train loss: 76.9457, Valid loss: 82.9642\n",
      "Epoch [6/100], Step[2200]: Train loss: 84.1199, Valid loss: 82.4073\n",
      "Saving model with loss 82.407...\n",
      "Epoch [6/100], Step[2300]: Train loss: 95.3850, Valid loss: 82.1305\n",
      "Saving model with loss 82.131...\n",
      "Epoch [6/100], Step[2400]: Train loss: 85.4202, Valid loss: 82.3593\n",
      "Epoch [6/100], Step[2500]: Train loss: 101.7497, Valid loss: 81.7972\n",
      "Saving model with loss 81.797...\n",
      "Epoch [7/100], Step[2600]: Train loss: 86.6239, Valid loss: 81.9159\n",
      "Epoch [7/100], Step[2700]: Train loss: 77.9864, Valid loss: 81.9726\n",
      "Epoch [7/100], Step[2800]: Train loss: 89.3020, Valid loss: 82.1904\n",
      "Epoch [7/100], Step[2900]: Train loss: 93.6242, Valid loss: 82.1016\n",
      "Epoch [8/100], Step[3000]: Train loss: 84.1550, Valid loss: 82.2292\n",
      "Epoch [8/100], Step[3100]: Train loss: 83.2459, Valid loss: 81.6294\n",
      "Saving model with loss 81.629...\n",
      "Epoch [8/100], Step[3200]: Train loss: 88.2700, Valid loss: 81.5374\n",
      "Saving model with loss 81.537...\n",
      "Epoch [8/100], Step[3300]: Train loss: 93.4567, Valid loss: 81.3026\n",
      "Saving model with loss 81.303...\n",
      "Epoch [9/100], Step[3400]: Train loss: 99.2502, Valid loss: 81.5697\n",
      "Epoch [9/100], Step[3500]: Train loss: 85.7678, Valid loss: 81.3940\n",
      "Epoch [9/100], Step[3600]: Train loss: 81.7275, Valid loss: 80.8602\n",
      "Saving model with loss 80.860...\n",
      "Epoch [9/100], Step[3700]: Train loss: 90.6568, Valid loss: 81.2616\n",
      "Epoch [10/100], Step[3800]: Train loss: 75.0014, Valid loss: 81.2107\n",
      "Epoch [10/100], Step[3900]: Train loss: 85.1229, Valid loss: 81.6494\n",
      "Epoch [10/100], Step[4000]: Train loss: 85.4043, Valid loss: 81.2419\n",
      "Epoch [10/100], Step[4100]: Train loss: 97.0470, Valid loss: 81.2649\n",
      "Epoch [11/100], Step[4200]: Train loss: 86.0410, Valid loss: 81.4352\n",
      "Epoch [11/100], Step[4300]: Train loss: 83.5691, Valid loss: 81.0098\n",
      "Epoch [11/100], Step[4400]: Train loss: 78.4132, Valid loss: 81.3161\n",
      "Epoch [11/100], Step[4500]: Train loss: 87.8481, Valid loss: 81.1332\n",
      "Epoch [12/100], Step[4600]: Train loss: 84.2475, Valid loss: 81.3819\n",
      "Epoch [12/100], Step[4700]: Train loss: 81.7579, Valid loss: 81.0434\n",
      "Epoch [12/100], Step[4800]: Train loss: 77.4066, Valid loss: 80.9301\n",
      "Epoch [12/100], Step[4900]: Train loss: 80.3466, Valid loss: 80.6774\n",
      "Saving model with loss 80.677...\n",
      "Epoch [12/100], Step[5000]: Train loss: 95.6206, Valid loss: 81.0650\n",
      "Epoch [13/100], Step[5100]: Train loss: 82.6737, Valid loss: 80.9571\n",
      "Epoch [13/100], Step[5200]: Train loss: 88.5419, Valid loss: 81.4504\n",
      "Epoch [13/100], Step[5300]: Train loss: 85.4833, Valid loss: 80.4624\n",
      "Saving model with loss 80.462...\n",
      "Epoch [13/100], Step[5400]: Train loss: 75.7516, Valid loss: 80.6583\n",
      "Epoch [14/100], Step[5500]: Train loss: 93.4810, Valid loss: 80.5075\n",
      "Epoch [14/100], Step[5600]: Train loss: 84.1155, Valid loss: 81.5866\n",
      "Epoch [14/100], Step[5700]: Train loss: 94.4837, Valid loss: 80.9266\n",
      "Epoch [14/100], Step[5800]: Train loss: 93.5161, Valid loss: 81.1534\n",
      "Epoch [15/100], Step[5900]: Train loss: 90.4546, Valid loss: 80.4925\n",
      "Epoch [15/100], Step[6000]: Train loss: 89.3883, Valid loss: 80.5819\n",
      "Epoch [15/100], Step[6100]: Train loss: 87.4692, Valid loss: 80.9662\n",
      "Epoch [15/100], Step[6200]: Train loss: 98.7415, Valid loss: 81.1537\n",
      "Epoch [16/100], Step[6300]: Train loss: 92.1291, Valid loss: 80.8642\n",
      "Epoch [16/100], Step[6400]: Train loss: 95.7388, Valid loss: 80.7641\n",
      "Epoch [16/100], Step[6500]: Train loss: 85.0801, Valid loss: 80.8796\n",
      "Epoch [16/100], Step[6600]: Train loss: 91.3140, Valid loss: 80.2970\n",
      "Saving model with loss 80.297...\n",
      "Epoch [17/100], Step[6700]: Train loss: 97.3189, Valid loss: 80.9195\n",
      "Epoch [17/100], Step[6800]: Train loss: 86.1541, Valid loss: 80.9780\n",
      "Epoch [17/100], Step[6900]: Train loss: 84.2789, Valid loss: 80.6686\n",
      "Epoch [17/100], Step[7000]: Train loss: 93.6624, Valid loss: 80.7588\n",
      "Epoch [17/100], Step[7100]: Train loss: 78.6204, Valid loss: 80.4807\n",
      "Epoch [18/100], Step[7200]: Train loss: 93.5702, Valid loss: 80.4978\n",
      "Epoch [18/100], Step[7300]: Train loss: 96.4993, Valid loss: 80.6747\n",
      "Epoch [18/100], Step[7400]: Train loss: 89.3311, Valid loss: 80.5446\n",
      "Epoch [18/100], Step[7500]: Train loss: 97.1508, Valid loss: 80.7562\n",
      "Epoch [19/100], Step[7600]: Train loss: 82.8629, Valid loss: 80.4989\n",
      "Epoch [19/100], Step[7700]: Train loss: 92.5838, Valid loss: 80.7958\n",
      "Epoch [19/100], Step[7800]: Train loss: 82.6688, Valid loss: 80.4324\n",
      "Epoch [19/100], Step[7900]: Train loss: 84.1257, Valid loss: 80.1781\n",
      "Saving model with loss 80.178...\n",
      "Epoch [20/100], Step[8000]: Train loss: 95.5396, Valid loss: 80.6967\n",
      "Epoch [20/100], Step[8100]: Train loss: 89.3566, Valid loss: 80.9662\n",
      "Epoch [20/100], Step[8200]: Train loss: 87.5395, Valid loss: 80.5394\n",
      "Epoch [20/100], Step[8300]: Train loss: 95.6687, Valid loss: 80.4800\n",
      "Epoch [21/100], Step[8400]: Train loss: 92.3540, Valid loss: 80.5167\n",
      "Epoch [21/100], Step[8500]: Train loss: 87.4667, Valid loss: 80.8469\n",
      "Epoch [21/100], Step[8600]: Train loss: 85.1340, Valid loss: 80.3975\n",
      "Epoch [21/100], Step[8700]: Train loss: 85.7216, Valid loss: 80.5682\n",
      "Epoch [22/100], Step[8800]: Train loss: 86.7584, Valid loss: 80.5048\n",
      "Epoch [22/100], Step[8900]: Train loss: 94.2145, Valid loss: 80.5768\n",
      "Epoch [22/100], Step[9000]: Train loss: 79.5505, Valid loss: 80.8631\n",
      "Epoch [22/100], Step[9100]: Train loss: 86.0864, Valid loss: 80.7825\n",
      "Epoch [23/100], Step[9200]: Train loss: 95.3191, Valid loss: 80.5854\n",
      "Epoch [23/100], Step[9300]: Train loss: 82.9840, Valid loss: 80.7035\n",
      "Epoch [23/100], Step[9400]: Train loss: 87.5693, Valid loss: 80.5273\n",
      "Epoch [23/100], Step[9500]: Train loss: 86.8963, Valid loss: 80.5648\n",
      "Epoch [23/100], Step[9600]: Train loss: 84.4539, Valid loss: 80.3330\n",
      "Epoch [24/100], Step[9700]: Train loss: 96.4041, Valid loss: 81.6685\n",
      "Epoch [24/100], Step[9800]: Train loss: 87.0858, Valid loss: 80.2372\n",
      "Epoch [24/100], Step[9900]: Train loss: 84.2726, Valid loss: 80.7280\n",
      "Epoch [24/100], Step[10000]: Train loss: 100.7741, Valid loss: 80.5283\n",
      "Epoch [25/100], Step[10100]: Train loss: 89.4912, Valid loss: 80.9515\n",
      "Epoch [25/100], Step[10200]: Train loss: 78.7533, Valid loss: 81.0108\n",
      "Epoch [25/100], Step[10300]: Train loss: 89.0230, Valid loss: 80.6508\n",
      "Epoch [25/100], Step[10400]: Train loss: 86.9706, Valid loss: 80.7072\n",
      "Epoch [26/100], Step[10500]: Train loss: 89.9359, Valid loss: 81.3061\n",
      "Epoch [26/100], Step[10600]: Train loss: 102.6697, Valid loss: 80.9801\n",
      "Epoch [26/100], Step[10700]: Train loss: 93.6679, Valid loss: 80.3495\n",
      "Epoch [26/100], Step[10800]: Train loss: 94.3028, Valid loss: 80.4932\n",
      "Epoch [27/100], Step[10900]: Train loss: 83.0871, Valid loss: 80.8642\n",
      "Epoch [27/100], Step[11000]: Train loss: 98.4333, Valid loss: 80.2797\n",
      "Epoch [27/100], Step[11100]: Train loss: 77.1640, Valid loss: 80.7301\n",
      "Epoch [27/100], Step[11200]: Train loss: 84.9702, Valid loss: 80.7531\n",
      "Epoch [28/100], Step[11300]: Train loss: 93.9412, Valid loss: 80.5706\n",
      "Epoch [28/100], Step[11400]: Train loss: 90.4306, Valid loss: 80.6223\n",
      "Epoch [28/100], Step[11500]: Train loss: 82.1205, Valid loss: 80.6505\n",
      "Epoch [28/100], Step[11600]: Train loss: 88.3947, Valid loss: 80.3332\n",
      "Epoch [28/100], Step[11700]: Train loss: 87.1538, Valid loss: 80.6227\n",
      "Epoch [29/100], Step[11800]: Train loss: 96.0404, Valid loss: 80.2738\n",
      "Epoch [29/100], Step[11900]: Train loss: 84.3883, Valid loss: 80.3512\n",
      "Epoch [29/100], Step[12000]: Train loss: 81.7514, Valid loss: 81.0653\n",
      "Epoch [29/100], Step[12100]: Train loss: 92.2706, Valid loss: 80.4860\n",
      "Epoch [30/100], Step[12200]: Train loss: 86.0728, Valid loss: 80.9832\n",
      "Epoch [30/100], Step[12300]: Train loss: 83.4423, Valid loss: 80.7316\n",
      "Epoch [30/100], Step[12400]: Train loss: 93.2234, Valid loss: 80.9675\n",
      "Epoch [30/100], Step[12500]: Train loss: 88.9774, Valid loss: 80.9549\n",
      "Epoch [31/100], Step[12600]: Train loss: 85.2645, Valid loss: 80.2510\n",
      "Epoch [31/100], Step[12700]: Train loss: 93.2153, Valid loss: 80.7157\n",
      "Epoch [31/100], Step[12800]: Train loss: 95.1396, Valid loss: 81.2351\n",
      "Epoch [31/100], Step[12900]: Train loss: 80.5690, Valid loss: 80.5461\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 91.5501, Valid loss: 97.9022\n",
      "Saving model with loss 97.902...\n",
      "Epoch [1/100], Step[200]: Train loss: 91.5178, Valid loss: 86.7987\n",
      "Saving model with loss 86.799...\n",
      "Epoch [1/100], Step[300]: Train loss: 92.5666, Valid loss: 83.8632\n",
      "Saving model with loss 83.863...\n",
      "Epoch [1/100], Step[400]: Train loss: 88.9349, Valid loss: 83.1443\n",
      "Saving model with loss 83.144...\n",
      "Epoch [2/100], Step[500]: Train loss: 90.6561, Valid loss: 82.2227\n",
      "Saving model with loss 82.223...\n",
      "Epoch [2/100], Step[600]: Train loss: 91.4030, Valid loss: 81.1731\n",
      "Saving model with loss 81.173...\n",
      "Epoch [2/100], Step[700]: Train loss: 90.1346, Valid loss: 81.7885\n",
      "Epoch [2/100], Step[800]: Train loss: 81.0675, Valid loss: 81.2219\n",
      "Epoch [3/100], Step[900]: Train loss: 79.6499, Valid loss: 79.9689\n",
      "Saving model with loss 79.969...\n",
      "Epoch [3/100], Step[1000]: Train loss: 93.0215, Valid loss: 80.2627\n",
      "Epoch [3/100], Step[1100]: Train loss: 109.0322, Valid loss: 79.9515\n",
      "Saving model with loss 79.952...\n",
      "Epoch [3/100], Step[1200]: Train loss: 88.1178, Valid loss: 79.9413\n",
      "Saving model with loss 79.941...\n",
      "Epoch [4/100], Step[1300]: Train loss: 87.5546, Valid loss: 78.8965\n",
      "Saving model with loss 78.897...\n",
      "Epoch [4/100], Step[1400]: Train loss: 75.0009, Valid loss: 79.8116\n",
      "Epoch [4/100], Step[1500]: Train loss: 81.5132, Valid loss: 79.5246\n",
      "Epoch [4/100], Step[1600]: Train loss: 87.2124, Valid loss: 78.9837\n",
      "Epoch [5/100], Step[1700]: Train loss: 87.4970, Valid loss: 79.0135\n",
      "Epoch [5/100], Step[1800]: Train loss: 80.4675, Valid loss: 78.7686\n",
      "Saving model with loss 78.769...\n",
      "Epoch [5/100], Step[1900]: Train loss: 78.8422, Valid loss: 78.6888\n",
      "Saving model with loss 78.689...\n",
      "Epoch [5/100], Step[2000]: Train loss: 76.4680, Valid loss: 79.0144\n",
      "Epoch [6/100], Step[2100]: Train loss: 93.3756, Valid loss: 78.4590\n",
      "Saving model with loss 78.459...\n",
      "Epoch [6/100], Step[2200]: Train loss: 85.1526, Valid loss: 78.4470\n",
      "Saving model with loss 78.447...\n",
      "Epoch [6/100], Step[2300]: Train loss: 73.6936, Valid loss: 78.7268\n",
      "Epoch [6/100], Step[2400]: Train loss: 91.7293, Valid loss: 78.2132\n",
      "Saving model with loss 78.213...\n",
      "Epoch [6/100], Step[2500]: Train loss: 82.3174, Valid loss: 78.4613\n",
      "Epoch [7/100], Step[2600]: Train loss: 86.3653, Valid loss: 78.2493\n",
      "Epoch [7/100], Step[2700]: Train loss: 75.7180, Valid loss: 78.5278\n",
      "Epoch [7/100], Step[2800]: Train loss: 85.0932, Valid loss: 78.0300\n",
      "Saving model with loss 78.030...\n",
      "Epoch [7/100], Step[2900]: Train loss: 78.4612, Valid loss: 78.5546\n",
      "Epoch [8/100], Step[3000]: Train loss: 86.9503, Valid loss: 78.2927\n",
      "Epoch [8/100], Step[3100]: Train loss: 74.8298, Valid loss: 78.1292\n",
      "Epoch [8/100], Step[3200]: Train loss: 72.0104, Valid loss: 77.7196\n",
      "Saving model with loss 77.720...\n",
      "Epoch [8/100], Step[3300]: Train loss: 81.6897, Valid loss: 77.7418\n",
      "Epoch [9/100], Step[3400]: Train loss: 79.6144, Valid loss: 77.3446\n",
      "Saving model with loss 77.345...\n",
      "Epoch [9/100], Step[3500]: Train loss: 85.8909, Valid loss: 77.8697\n",
      "Epoch [9/100], Step[3600]: Train loss: 83.2681, Valid loss: 77.5006\n",
      "Epoch [9/100], Step[3700]: Train loss: 80.6105, Valid loss: 77.6872\n",
      "Epoch [10/100], Step[3800]: Train loss: 79.6466, Valid loss: 77.3287\n",
      "Saving model with loss 77.329...\n",
      "Epoch [10/100], Step[3900]: Train loss: 81.9090, Valid loss: 77.5202\n",
      "Epoch [10/100], Step[4000]: Train loss: 88.1542, Valid loss: 78.0146\n",
      "Epoch [10/100], Step[4100]: Train loss: 97.0898, Valid loss: 77.5916\n",
      "Epoch [11/100], Step[4200]: Train loss: 94.6921, Valid loss: 77.7664\n",
      "Epoch [11/100], Step[4300]: Train loss: 89.3224, Valid loss: 77.5460\n",
      "Epoch [11/100], Step[4400]: Train loss: 77.9034, Valid loss: 78.0675\n",
      "Epoch [11/100], Step[4500]: Train loss: 84.4892, Valid loss: 77.2723\n",
      "Saving model with loss 77.272...\n",
      "Epoch [12/100], Step[4600]: Train loss: 80.4936, Valid loss: 77.7236\n",
      "Epoch [12/100], Step[4700]: Train loss: 75.6276, Valid loss: 77.4959\n",
      "Epoch [12/100], Step[4800]: Train loss: 77.3554, Valid loss: 77.6368\n",
      "Epoch [12/100], Step[4900]: Train loss: 75.9722, Valid loss: 77.4763\n",
      "Epoch [12/100], Step[5000]: Train loss: 86.9371, Valid loss: 77.5590\n",
      "Epoch [13/100], Step[5100]: Train loss: 82.3439, Valid loss: 77.1101\n",
      "Saving model with loss 77.110...\n",
      "Epoch [13/100], Step[5200]: Train loss: 92.7635, Valid loss: 77.5610\n",
      "Epoch [13/100], Step[5300]: Train loss: 80.6768, Valid loss: 77.2221\n",
      "Epoch [13/100], Step[5400]: Train loss: 98.9158, Valid loss: 77.3795\n",
      "Epoch [14/100], Step[5500]: Train loss: 78.0084, Valid loss: 77.3272\n",
      "Epoch [14/100], Step[5600]: Train loss: 80.9058, Valid loss: 77.5569\n",
      "Epoch [14/100], Step[5700]: Train loss: 76.4808, Valid loss: 77.5285\n",
      "Epoch [14/100], Step[5800]: Train loss: 88.3736, Valid loss: 77.0379\n",
      "Saving model with loss 77.038...\n",
      "Epoch [15/100], Step[5900]: Train loss: 83.1655, Valid loss: 77.2751\n",
      "Epoch [15/100], Step[6000]: Train loss: 82.7417, Valid loss: 77.1917\n",
      "Epoch [15/100], Step[6100]: Train loss: 77.0836, Valid loss: 76.8146\n",
      "Saving model with loss 76.815...\n",
      "Epoch [15/100], Step[6200]: Train loss: 80.5471, Valid loss: 77.1271\n",
      "Epoch [16/100], Step[6300]: Train loss: 82.1136, Valid loss: 76.7863\n",
      "Saving model with loss 76.786...\n",
      "Epoch [16/100], Step[6400]: Train loss: 84.6390, Valid loss: 77.2784\n",
      "Epoch [16/100], Step[6500]: Train loss: 67.9819, Valid loss: 77.2513\n",
      "Epoch [16/100], Step[6600]: Train loss: 83.1720, Valid loss: 77.1703\n",
      "Epoch [17/100], Step[6700]: Train loss: 88.7977, Valid loss: 76.9429\n",
      "Epoch [17/100], Step[6800]: Train loss: 80.9774, Valid loss: 77.1120\n",
      "Epoch [17/100], Step[6900]: Train loss: 87.8404, Valid loss: 77.2970\n",
      "Epoch [17/100], Step[7000]: Train loss: 77.4249, Valid loss: 77.3591\n",
      "Epoch [17/100], Step[7100]: Train loss: 88.9222, Valid loss: 76.9690\n",
      "Epoch [18/100], Step[7200]: Train loss: 80.0989, Valid loss: 76.6150\n",
      "Saving model with loss 76.615...\n",
      "Epoch [18/100], Step[7300]: Train loss: 87.6104, Valid loss: 76.8480\n",
      "Epoch [18/100], Step[7400]: Train loss: 90.2173, Valid loss: 77.4755\n",
      "Epoch [18/100], Step[7500]: Train loss: 83.4634, Valid loss: 76.8431\n",
      "Epoch [19/100], Step[7600]: Train loss: 79.2879, Valid loss: 77.2066\n",
      "Epoch [19/100], Step[7700]: Train loss: 80.5308, Valid loss: 77.0774\n",
      "Epoch [19/100], Step[7800]: Train loss: 86.7026, Valid loss: 77.1306\n",
      "Epoch [19/100], Step[7900]: Train loss: 84.1376, Valid loss: 76.9976\n",
      "Epoch [20/100], Step[8000]: Train loss: 77.8922, Valid loss: 77.0753\n",
      "Epoch [20/100], Step[8100]: Train loss: 77.1980, Valid loss: 76.9493\n",
      "Epoch [20/100], Step[8200]: Train loss: 80.6903, Valid loss: 76.9242\n",
      "Epoch [20/100], Step[8300]: Train loss: 88.8224, Valid loss: 76.7880\n",
      "Epoch [21/100], Step[8400]: Train loss: 73.1871, Valid loss: 76.6128\n",
      "Saving model with loss 76.613...\n",
      "Epoch [21/100], Step[8500]: Train loss: 75.7493, Valid loss: 77.0659\n",
      "Epoch [21/100], Step[8600]: Train loss: 82.1831, Valid loss: 77.1841\n",
      "Epoch [21/100], Step[8700]: Train loss: 77.3214, Valid loss: 76.2717\n",
      "Saving model with loss 76.272...\n",
      "Epoch [22/100], Step[8800]: Train loss: 83.8314, Valid loss: 77.1736\n",
      "Epoch [22/100], Step[8900]: Train loss: 80.0532, Valid loss: 76.7383\n",
      "Epoch [22/100], Step[9000]: Train loss: 90.9756, Valid loss: 76.5208\n",
      "Epoch [22/100], Step[9100]: Train loss: 79.9344, Valid loss: 77.1221\n",
      "Epoch [23/100], Step[9200]: Train loss: 86.9761, Valid loss: 77.0586\n",
      "Epoch [23/100], Step[9300]: Train loss: 77.3073, Valid loss: 77.0523\n",
      "Epoch [23/100], Step[9400]: Train loss: 85.1285, Valid loss: 76.9324\n",
      "Epoch [23/100], Step[9500]: Train loss: 85.0387, Valid loss: 77.0054\n",
      "Epoch [23/100], Step[9600]: Train loss: 90.9724, Valid loss: 76.6672\n",
      "Epoch [24/100], Step[9700]: Train loss: 78.7652, Valid loss: 76.9371\n",
      "Epoch [24/100], Step[9800]: Train loss: 79.1299, Valid loss: 76.7786\n",
      "Epoch [24/100], Step[9900]: Train loss: 95.9763, Valid loss: 76.7957\n",
      "Epoch [24/100], Step[10000]: Train loss: 70.8799, Valid loss: 76.8430\n",
      "Epoch [25/100], Step[10100]: Train loss: 87.0746, Valid loss: 76.5499\n",
      "Epoch [25/100], Step[10200]: Train loss: 90.0027, Valid loss: 77.0021\n",
      "Epoch [25/100], Step[10300]: Train loss: 81.3730, Valid loss: 76.8226\n",
      "Epoch [25/100], Step[10400]: Train loss: 79.7008, Valid loss: 76.8317\n",
      "Epoch [26/100], Step[10500]: Train loss: 81.7573, Valid loss: 77.1071\n",
      "Epoch [26/100], Step[10600]: Train loss: 94.4233, Valid loss: 77.1452\n",
      "Epoch [26/100], Step[10700]: Train loss: 80.4285, Valid loss: 77.4189\n",
      "Epoch [26/100], Step[10800]: Train loss: 84.2865, Valid loss: 76.8797\n",
      "Epoch [27/100], Step[10900]: Train loss: 87.8744, Valid loss: 77.4789\n",
      "Epoch [27/100], Step[11000]: Train loss: 89.9707, Valid loss: 76.7327\n",
      "Epoch [27/100], Step[11100]: Train loss: 72.8846, Valid loss: 76.6105\n",
      "Epoch [27/100], Step[11200]: Train loss: 83.6750, Valid loss: 76.9199\n",
      "Epoch [28/100], Step[11300]: Train loss: 90.3959, Valid loss: 77.4100\n",
      "Epoch [28/100], Step[11400]: Train loss: 80.6522, Valid loss: 76.9920\n",
      "Epoch [28/100], Step[11500]: Train loss: 85.8208, Valid loss: 76.8388\n",
      "Epoch [28/100], Step[11600]: Train loss: 81.2048, Valid loss: 76.7377\n",
      "Epoch [28/100], Step[11700]: Train loss: 64.4322, Valid loss: 76.8451\n",
      "Epoch [29/100], Step[11800]: Train loss: 86.0750, Valid loss: 76.7522\n",
      "Epoch [29/100], Step[11900]: Train loss: 72.9292, Valid loss: 77.2265\n",
      "Epoch [29/100], Step[12000]: Train loss: 82.3213, Valid loss: 76.7401\n",
      "Epoch [29/100], Step[12100]: Train loss: 68.4874, Valid loss: 77.3797\n",
      "Epoch [30/100], Step[12200]: Train loss: 73.0582, Valid loss: 76.6482\n",
      "Epoch [30/100], Step[12300]: Train loss: 74.2832, Valid loss: 76.8719\n",
      "Epoch [30/100], Step[12400]: Train loss: 91.6589, Valid loss: 76.8350\n",
      "Epoch [30/100], Step[12500]: Train loss: 98.1165, Valid loss: 76.6495\n",
      "Epoch [31/100], Step[12600]: Train loss: 77.4155, Valid loss: 76.6733\n",
      "Epoch [31/100], Step[12700]: Train loss: 77.8352, Valid loss: 76.9363\n",
      "Epoch [31/100], Step[12800]: Train loss: 78.8129, Valid loss: 76.9194\n",
      "Epoch [31/100], Step[12900]: Train loss: 75.9101, Valid loss: 77.0066\n",
      "Epoch [32/100], Step[13000]: Train loss: 83.3688, Valid loss: 76.7437\n",
      "Epoch [32/100], Step[13100]: Train loss: 87.6503, Valid loss: 76.6294\n",
      "Epoch [32/100], Step[13200]: Train loss: 93.6644, Valid loss: 76.7083\n",
      "Epoch [32/100], Step[13300]: Train loss: 84.9283, Valid loss: 77.3305\n",
      "Epoch [33/100], Step[13400]: Train loss: 84.9942, Valid loss: 76.6410\n",
      "Epoch [33/100], Step[13500]: Train loss: 84.3131, Valid loss: 77.0855\n",
      "Epoch [33/100], Step[13600]: Train loss: 74.3333, Valid loss: 76.1861\n",
      "Saving model with loss 76.186...\n",
      "Epoch [33/100], Step[13700]: Train loss: 79.0173, Valid loss: 76.3018\n",
      "Epoch [34/100], Step[13800]: Train loss: 91.9336, Valid loss: 77.2943\n",
      "Epoch [34/100], Step[13900]: Train loss: 69.5768, Valid loss: 76.5140\n",
      "Epoch [34/100], Step[14000]: Train loss: 81.8876, Valid loss: 76.4995\n",
      "Epoch [34/100], Step[14100]: Train loss: 87.8096, Valid loss: 77.1844\n",
      "Epoch [34/100], Step[14200]: Train loss: 77.3467, Valid loss: 76.6362\n",
      "Epoch [35/100], Step[14300]: Train loss: 81.1730, Valid loss: 76.8046\n",
      "Epoch [35/100], Step[14400]: Train loss: 89.6174, Valid loss: 77.0055\n",
      "Epoch [35/100], Step[14500]: Train loss: 79.3129, Valid loss: 76.8998\n",
      "Epoch [35/100], Step[14600]: Train loss: 77.7349, Valid loss: 76.6764\n",
      "Epoch [36/100], Step[14700]: Train loss: 81.8386, Valid loss: 76.4777\n",
      "Epoch [36/100], Step[14800]: Train loss: 84.1184, Valid loss: 76.3917\n",
      "Epoch [36/100], Step[14900]: Train loss: 89.0466, Valid loss: 76.5258\n",
      "Epoch [36/100], Step[15000]: Train loss: 87.5901, Valid loss: 77.0369\n",
      "Epoch [37/100], Step[15100]: Train loss: 76.3174, Valid loss: 76.5011\n",
      "Epoch [37/100], Step[15200]: Train loss: 80.9159, Valid loss: 76.6701\n",
      "Epoch [37/100], Step[15300]: Train loss: 84.2624, Valid loss: 76.4887\n",
      "Epoch [37/100], Step[15400]: Train loss: 77.4459, Valid loss: 76.2280\n",
      "Epoch [38/100], Step[15500]: Train loss: 76.9096, Valid loss: 76.1993\n",
      "Epoch [38/100], Step[15600]: Train loss: 80.2268, Valid loss: 76.6557\n",
      "Epoch [38/100], Step[15700]: Train loss: 93.1982, Valid loss: 76.8444\n",
      "Epoch [38/100], Step[15800]: Train loss: 77.6368, Valid loss: 76.4562\n",
      "Epoch [39/100], Step[15900]: Train loss: 69.4979, Valid loss: 76.4218\n",
      "Epoch [39/100], Step[16000]: Train loss: 88.7856, Valid loss: 76.7003\n",
      "Epoch [39/100], Step[16100]: Train loss: 94.1761, Valid loss: 76.5553\n",
      "Epoch [39/100], Step[16200]: Train loss: 86.9437, Valid loss: 76.5192\n",
      "Epoch [39/100], Step[16300]: Train loss: 79.7635, Valid loss: 76.5192\n",
      "Epoch [40/100], Step[16400]: Train loss: 73.5000, Valid loss: 76.3872\n",
      "Epoch [40/100], Step[16500]: Train loss: 77.9934, Valid loss: 76.9470\n",
      "Epoch [40/100], Step[16600]: Train loss: 85.9105, Valid loss: 76.6022\n",
      "Epoch [40/100], Step[16700]: Train loss: 80.7817, Valid loss: 76.4180\n",
      "Epoch [41/100], Step[16800]: Train loss: 85.5472, Valid loss: 76.4620\n",
      "Epoch [41/100], Step[16900]: Train loss: 83.8391, Valid loss: 76.3209\n",
      "Epoch [41/100], Step[17000]: Train loss: 63.4583, Valid loss: 76.4408\n",
      "Epoch [41/100], Step[17100]: Train loss: 79.7258, Valid loss: 76.3780\n",
      "Epoch [42/100], Step[17200]: Train loss: 80.8561, Valid loss: 76.7355\n",
      "Epoch [42/100], Step[17300]: Train loss: 75.9879, Valid loss: 76.5632\n",
      "Epoch [42/100], Step[17400]: Train loss: 82.1990, Valid loss: 76.3489\n",
      "Epoch [42/100], Step[17500]: Train loss: 98.1985, Valid loss: 76.5718\n",
      "Epoch [43/100], Step[17600]: Train loss: 79.1465, Valid loss: 76.3420\n",
      "Epoch [43/100], Step[17700]: Train loss: 78.0409, Valid loss: 76.9278\n",
      "Epoch [43/100], Step[17800]: Train loss: 89.9769, Valid loss: 76.6867\n",
      "Epoch [43/100], Step[17900]: Train loss: 102.1205, Valid loss: 76.4248\n",
      "Epoch [44/100], Step[18000]: Train loss: 81.1421, Valid loss: 76.4518\n",
      "Epoch [44/100], Step[18100]: Train loss: 75.0877, Valid loss: 76.4732\n",
      "Epoch [44/100], Step[18200]: Train loss: 85.6663, Valid loss: 76.9034\n",
      "Epoch [44/100], Step[18300]: Train loss: 87.8945, Valid loss: 76.3144\n",
      "Epoch [45/100], Step[18400]: Train loss: 74.6190, Valid loss: 76.0202\n",
      "Saving model with loss 76.020...\n",
      "Epoch [45/100], Step[18500]: Train loss: 89.5457, Valid loss: 76.6271\n",
      "Epoch [45/100], Step[18600]: Train loss: 77.9628, Valid loss: 76.6410\n",
      "Epoch [45/100], Step[18700]: Train loss: 80.5677, Valid loss: 76.8776\n",
      "Epoch [45/100], Step[18800]: Train loss: 73.6212, Valid loss: 77.0257\n",
      "Epoch [46/100], Step[18900]: Train loss: 92.5269, Valid loss: 76.6173\n",
      "Epoch [46/100], Step[19000]: Train loss: 83.9098, Valid loss: 76.6336\n",
      "Epoch [46/100], Step[19100]: Train loss: 82.8947, Valid loss: 76.2622\n",
      "Epoch [46/100], Step[19200]: Train loss: 77.3101, Valid loss: 76.7476\n",
      "Epoch [47/100], Step[19300]: Train loss: 86.2233, Valid loss: 76.6374\n",
      "Epoch [47/100], Step[19400]: Train loss: 79.5656, Valid loss: 76.2064\n",
      "Epoch [47/100], Step[19500]: Train loss: 78.0997, Valid loss: 76.7812\n",
      "Epoch [47/100], Step[19600]: Train loss: 87.8386, Valid loss: 76.3472\n",
      "Epoch [48/100], Step[19700]: Train loss: 72.9697, Valid loss: 76.4127\n",
      "Epoch [48/100], Step[19800]: Train loss: 76.8642, Valid loss: 76.2188\n",
      "Epoch [48/100], Step[19900]: Train loss: 98.1984, Valid loss: 76.7007\n",
      "Epoch [48/100], Step[20000]: Train loss: 88.4588, Valid loss: 76.6299\n",
      "Epoch [49/100], Step[20100]: Train loss: 92.0256, Valid loss: 76.4781\n",
      "Epoch [49/100], Step[20200]: Train loss: 83.6826, Valid loss: 76.3150\n",
      "Epoch [49/100], Step[20300]: Train loss: 82.7219, Valid loss: 76.1210\n",
      "Epoch [49/100], Step[20400]: Train loss: 80.7862, Valid loss: 76.6045\n",
      "Epoch [50/100], Step[20500]: Train loss: 74.8760, Valid loss: 76.4268\n",
      "Epoch [50/100], Step[20600]: Train loss: 86.2420, Valid loss: 76.1512\n",
      "Epoch [50/100], Step[20700]: Train loss: 82.6484, Valid loss: 76.1264\n",
      "Epoch [50/100], Step[20800]: Train loss: 87.3299, Valid loss: 76.5374\n",
      "Epoch [50/100], Step[20900]: Train loss: 68.3094, Valid loss: 75.9995\n",
      "Saving model with loss 76.000...\n",
      "Epoch [51/100], Step[21000]: Train loss: 80.2706, Valid loss: 76.4779\n",
      "Epoch [51/100], Step[21100]: Train loss: 84.2697, Valid loss: 76.1535\n",
      "Epoch [51/100], Step[21200]: Train loss: 84.9945, Valid loss: 77.0609\n",
      "Epoch [51/100], Step[21300]: Train loss: 78.6122, Valid loss: 76.2073\n",
      "Epoch [52/100], Step[21400]: Train loss: 87.5798, Valid loss: 76.3170\n",
      "Epoch [52/100], Step[21500]: Train loss: 81.7909, Valid loss: 76.2778\n",
      "Epoch [52/100], Step[21600]: Train loss: 71.2977, Valid loss: 76.7643\n",
      "Epoch [52/100], Step[21700]: Train loss: 74.7811, Valid loss: 76.1816\n",
      "Epoch [53/100], Step[21800]: Train loss: 82.0172, Valid loss: 76.3304\n",
      "Epoch [53/100], Step[21900]: Train loss: 78.0173, Valid loss: 76.4099\n",
      "Epoch [53/100], Step[22000]: Train loss: 75.6037, Valid loss: 76.2713\n",
      "Epoch [53/100], Step[22100]: Train loss: 81.2255, Valid loss: 76.0868\n",
      "Epoch [54/100], Step[22200]: Train loss: 88.4400, Valid loss: 76.6327\n",
      "Epoch [54/100], Step[22300]: Train loss: 78.1647, Valid loss: 76.3699\n",
      "Epoch [54/100], Step[22400]: Train loss: 84.4607, Valid loss: 76.4221\n",
      "Epoch [54/100], Step[22500]: Train loss: 74.2977, Valid loss: 76.7470\n",
      "Epoch [55/100], Step[22600]: Train loss: 89.7821, Valid loss: 76.0748\n",
      "Epoch [55/100], Step[22700]: Train loss: 80.7186, Valid loss: 76.2802\n",
      "Epoch [55/100], Step[22800]: Train loss: 81.9086, Valid loss: 76.3668\n",
      "Epoch [55/100], Step[22900]: Train loss: 82.7534, Valid loss: 76.4164\n",
      "Epoch [56/100], Step[23000]: Train loss: 81.9031, Valid loss: 76.3819\n",
      "Epoch [56/100], Step[23100]: Train loss: 74.3395, Valid loss: 76.2047\n",
      "Epoch [56/100], Step[23200]: Train loss: 75.0677, Valid loss: 75.9918\n",
      "Saving model with loss 75.992...\n",
      "Epoch [56/100], Step[23300]: Train loss: 70.9246, Valid loss: 76.2072\n",
      "Epoch [56/100], Step[23400]: Train loss: 78.9203, Valid loss: 76.4932\n",
      "Epoch [57/100], Step[23500]: Train loss: 77.4129, Valid loss: 76.0116\n",
      "Epoch [57/100], Step[23600]: Train loss: 70.9976, Valid loss: 76.1762\n",
      "Epoch [57/100], Step[23700]: Train loss: 77.9644, Valid loss: 76.6960\n",
      "Epoch [57/100], Step[23800]: Train loss: 72.0651, Valid loss: 76.3331\n",
      "Epoch [58/100], Step[23900]: Train loss: 81.2267, Valid loss: 76.3841\n",
      "Epoch [58/100], Step[24000]: Train loss: 76.3314, Valid loss: 76.3941\n",
      "Epoch [58/100], Step[24100]: Train loss: 90.1105, Valid loss: 76.4941\n",
      "Epoch [58/100], Step[24200]: Train loss: 79.7546, Valid loss: 76.5196\n",
      "Epoch [59/100], Step[24300]: Train loss: 80.4369, Valid loss: 76.6301\n",
      "Epoch [59/100], Step[24400]: Train loss: 88.2404, Valid loss: 76.4187\n",
      "Epoch [59/100], Step[24500]: Train loss: 75.5611, Valid loss: 76.4880\n",
      "Epoch [59/100], Step[24600]: Train loss: 71.8417, Valid loss: 76.5011\n",
      "Epoch [60/100], Step[24700]: Train loss: 79.0104, Valid loss: 76.2387\n",
      "Epoch [60/100], Step[24800]: Train loss: 77.6874, Valid loss: 76.5616\n",
      "Epoch [60/100], Step[24900]: Train loss: 74.5540, Valid loss: 76.4565\n",
      "Epoch [60/100], Step[25000]: Train loss: 87.9308, Valid loss: 76.0615\n",
      "Epoch [61/100], Step[25100]: Train loss: 80.4711, Valid loss: 76.4393\n",
      "Epoch [61/100], Step[25200]: Train loss: 70.2354, Valid loss: 76.3709\n",
      "Epoch [61/100], Step[25300]: Train loss: 73.0716, Valid loss: 75.9789\n",
      "Saving model with loss 75.979...\n",
      "Epoch [61/100], Step[25400]: Train loss: 83.4005, Valid loss: 76.2740\n",
      "Epoch [62/100], Step[25500]: Train loss: 69.8193, Valid loss: 76.4745\n",
      "Epoch [62/100], Step[25600]: Train loss: 82.1260, Valid loss: 76.3805\n",
      "Epoch [62/100], Step[25700]: Train loss: 73.8628, Valid loss: 76.2400\n",
      "Epoch [62/100], Step[25800]: Train loss: 82.2972, Valid loss: 76.5140\n",
      "Epoch [62/100], Step[25900]: Train loss: 83.9175, Valid loss: 76.5141\n",
      "Epoch [63/100], Step[26000]: Train loss: 81.8391, Valid loss: 76.7307\n",
      "Epoch [63/100], Step[26100]: Train loss: 78.2851, Valid loss: 76.3048\n",
      "Epoch [63/100], Step[26200]: Train loss: 86.6102, Valid loss: 76.0568\n",
      "Epoch [63/100], Step[26300]: Train loss: 82.7662, Valid loss: 76.4266\n",
      "Epoch [64/100], Step[26400]: Train loss: 78.4540, Valid loss: 76.0037\n",
      "Epoch [64/100], Step[26500]: Train loss: 78.2921, Valid loss: 76.4645\n",
      "Epoch [64/100], Step[26600]: Train loss: 72.7566, Valid loss: 76.4783\n",
      "Epoch [64/100], Step[26700]: Train loss: 88.0986, Valid loss: 76.2556\n",
      "Epoch [65/100], Step[26800]: Train loss: 74.1625, Valid loss: 76.1027\n",
      "Epoch [65/100], Step[26900]: Train loss: 90.8279, Valid loss: 76.4104\n",
      "Epoch [65/100], Step[27000]: Train loss: 77.3629, Valid loss: 75.8732\n",
      "Saving model with loss 75.873...\n",
      "Epoch [65/100], Step[27100]: Train loss: 84.0670, Valid loss: 76.3817\n",
      "Epoch [66/100], Step[27200]: Train loss: 85.7438, Valid loss: 76.6582\n",
      "Epoch [66/100], Step[27300]: Train loss: 87.7058, Valid loss: 76.3894\n",
      "Epoch [66/100], Step[27400]: Train loss: 72.9402, Valid loss: 76.3427\n",
      "Epoch [66/100], Step[27500]: Train loss: 81.3853, Valid loss: 76.5071\n",
      "Epoch [67/100], Step[27600]: Train loss: 81.4721, Valid loss: 76.8078\n",
      "Epoch [67/100], Step[27700]: Train loss: 96.9678, Valid loss: 76.0678\n",
      "Epoch [67/100], Step[27800]: Train loss: 77.2511, Valid loss: 76.2025\n",
      "Epoch [67/100], Step[27900]: Train loss: 82.2960, Valid loss: 76.2545\n",
      "Epoch [67/100], Step[28000]: Train loss: 85.6418, Valid loss: 76.1715\n",
      "Epoch [68/100], Step[28100]: Train loss: 85.1736, Valid loss: 76.5109\n",
      "Epoch [68/100], Step[28200]: Train loss: 84.3460, Valid loss: 75.9802\n",
      "Epoch [68/100], Step[28300]: Train loss: 80.9772, Valid loss: 76.2573\n",
      "Epoch [68/100], Step[28400]: Train loss: 84.7410, Valid loss: 76.4525\n",
      "Epoch [69/100], Step[28500]: Train loss: 88.4809, Valid loss: 76.5849\n",
      "Epoch [69/100], Step[28600]: Train loss: 84.7790, Valid loss: 76.3547\n",
      "Epoch [69/100], Step[28700]: Train loss: 88.5446, Valid loss: 76.3265\n",
      "Epoch [69/100], Step[28800]: Train loss: 67.8240, Valid loss: 76.9822\n",
      "Epoch [70/100], Step[28900]: Train loss: 76.8106, Valid loss: 76.4449\n",
      "Epoch [70/100], Step[29000]: Train loss: 76.1057, Valid loss: 76.1868\n",
      "Epoch [70/100], Step[29100]: Train loss: 72.5978, Valid loss: 76.1415\n",
      "Epoch [70/100], Step[29200]: Train loss: 67.4722, Valid loss: 76.1075\n",
      "Epoch [71/100], Step[29300]: Train loss: 81.1890, Valid loss: 76.1800\n",
      "Epoch [71/100], Step[29400]: Train loss: 83.5827, Valid loss: 76.4919\n",
      "Epoch [71/100], Step[29500]: Train loss: 83.0080, Valid loss: 76.3934\n",
      "Epoch [71/100], Step[29600]: Train loss: 88.9878, Valid loss: 76.2636\n",
      "Epoch [72/100], Step[29700]: Train loss: 83.3021, Valid loss: 76.5118\n",
      "Epoch [72/100], Step[29800]: Train loss: 84.2360, Valid loss: 76.3520\n",
      "Epoch [72/100], Step[29900]: Train loss: 82.5775, Valid loss: 76.3679\n",
      "Epoch [72/100], Step[30000]: Train loss: 63.6805, Valid loss: 76.2516\n",
      "Epoch [73/100], Step[30100]: Train loss: 80.2562, Valid loss: 76.5067\n",
      "Epoch [73/100], Step[30200]: Train loss: 75.3410, Valid loss: 76.6394\n",
      "Epoch [73/100], Step[30300]: Train loss: 87.5868, Valid loss: 76.1719\n",
      "Epoch [73/100], Step[30400]: Train loss: 80.3160, Valid loss: 76.5018\n",
      "Epoch [73/100], Step[30500]: Train loss: 78.3936, Valid loss: 76.4326\n",
      "Epoch [74/100], Step[30600]: Train loss: 85.5881, Valid loss: 76.2274\n",
      "Epoch [74/100], Step[30700]: Train loss: 78.1619, Valid loss: 76.5521\n",
      "Epoch [74/100], Step[30800]: Train loss: 78.5357, Valid loss: 76.0841\n",
      "Epoch [74/100], Step[30900]: Train loss: 80.5931, Valid loss: 76.4508\n",
      "Epoch [75/100], Step[31000]: Train loss: 81.9468, Valid loss: 76.1168\n",
      "Epoch [75/100], Step[31100]: Train loss: 86.0922, Valid loss: 76.3422\n",
      "Epoch [75/100], Step[31200]: Train loss: 85.6676, Valid loss: 76.4035\n",
      "Epoch [75/100], Step[31300]: Train loss: 80.5514, Valid loss: 76.4630\n",
      "Epoch [76/100], Step[31400]: Train loss: 82.8550, Valid loss: 76.3825\n",
      "Epoch [76/100], Step[31500]: Train loss: 94.1502, Valid loss: 76.2608\n",
      "Epoch [76/100], Step[31600]: Train loss: 78.3143, Valid loss: 76.2116\n",
      "Epoch [76/100], Step[31700]: Train loss: 77.6982, Valid loss: 76.1293\n",
      "Epoch [77/100], Step[31800]: Train loss: 83.5699, Valid loss: 76.1374\n",
      "Epoch [77/100], Step[31900]: Train loss: 75.9859, Valid loss: 76.2364\n",
      "Epoch [77/100], Step[32000]: Train loss: 77.9000, Valid loss: 76.3197\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 86.4576, Valid loss: 85.0439\n",
      "Saving model with loss 85.044...\n",
      "Epoch [1/100], Step[200]: Train loss: 77.2024, Valid loss: 81.1668\n",
      "Saving model with loss 81.167...\n",
      "Epoch [1/100], Step[300]: Train loss: 87.1982, Valid loss: 79.4494\n",
      "Saving model with loss 79.449...\n",
      "Epoch [1/100], Step[400]: Train loss: 80.5807, Valid loss: 78.5087\n",
      "Saving model with loss 78.509...\n",
      "Epoch [2/100], Step[500]: Train loss: 82.2286, Valid loss: 77.9526\n",
      "Saving model with loss 77.953...\n",
      "Epoch [2/100], Step[600]: Train loss: 75.5153, Valid loss: 77.0196\n",
      "Saving model with loss 77.020...\n",
      "Epoch [2/100], Step[700]: Train loss: 72.6547, Valid loss: 76.8168\n",
      "Saving model with loss 76.817...\n",
      "Epoch [2/100], Step[800]: Train loss: 73.1820, Valid loss: 76.7403\n",
      "Saving model with loss 76.740...\n",
      "Epoch [3/100], Step[900]: Train loss: 87.5806, Valid loss: 76.8734\n",
      "Epoch [3/100], Step[1000]: Train loss: 91.6155, Valid loss: 75.8978\n",
      "Saving model with loss 75.898...\n",
      "Epoch [3/100], Step[1100]: Train loss: 84.4098, Valid loss: 76.3172\n",
      "Epoch [3/100], Step[1200]: Train loss: 71.8153, Valid loss: 76.3823\n",
      "Epoch [4/100], Step[1300]: Train loss: 77.4030, Valid loss: 75.6402\n",
      "Saving model with loss 75.640...\n",
      "Epoch [4/100], Step[1400]: Train loss: 78.8423, Valid loss: 75.6420\n",
      "Epoch [4/100], Step[1500]: Train loss: 72.5068, Valid loss: 75.5838\n",
      "Saving model with loss 75.584...\n",
      "Epoch [4/100], Step[1600]: Train loss: 71.0637, Valid loss: 75.2242\n",
      "Saving model with loss 75.224...\n",
      "Epoch [5/100], Step[1700]: Train loss: 77.6784, Valid loss: 75.1458\n",
      "Saving model with loss 75.146...\n",
      "Epoch [5/100], Step[1800]: Train loss: 79.9973, Valid loss: 74.9794\n",
      "Saving model with loss 74.979...\n",
      "Epoch [5/100], Step[1900]: Train loss: 74.4838, Valid loss: 74.5241\n",
      "Saving model with loss 74.524...\n",
      "Epoch [5/100], Step[2000]: Train loss: 80.4963, Valid loss: 74.6117\n",
      "Epoch [6/100], Step[2100]: Train loss: 85.9881, Valid loss: 74.8227\n",
      "Epoch [6/100], Step[2200]: Train loss: 71.9786, Valid loss: 74.4998\n",
      "Saving model with loss 74.500...\n",
      "Epoch [6/100], Step[2300]: Train loss: 78.5995, Valid loss: 74.1499\n",
      "Saving model with loss 74.150...\n",
      "Epoch [6/100], Step[2400]: Train loss: 84.1841, Valid loss: 74.4634\n",
      "Epoch [6/100], Step[2500]: Train loss: 81.0000, Valid loss: 74.1741\n",
      "Epoch [7/100], Step[2600]: Train loss: 89.2854, Valid loss: 74.6641\n",
      "Epoch [7/100], Step[2700]: Train loss: 78.8379, Valid loss: 74.5980\n",
      "Epoch [7/100], Step[2800]: Train loss: 74.8332, Valid loss: 74.5816\n",
      "Epoch [7/100], Step[2900]: Train loss: 76.7841, Valid loss: 74.3027\n",
      "Epoch [8/100], Step[3000]: Train loss: 74.8623, Valid loss: 74.1029\n",
      "Saving model with loss 74.103...\n",
      "Epoch [8/100], Step[3100]: Train loss: 76.2847, Valid loss: 74.4996\n",
      "Epoch [8/100], Step[3200]: Train loss: 76.9388, Valid loss: 74.6350\n",
      "Epoch [8/100], Step[3300]: Train loss: 77.9507, Valid loss: 74.0291\n",
      "Saving model with loss 74.029...\n",
      "Epoch [9/100], Step[3400]: Train loss: 64.7839, Valid loss: 74.2648\n",
      "Epoch [9/100], Step[3500]: Train loss: 70.2192, Valid loss: 74.6732\n",
      "Epoch [9/100], Step[3600]: Train loss: 93.1021, Valid loss: 74.1550\n",
      "Epoch [9/100], Step[3700]: Train loss: 70.9562, Valid loss: 74.2142\n",
      "Epoch [10/100], Step[3800]: Train loss: 78.7684, Valid loss: 74.4731\n",
      "Epoch [10/100], Step[3900]: Train loss: 79.9999, Valid loss: 74.0207\n",
      "Saving model with loss 74.021...\n",
      "Epoch [10/100], Step[4000]: Train loss: 70.4511, Valid loss: 73.7113\n",
      "Saving model with loss 73.711...\n",
      "Epoch [10/100], Step[4100]: Train loss: 88.9835, Valid loss: 73.6273\n",
      "Saving model with loss 73.627...\n",
      "Epoch [11/100], Step[4200]: Train loss: 77.1391, Valid loss: 73.9095\n",
      "Epoch [11/100], Step[4300]: Train loss: 73.3515, Valid loss: 74.0601\n",
      "Epoch [11/100], Step[4400]: Train loss: 80.3196, Valid loss: 74.3519\n",
      "Epoch [11/100], Step[4500]: Train loss: 80.9648, Valid loss: 74.3969\n",
      "Epoch [12/100], Step[4600]: Train loss: 83.2038, Valid loss: 73.7330\n",
      "Epoch [12/100], Step[4700]: Train loss: 75.6506, Valid loss: 73.5213\n",
      "Saving model with loss 73.521...\n",
      "Epoch [12/100], Step[4800]: Train loss: 79.2192, Valid loss: 73.5718\n",
      "Epoch [12/100], Step[4900]: Train loss: 74.0497, Valid loss: 73.8544\n",
      "Epoch [12/100], Step[5000]: Train loss: 81.3524, Valid loss: 73.7347\n",
      "Epoch [13/100], Step[5100]: Train loss: 73.0014, Valid loss: 73.4093\n",
      "Saving model with loss 73.409...\n",
      "Epoch [13/100], Step[5200]: Train loss: 76.4251, Valid loss: 73.5800\n",
      "Epoch [13/100], Step[5300]: Train loss: 76.8309, Valid loss: 73.4609\n",
      "Epoch [13/100], Step[5400]: Train loss: 74.0056, Valid loss: 73.5890\n",
      "Epoch [14/100], Step[5500]: Train loss: 87.1972, Valid loss: 73.5585\n",
      "Epoch [14/100], Step[5600]: Train loss: 82.0834, Valid loss: 73.1319\n",
      "Saving model with loss 73.132...\n",
      "Epoch [14/100], Step[5700]: Train loss: 88.8324, Valid loss: 73.7537\n",
      "Epoch [14/100], Step[5800]: Train loss: 68.9449, Valid loss: 73.5256\n",
      "Epoch [15/100], Step[5900]: Train loss: 68.7467, Valid loss: 73.0761\n",
      "Saving model with loss 73.076...\n",
      "Epoch [15/100], Step[6000]: Train loss: 78.6754, Valid loss: 73.4397\n",
      "Epoch [15/100], Step[6100]: Train loss: 78.8998, Valid loss: 73.4835\n",
      "Epoch [15/100], Step[6200]: Train loss: 62.9513, Valid loss: 73.4577\n",
      "Epoch [16/100], Step[6300]: Train loss: 78.8472, Valid loss: 73.5110\n",
      "Epoch [16/100], Step[6400]: Train loss: 71.1368, Valid loss: 73.3742\n",
      "Epoch [16/100], Step[6500]: Train loss: 70.3659, Valid loss: 73.0249\n",
      "Saving model with loss 73.025...\n",
      "Epoch [16/100], Step[6600]: Train loss: 82.4145, Valid loss: 72.9674\n",
      "Saving model with loss 72.967...\n",
      "Epoch [17/100], Step[6700]: Train loss: 69.9262, Valid loss: 73.8590\n",
      "Epoch [17/100], Step[6800]: Train loss: 74.6332, Valid loss: 73.5114\n",
      "Epoch [17/100], Step[6900]: Train loss: 74.5972, Valid loss: 73.3572\n",
      "Epoch [17/100], Step[7000]: Train loss: 81.6157, Valid loss: 73.2642\n",
      "Epoch [17/100], Step[7100]: Train loss: 70.1945, Valid loss: 73.1206\n",
      "Epoch [18/100], Step[7200]: Train loss: 63.9903, Valid loss: 73.0819\n",
      "Epoch [18/100], Step[7300]: Train loss: 73.0616, Valid loss: 73.0106\n",
      "Epoch [18/100], Step[7400]: Train loss: 83.3499, Valid loss: 73.3545\n",
      "Epoch [18/100], Step[7500]: Train loss: 77.5561, Valid loss: 73.2150\n",
      "Epoch [19/100], Step[7600]: Train loss: 59.0565, Valid loss: 72.9529\n",
      "Saving model with loss 72.953...\n",
      "Epoch [19/100], Step[7700]: Train loss: 70.3335, Valid loss: 73.0583\n",
      "Epoch [19/100], Step[7800]: Train loss: 65.1443, Valid loss: 72.7804\n",
      "Saving model with loss 72.780...\n",
      "Epoch [19/100], Step[7900]: Train loss: 77.3091, Valid loss: 73.2117\n",
      "Epoch [20/100], Step[8000]: Train loss: 72.1575, Valid loss: 73.4419\n",
      "Epoch [20/100], Step[8100]: Train loss: 61.3822, Valid loss: 73.3922\n",
      "Epoch [20/100], Step[8200]: Train loss: 63.2940, Valid loss: 72.9307\n",
      "Epoch [20/100], Step[8300]: Train loss: 69.5504, Valid loss: 73.1595\n",
      "Epoch [21/100], Step[8400]: Train loss: 75.7483, Valid loss: 73.1944\n",
      "Epoch [21/100], Step[8500]: Train loss: 84.4272, Valid loss: 72.9270\n",
      "Epoch [21/100], Step[8600]: Train loss: 67.3272, Valid loss: 73.2833\n",
      "Epoch [21/100], Step[8700]: Train loss: 76.7995, Valid loss: 72.6753\n",
      "Saving model with loss 72.675...\n",
      "Epoch [22/100], Step[8800]: Train loss: 67.5643, Valid loss: 72.9906\n",
      "Epoch [22/100], Step[8900]: Train loss: 71.0578, Valid loss: 72.8513\n",
      "Epoch [22/100], Step[9000]: Train loss: 69.2067, Valid loss: 72.9088\n",
      "Epoch [22/100], Step[9100]: Train loss: 80.8538, Valid loss: 72.5943\n",
      "Saving model with loss 72.594...\n",
      "Epoch [23/100], Step[9200]: Train loss: 80.7562, Valid loss: 72.4769\n",
      "Saving model with loss 72.477...\n",
      "Epoch [23/100], Step[9300]: Train loss: 82.1955, Valid loss: 72.9994\n",
      "Epoch [23/100], Step[9400]: Train loss: 66.6531, Valid loss: 72.6893\n",
      "Epoch [23/100], Step[9500]: Train loss: 75.7220, Valid loss: 72.7274\n",
      "Epoch [23/100], Step[9600]: Train loss: 73.8127, Valid loss: 72.9864\n",
      "Epoch [24/100], Step[9700]: Train loss: 69.1126, Valid loss: 72.6995\n",
      "Epoch [24/100], Step[9800]: Train loss: 67.9510, Valid loss: 72.5870\n",
      "Epoch [24/100], Step[9900]: Train loss: 74.2496, Valid loss: 72.6716\n",
      "Epoch [24/100], Step[10000]: Train loss: 76.6568, Valid loss: 72.6317\n",
      "Epoch [25/100], Step[10100]: Train loss: 65.4131, Valid loss: 72.6971\n",
      "Epoch [25/100], Step[10200]: Train loss: 76.5040, Valid loss: 72.5560\n",
      "Epoch [25/100], Step[10300]: Train loss: 71.4478, Valid loss: 72.7662\n",
      "Epoch [25/100], Step[10400]: Train loss: 68.4011, Valid loss: 72.4083\n",
      "Saving model with loss 72.408...\n",
      "Epoch [26/100], Step[10500]: Train loss: 72.2620, Valid loss: 72.7740\n",
      "Epoch [26/100], Step[10600]: Train loss: 68.1880, Valid loss: 72.5874\n",
      "Epoch [26/100], Step[10700]: Train loss: 77.7676, Valid loss: 72.5691\n",
      "Epoch [26/100], Step[10800]: Train loss: 74.1410, Valid loss: 73.1666\n",
      "Epoch [27/100], Step[10900]: Train loss: 68.1948, Valid loss: 72.4085\n",
      "Epoch [27/100], Step[11000]: Train loss: 67.6246, Valid loss: 72.5417\n",
      "Epoch [27/100], Step[11100]: Train loss: 74.6369, Valid loss: 72.9071\n",
      "Epoch [27/100], Step[11200]: Train loss: 81.0792, Valid loss: 72.6863\n",
      "Epoch [28/100], Step[11300]: Train loss: 74.0262, Valid loss: 72.5872\n",
      "Epoch [28/100], Step[11400]: Train loss: 76.2426, Valid loss: 72.5834\n",
      "Epoch [28/100], Step[11500]: Train loss: 80.9790, Valid loss: 73.2960\n",
      "Epoch [28/100], Step[11600]: Train loss: 76.5256, Valid loss: 72.6644\n",
      "Epoch [28/100], Step[11700]: Train loss: 67.9065, Valid loss: 72.7513\n",
      "Epoch [29/100], Step[11800]: Train loss: 76.5002, Valid loss: 72.6806\n",
      "Epoch [29/100], Step[11900]: Train loss: 81.8916, Valid loss: 72.9643\n",
      "Epoch [29/100], Step[12000]: Train loss: 86.3460, Valid loss: 72.8125\n",
      "Epoch [29/100], Step[12100]: Train loss: 68.3280, Valid loss: 72.6243\n",
      "Epoch [30/100], Step[12200]: Train loss: 76.8018, Valid loss: 72.6451\n",
      "Epoch [30/100], Step[12300]: Train loss: 58.2390, Valid loss: 72.8597\n",
      "Epoch [30/100], Step[12400]: Train loss: 70.6749, Valid loss: 72.4552\n",
      "Epoch [30/100], Step[12500]: Train loss: 86.1686, Valid loss: 72.5707\n",
      "Epoch [31/100], Step[12600]: Train loss: 72.7451, Valid loss: 72.8320\n",
      "Epoch [31/100], Step[12700]: Train loss: 72.1055, Valid loss: 72.6033\n",
      "Epoch [31/100], Step[12800]: Train loss: 74.4495, Valid loss: 72.7262\n",
      "Epoch [31/100], Step[12900]: Train loss: 82.3791, Valid loss: 72.6618\n",
      "Epoch [32/100], Step[13000]: Train loss: 72.8508, Valid loss: 72.4483\n",
      "Epoch [32/100], Step[13100]: Train loss: 72.9152, Valid loss: 72.3780\n",
      "Saving model with loss 72.378...\n",
      "Epoch [32/100], Step[13200]: Train loss: 70.9675, Valid loss: 72.4115\n",
      "Epoch [32/100], Step[13300]: Train loss: 76.1419, Valid loss: 72.7387\n",
      "Epoch [33/100], Step[13400]: Train loss: 58.3066, Valid loss: 72.4002\n",
      "Epoch [33/100], Step[13500]: Train loss: 77.2530, Valid loss: 72.2238\n",
      "Saving model with loss 72.224...\n",
      "Epoch [33/100], Step[13600]: Train loss: 68.2595, Valid loss: 72.9892\n",
      "Epoch [33/100], Step[13700]: Train loss: 71.4850, Valid loss: 72.2665\n",
      "Epoch [34/100], Step[13800]: Train loss: 85.4863, Valid loss: 72.5001\n",
      "Epoch [34/100], Step[13900]: Train loss: 69.1216, Valid loss: 72.4966\n",
      "Epoch [34/100], Step[14000]: Train loss: 74.7238, Valid loss: 72.4890\n",
      "Epoch [34/100], Step[14100]: Train loss: 79.5504, Valid loss: 72.5513\n",
      "Epoch [34/100], Step[14200]: Train loss: 77.9880, Valid loss: 72.2009\n",
      "Saving model with loss 72.201...\n",
      "Epoch [35/100], Step[14300]: Train loss: 71.4285, Valid loss: 73.0012\n",
      "Epoch [35/100], Step[14400]: Train loss: 84.7980, Valid loss: 72.8032\n",
      "Epoch [35/100], Step[14500]: Train loss: 73.8483, Valid loss: 72.7472\n",
      "Epoch [35/100], Step[14600]: Train loss: 78.1139, Valid loss: 72.9442\n",
      "Epoch [36/100], Step[14700]: Train loss: 80.5616, Valid loss: 72.6236\n",
      "Epoch [36/100], Step[14800]: Train loss: 74.1535, Valid loss: 72.4059\n",
      "Epoch [36/100], Step[14900]: Train loss: 69.5297, Valid loss: 72.4419\n",
      "Epoch [36/100], Step[15000]: Train loss: 70.1447, Valid loss: 72.7190\n",
      "Epoch [37/100], Step[15100]: Train loss: 62.3309, Valid loss: 72.7240\n",
      "Epoch [37/100], Step[15200]: Train loss: 69.1870, Valid loss: 72.7662\n",
      "Epoch [37/100], Step[15300]: Train loss: 64.8285, Valid loss: 72.7099\n",
      "Epoch [37/100], Step[15400]: Train loss: 66.6592, Valid loss: 73.0241\n",
      "Epoch [38/100], Step[15500]: Train loss: 67.0981, Valid loss: 72.6462\n",
      "Epoch [38/100], Step[15600]: Train loss: 73.5948, Valid loss: 71.9190\n",
      "Saving model with loss 71.919...\n",
      "Epoch [38/100], Step[15700]: Train loss: 73.6538, Valid loss: 72.4878\n",
      "Epoch [38/100], Step[15800]: Train loss: 74.3714, Valid loss: 72.4039\n",
      "Epoch [39/100], Step[15900]: Train loss: 74.4183, Valid loss: 72.2446\n",
      "Epoch [39/100], Step[16000]: Train loss: 71.6768, Valid loss: 72.0492\n",
      "Epoch [39/100], Step[16100]: Train loss: 76.9355, Valid loss: 72.7344\n",
      "Epoch [39/100], Step[16200]: Train loss: 76.4581, Valid loss: 72.5252\n",
      "Epoch [39/100], Step[16300]: Train loss: 73.0868, Valid loss: 72.4826\n",
      "Epoch [40/100], Step[16400]: Train loss: 70.8004, Valid loss: 72.2631\n",
      "Epoch [40/100], Step[16500]: Train loss: 75.1095, Valid loss: 72.3402\n",
      "Epoch [40/100], Step[16600]: Train loss: 72.5979, Valid loss: 72.1585\n",
      "Epoch [40/100], Step[16700]: Train loss: 65.3166, Valid loss: 72.5537\n",
      "Epoch [41/100], Step[16800]: Train loss: 79.6021, Valid loss: 72.3240\n",
      "Epoch [41/100], Step[16900]: Train loss: 73.8227, Valid loss: 72.1829\n",
      "Epoch [41/100], Step[17000]: Train loss: 74.6291, Valid loss: 72.2297\n",
      "Epoch [41/100], Step[17100]: Train loss: 67.6894, Valid loss: 72.2649\n",
      "Epoch [42/100], Step[17200]: Train loss: 68.2104, Valid loss: 72.6984\n",
      "Epoch [42/100], Step[17300]: Train loss: 73.7350, Valid loss: 72.4967\n",
      "Epoch [42/100], Step[17400]: Train loss: 82.5756, Valid loss: 72.3306\n",
      "Epoch [42/100], Step[17500]: Train loss: 66.2071, Valid loss: 72.2096\n",
      "Epoch [43/100], Step[17600]: Train loss: 73.5044, Valid loss: 72.3004\n",
      "Epoch [43/100], Step[17700]: Train loss: 71.4450, Valid loss: 72.3963\n",
      "Epoch [43/100], Step[17800]: Train loss: 70.4734, Valid loss: 72.3769\n",
      "Epoch [43/100], Step[17900]: Train loss: 67.0563, Valid loss: 72.5814\n",
      "Epoch [44/100], Step[18000]: Train loss: 78.2103, Valid loss: 71.9918\n",
      "Epoch [44/100], Step[18100]: Train loss: 79.1039, Valid loss: 72.2947\n",
      "Epoch [44/100], Step[18200]: Train loss: 85.6408, Valid loss: 72.5615\n",
      "Epoch [44/100], Step[18300]: Train loss: 73.8231, Valid loss: 72.9380\n",
      "Epoch [45/100], Step[18400]: Train loss: 80.5844, Valid loss: 71.9869\n",
      "Epoch [45/100], Step[18500]: Train loss: 72.0214, Valid loss: 72.0897\n",
      "Epoch [45/100], Step[18600]: Train loss: 66.9645, Valid loss: 72.5249\n",
      "Epoch [45/100], Step[18700]: Train loss: 68.7388, Valid loss: 72.4474\n",
      "Epoch [45/100], Step[18800]: Train loss: 89.1719, Valid loss: 72.4821\n",
      "Epoch [46/100], Step[18900]: Train loss: 69.2024, Valid loss: 71.7378\n",
      "Saving model with loss 71.738...\n",
      "Epoch [46/100], Step[19000]: Train loss: 68.1198, Valid loss: 72.0091\n",
      "Epoch [46/100], Step[19100]: Train loss: 88.6196, Valid loss: 72.1761\n",
      "Epoch [46/100], Step[19200]: Train loss: 70.1947, Valid loss: 72.0398\n",
      "Epoch [47/100], Step[19300]: Train loss: 68.6466, Valid loss: 72.1564\n",
      "Epoch [47/100], Step[19400]: Train loss: 74.4119, Valid loss: 72.2484\n",
      "Epoch [47/100], Step[19500]: Train loss: 74.9219, Valid loss: 72.4400\n",
      "Epoch [47/100], Step[19600]: Train loss: 79.8810, Valid loss: 72.5276\n",
      "Epoch [48/100], Step[19700]: Train loss: 73.9106, Valid loss: 72.5354\n",
      "Epoch [48/100], Step[19800]: Train loss: 79.1855, Valid loss: 72.2438\n",
      "Epoch [48/100], Step[19900]: Train loss: 64.5258, Valid loss: 72.0841\n",
      "Epoch [48/100], Step[20000]: Train loss: 78.1526, Valid loss: 72.3430\n",
      "Epoch [49/100], Step[20100]: Train loss: 67.7585, Valid loss: 71.9101\n",
      "Epoch [49/100], Step[20200]: Train loss: 81.2939, Valid loss: 72.3685\n",
      "Epoch [49/100], Step[20300]: Train loss: 70.8098, Valid loss: 71.8749\n",
      "Epoch [49/100], Step[20400]: Train loss: 72.3768, Valid loss: 72.2037\n",
      "Epoch [50/100], Step[20500]: Train loss: 75.7106, Valid loss: 72.0479\n",
      "Epoch [50/100], Step[20600]: Train loss: 63.3158, Valid loss: 72.5710\n",
      "Epoch [50/100], Step[20700]: Train loss: 77.3077, Valid loss: 72.4008\n",
      "Epoch [50/100], Step[20800]: Train loss: 77.6598, Valid loss: 71.7148\n",
      "Saving model with loss 71.715...\n",
      "Epoch [50/100], Step[20900]: Train loss: 71.8220, Valid loss: 71.6057\n",
      "Saving model with loss 71.606...\n",
      "Epoch [51/100], Step[21000]: Train loss: 65.4470, Valid loss: 71.8150\n",
      "Epoch [51/100], Step[21100]: Train loss: 70.5824, Valid loss: 71.9661\n",
      "Epoch [51/100], Step[21200]: Train loss: 71.3169, Valid loss: 72.0235\n",
      "Epoch [51/100], Step[21300]: Train loss: 66.4579, Valid loss: 71.8973\n",
      "Epoch [52/100], Step[21400]: Train loss: 68.1229, Valid loss: 72.0338\n",
      "Epoch [52/100], Step[21500]: Train loss: 76.6381, Valid loss: 71.9733\n",
      "Epoch [52/100], Step[21600]: Train loss: 69.6807, Valid loss: 71.9324\n",
      "Epoch [52/100], Step[21700]: Train loss: 77.6782, Valid loss: 72.0489\n",
      "Epoch [53/100], Step[21800]: Train loss: 77.4762, Valid loss: 71.7521\n",
      "Epoch [53/100], Step[21900]: Train loss: 71.8024, Valid loss: 71.6354\n",
      "Epoch [53/100], Step[22000]: Train loss: 69.2496, Valid loss: 72.1319\n",
      "Epoch [53/100], Step[22100]: Train loss: 80.8508, Valid loss: 72.3221\n",
      "Epoch [54/100], Step[22200]: Train loss: 70.7650, Valid loss: 71.8490\n",
      "Epoch [54/100], Step[22300]: Train loss: 70.5681, Valid loss: 72.1330\n",
      "Epoch [54/100], Step[22400]: Train loss: 78.0394, Valid loss: 72.4060\n",
      "Epoch [54/100], Step[22500]: Train loss: 76.1763, Valid loss: 71.6760\n",
      "Epoch [55/100], Step[22600]: Train loss: 68.4663, Valid loss: 71.9654\n",
      "Epoch [55/100], Step[22700]: Train loss: 74.6923, Valid loss: 72.1869\n",
      "Epoch [55/100], Step[22800]: Train loss: 69.4837, Valid loss: 72.0607\n",
      "Epoch [55/100], Step[22900]: Train loss: 77.5644, Valid loss: 72.1497\n",
      "Epoch [56/100], Step[23000]: Train loss: 77.0724, Valid loss: 71.9621\n",
      "Epoch [56/100], Step[23100]: Train loss: 71.1890, Valid loss: 72.0026\n",
      "Epoch [56/100], Step[23200]: Train loss: 81.0424, Valid loss: 72.4599\n",
      "Epoch [56/100], Step[23300]: Train loss: 66.5916, Valid loss: 72.2905\n",
      "Epoch [56/100], Step[23400]: Train loss: 78.2219, Valid loss: 71.8962\n",
      "Epoch [57/100], Step[23500]: Train loss: 78.3240, Valid loss: 72.2901\n",
      "Epoch [57/100], Step[23600]: Train loss: 76.0079, Valid loss: 72.2960\n",
      "Epoch [57/100], Step[23700]: Train loss: 68.5887, Valid loss: 71.9389\n",
      "Epoch [57/100], Step[23800]: Train loss: 69.2674, Valid loss: 72.0118\n",
      "Epoch [58/100], Step[23900]: Train loss: 72.7157, Valid loss: 72.2390\n",
      "Epoch [58/100], Step[24000]: Train loss: 64.1035, Valid loss: 72.1779\n",
      "Epoch [58/100], Step[24100]: Train loss: 83.3355, Valid loss: 72.0647\n",
      "Epoch [58/100], Step[24200]: Train loss: 76.0610, Valid loss: 71.9658\n",
      "Epoch [59/100], Step[24300]: Train loss: 78.5714, Valid loss: 72.1580\n",
      "Epoch [59/100], Step[24400]: Train loss: 81.3842, Valid loss: 72.4198\n",
      "Epoch [59/100], Step[24500]: Train loss: 69.2042, Valid loss: 72.2232\n",
      "Epoch [59/100], Step[24600]: Train loss: 60.8814, Valid loss: 71.8595\n",
      "Epoch [60/100], Step[24700]: Train loss: 68.9790, Valid loss: 72.0158\n",
      "Epoch [60/100], Step[24800]: Train loss: 84.7076, Valid loss: 71.7723\n",
      "Epoch [60/100], Step[24900]: Train loss: 79.1680, Valid loss: 72.0361\n",
      "Epoch [60/100], Step[25000]: Train loss: 68.4411, Valid loss: 72.1842\n",
      "Epoch [61/100], Step[25100]: Train loss: 74.7706, Valid loss: 72.0566\n",
      "Epoch [61/100], Step[25200]: Train loss: 75.4039, Valid loss: 71.7891\n",
      "Epoch [61/100], Step[25300]: Train loss: 69.0340, Valid loss: 72.1241\n",
      "Epoch [61/100], Step[25400]: Train loss: 72.7122, Valid loss: 72.0076\n",
      "Epoch [62/100], Step[25500]: Train loss: 78.6760, Valid loss: 72.5426\n",
      "Epoch [62/100], Step[25600]: Train loss: 80.2148, Valid loss: 71.8410\n",
      "Epoch [62/100], Step[25700]: Train loss: 61.5215, Valid loss: 71.9784\n",
      "Epoch [62/100], Step[25800]: Train loss: 77.5781, Valid loss: 71.9133\n",
      "Epoch [62/100], Step[25900]: Train loss: 80.2647, Valid loss: 72.0217\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 83.4702, Valid loss: 82.2154\n",
      "Saving model with loss 82.215...\n",
      "Epoch [1/100], Step[200]: Train loss: 90.5579, Valid loss: 79.9456\n",
      "Saving model with loss 79.946...\n",
      "Epoch [1/100], Step[300]: Train loss: 82.9211, Valid loss: 78.5458\n",
      "Saving model with loss 78.546...\n",
      "Epoch [1/100], Step[400]: Train loss: 82.1158, Valid loss: 77.2682\n",
      "Saving model with loss 77.268...\n",
      "Epoch [2/100], Step[500]: Train loss: 75.1507, Valid loss: 76.7296\n",
      "Saving model with loss 76.730...\n",
      "Epoch [2/100], Step[600]: Train loss: 69.9539, Valid loss: 76.5431\n",
      "Saving model with loss 76.543...\n",
      "Epoch [2/100], Step[700]: Train loss: 87.6506, Valid loss: 75.7657\n",
      "Saving model with loss 75.766...\n",
      "Epoch [2/100], Step[800]: Train loss: 74.1230, Valid loss: 76.1805\n",
      "Epoch [3/100], Step[900]: Train loss: 80.8862, Valid loss: 75.3226\n",
      "Saving model with loss 75.323...\n",
      "Epoch [3/100], Step[1000]: Train loss: 68.2595, Valid loss: 74.9307\n",
      "Saving model with loss 74.931...\n",
      "Epoch [3/100], Step[1100]: Train loss: 77.7862, Valid loss: 75.3693\n",
      "Epoch [3/100], Step[1200]: Train loss: 74.8297, Valid loss: 75.0654\n",
      "Epoch [4/100], Step[1300]: Train loss: 78.0830, Valid loss: 75.3739\n",
      "Epoch [4/100], Step[1400]: Train loss: 76.3978, Valid loss: 74.5768\n",
      "Saving model with loss 74.577...\n",
      "Epoch [4/100], Step[1500]: Train loss: 81.2949, Valid loss: 74.6066\n",
      "Epoch [4/100], Step[1600]: Train loss: 87.4770, Valid loss: 74.8796\n",
      "Epoch [5/100], Step[1700]: Train loss: 70.4964, Valid loss: 74.1237\n",
      "Saving model with loss 74.124...\n",
      "Epoch [5/100], Step[1800]: Train loss: 74.6835, Valid loss: 74.7467\n",
      "Epoch [5/100], Step[1900]: Train loss: 73.7032, Valid loss: 74.4223\n",
      "Epoch [5/100], Step[2000]: Train loss: 62.8533, Valid loss: 74.1271\n",
      "Epoch [6/100], Step[2100]: Train loss: 86.5610, Valid loss: 73.7992\n",
      "Saving model with loss 73.799...\n",
      "Epoch [6/100], Step[2200]: Train loss: 68.2974, Valid loss: 74.2857\n",
      "Epoch [6/100], Step[2300]: Train loss: 75.8895, Valid loss: 74.3347\n",
      "Epoch [6/100], Step[2400]: Train loss: 73.0674, Valid loss: 74.1387\n",
      "Epoch [6/100], Step[2500]: Train loss: 79.0873, Valid loss: 73.5355\n",
      "Saving model with loss 73.535...\n",
      "Epoch [7/100], Step[2600]: Train loss: 77.4104, Valid loss: 73.3215\n",
      "Saving model with loss 73.322...\n",
      "Epoch [7/100], Step[2700]: Train loss: 74.2033, Valid loss: 73.0961\n",
      "Saving model with loss 73.096...\n",
      "Epoch [7/100], Step[2800]: Train loss: 67.7097, Valid loss: 73.4264\n",
      "Epoch [7/100], Step[2900]: Train loss: 82.4733, Valid loss: 73.4924\n",
      "Epoch [8/100], Step[3000]: Train loss: 82.4249, Valid loss: 73.0813\n",
      "Saving model with loss 73.081...\n",
      "Epoch [8/100], Step[3100]: Train loss: 81.4750, Valid loss: 73.4598\n",
      "Epoch [8/100], Step[3200]: Train loss: 63.3525, Valid loss: 73.2553\n",
      "Epoch [8/100], Step[3300]: Train loss: 71.7381, Valid loss: 73.4283\n",
      "Epoch [9/100], Step[3400]: Train loss: 66.2775, Valid loss: 73.1372\n",
      "Epoch [9/100], Step[3500]: Train loss: 77.4490, Valid loss: 73.1035\n",
      "Epoch [9/100], Step[3600]: Train loss: 67.9550, Valid loss: 73.2984\n",
      "Epoch [9/100], Step[3700]: Train loss: 77.1511, Valid loss: 73.7508\n",
      "Epoch [10/100], Step[3800]: Train loss: 65.3579, Valid loss: 73.3521\n",
      "Epoch [10/100], Step[3900]: Train loss: 68.0100, Valid loss: 73.4562\n",
      "Epoch [10/100], Step[4000]: Train loss: 77.9265, Valid loss: 73.5057\n",
      "Epoch [10/100], Step[4100]: Train loss: 65.8453, Valid loss: 73.0797\n",
      "Saving model with loss 73.080...\n",
      "Epoch [11/100], Step[4200]: Train loss: 66.6411, Valid loss: 73.1196\n",
      "Epoch [11/100], Step[4300]: Train loss: 76.2781, Valid loss: 72.8048\n",
      "Saving model with loss 72.805...\n",
      "Epoch [11/100], Step[4400]: Train loss: 73.8351, Valid loss: 72.8695\n",
      "Epoch [11/100], Step[4500]: Train loss: 84.2726, Valid loss: 73.1266\n",
      "Epoch [12/100], Step[4600]: Train loss: 74.9751, Valid loss: 72.5406\n",
      "Saving model with loss 72.541...\n",
      "Epoch [12/100], Step[4700]: Train loss: 72.3723, Valid loss: 72.9439\n",
      "Epoch [12/100], Step[4800]: Train loss: 74.6122, Valid loss: 73.5080\n",
      "Epoch [12/100], Step[4900]: Train loss: 76.7399, Valid loss: 72.8655\n",
      "Epoch [12/100], Step[5000]: Train loss: 61.5662, Valid loss: 72.7629\n",
      "Epoch [13/100], Step[5100]: Train loss: 67.7478, Valid loss: 72.2191\n",
      "Saving model with loss 72.219...\n",
      "Epoch [13/100], Step[5200]: Train loss: 81.3387, Valid loss: 73.4641\n",
      "Epoch [13/100], Step[5300]: Train loss: 74.4129, Valid loss: 72.5697\n",
      "Epoch [13/100], Step[5400]: Train loss: 72.7056, Valid loss: 72.6014\n",
      "Epoch [14/100], Step[5500]: Train loss: 73.1050, Valid loss: 72.8339\n",
      "Epoch [14/100], Step[5600]: Train loss: 69.2676, Valid loss: 72.1393\n",
      "Saving model with loss 72.139...\n",
      "Epoch [14/100], Step[5700]: Train loss: 64.9940, Valid loss: 72.5926\n",
      "Epoch [14/100], Step[5800]: Train loss: 72.1683, Valid loss: 72.3164\n",
      "Epoch [15/100], Step[5900]: Train loss: 76.5136, Valid loss: 73.1125\n",
      "Epoch [15/100], Step[6000]: Train loss: 74.6513, Valid loss: 72.3946\n",
      "Epoch [15/100], Step[6100]: Train loss: 73.7675, Valid loss: 72.8533\n",
      "Epoch [15/100], Step[6200]: Train loss: 63.2463, Valid loss: 72.1894\n",
      "Epoch [16/100], Step[6300]: Train loss: 65.3378, Valid loss: 72.8480\n",
      "Epoch [16/100], Step[6400]: Train loss: 71.1277, Valid loss: 72.1786\n",
      "Epoch [16/100], Step[6500]: Train loss: 70.6374, Valid loss: 72.4210\n",
      "Epoch [16/100], Step[6600]: Train loss: 78.1938, Valid loss: 72.2594\n",
      "Epoch [17/100], Step[6700]: Train loss: 67.7772, Valid loss: 72.2020\n",
      "Epoch [17/100], Step[6800]: Train loss: 65.6418, Valid loss: 72.1007\n",
      "Saving model with loss 72.101...\n",
      "Epoch [17/100], Step[6900]: Train loss: 77.3328, Valid loss: 72.1715\n",
      "Epoch [17/100], Step[7000]: Train loss: 66.4611, Valid loss: 71.8906\n",
      "Saving model with loss 71.891...\n",
      "Epoch [17/100], Step[7100]: Train loss: 62.3621, Valid loss: 73.0146\n",
      "Epoch [18/100], Step[7200]: Train loss: 70.3689, Valid loss: 72.6174\n",
      "Epoch [18/100], Step[7300]: Train loss: 68.9462, Valid loss: 72.2061\n",
      "Epoch [18/100], Step[7400]: Train loss: 70.6449, Valid loss: 72.2446\n",
      "Epoch [18/100], Step[7500]: Train loss: 71.8774, Valid loss: 71.9275\n",
      "Epoch [19/100], Step[7600]: Train loss: 69.9500, Valid loss: 72.1958\n",
      "Epoch [19/100], Step[7700]: Train loss: 75.8292, Valid loss: 71.9753\n",
      "Epoch [19/100], Step[7800]: Train loss: 67.6399, Valid loss: 72.0438\n",
      "Epoch [19/100], Step[7900]: Train loss: 71.9548, Valid loss: 72.0793\n",
      "Epoch [20/100], Step[8000]: Train loss: 66.0058, Valid loss: 71.8065\n",
      "Saving model with loss 71.807...\n",
      "Epoch [20/100], Step[8100]: Train loss: 68.9872, Valid loss: 72.0252\n",
      "Epoch [20/100], Step[8200]: Train loss: 64.5151, Valid loss: 71.7429\n",
      "Saving model with loss 71.743...\n",
      "Epoch [20/100], Step[8300]: Train loss: 66.4516, Valid loss: 72.1626\n",
      "Epoch [21/100], Step[8400]: Train loss: 67.9411, Valid loss: 71.9195\n",
      "Epoch [21/100], Step[8500]: Train loss: 64.0048, Valid loss: 71.9295\n",
      "Epoch [21/100], Step[8600]: Train loss: 66.3520, Valid loss: 71.8883\n",
      "Epoch [21/100], Step[8700]: Train loss: 70.7612, Valid loss: 72.4933\n",
      "Epoch [22/100], Step[8800]: Train loss: 73.6814, Valid loss: 71.8473\n",
      "Epoch [22/100], Step[8900]: Train loss: 74.3182, Valid loss: 72.3308\n",
      "Epoch [22/100], Step[9000]: Train loss: 69.1935, Valid loss: 71.5243\n",
      "Saving model with loss 71.524...\n",
      "Epoch [22/100], Step[9100]: Train loss: 68.2467, Valid loss: 71.9746\n",
      "Epoch [23/100], Step[9200]: Train loss: 71.6060, Valid loss: 71.5799\n",
      "Epoch [23/100], Step[9300]: Train loss: 65.9264, Valid loss: 71.5549\n",
      "Epoch [23/100], Step[9400]: Train loss: 68.5527, Valid loss: 71.5887\n",
      "Epoch [23/100], Step[9500]: Train loss: 66.8463, Valid loss: 71.6031\n",
      "Epoch [23/100], Step[9600]: Train loss: 71.7041, Valid loss: 72.3108\n",
      "Epoch [24/100], Step[9700]: Train loss: 74.3195, Valid loss: 71.9325\n",
      "Epoch [24/100], Step[9800]: Train loss: 75.3240, Valid loss: 71.5315\n",
      "Epoch [24/100], Step[9900]: Train loss: 80.4416, Valid loss: 71.9722\n",
      "Epoch [24/100], Step[10000]: Train loss: 75.2765, Valid loss: 71.9833\n",
      "Epoch [25/100], Step[10100]: Train loss: 77.9741, Valid loss: 72.2067\n",
      "Epoch [25/100], Step[10200]: Train loss: 71.7696, Valid loss: 71.9089\n",
      "Epoch [25/100], Step[10300]: Train loss: 74.1165, Valid loss: 71.5746\n",
      "Epoch [25/100], Step[10400]: Train loss: 64.3106, Valid loss: 71.1833\n",
      "Saving model with loss 71.183...\n",
      "Epoch [26/100], Step[10500]: Train loss: 79.1702, Valid loss: 72.0983\n",
      "Epoch [26/100], Step[10600]: Train loss: 73.8522, Valid loss: 71.8195\n",
      "Epoch [26/100], Step[10700]: Train loss: 72.7413, Valid loss: 71.5084\n",
      "Epoch [26/100], Step[10800]: Train loss: 70.9660, Valid loss: 71.6578\n",
      "Epoch [27/100], Step[10900]: Train loss: 72.5254, Valid loss: 71.6214\n",
      "Epoch [27/100], Step[11000]: Train loss: 66.3955, Valid loss: 71.8516\n",
      "Epoch [27/100], Step[11100]: Train loss: 63.0357, Valid loss: 71.7471\n",
      "Epoch [27/100], Step[11200]: Train loss: 71.0521, Valid loss: 71.7419\n",
      "Epoch [28/100], Step[11300]: Train loss: 70.7269, Valid loss: 71.6815\n",
      "Epoch [28/100], Step[11400]: Train loss: 71.9162, Valid loss: 71.7438\n",
      "Epoch [28/100], Step[11500]: Train loss: 70.5317, Valid loss: 71.4218\n",
      "Epoch [28/100], Step[11600]: Train loss: 92.6314, Valid loss: 71.1163\n",
      "Saving model with loss 71.116...\n",
      "Epoch [28/100], Step[11700]: Train loss: 71.5051, Valid loss: 71.4850\n",
      "Epoch [29/100], Step[11800]: Train loss: 65.0233, Valid loss: 71.3883\n",
      "Epoch [29/100], Step[11900]: Train loss: 80.7876, Valid loss: 71.5716\n",
      "Epoch [29/100], Step[12000]: Train loss: 75.7519, Valid loss: 71.2065\n",
      "Epoch [29/100], Step[12100]: Train loss: 83.1657, Valid loss: 71.1356\n",
      "Epoch [30/100], Step[12200]: Train loss: 73.6568, Valid loss: 71.0136\n",
      "Saving model with loss 71.014...\n",
      "Epoch [30/100], Step[12300]: Train loss: 64.0713, Valid loss: 71.0389\n",
      "Epoch [30/100], Step[12400]: Train loss: 67.8387, Valid loss: 71.2575\n",
      "Epoch [30/100], Step[12500]: Train loss: 68.3170, Valid loss: 70.8752\n",
      "Saving model with loss 70.875...\n",
      "Epoch [31/100], Step[12600]: Train loss: 70.1106, Valid loss: 71.8561\n",
      "Epoch [31/100], Step[12700]: Train loss: 71.8549, Valid loss: 71.0858\n",
      "Epoch [31/100], Step[12800]: Train loss: 70.0775, Valid loss: 71.1019\n",
      "Epoch [31/100], Step[12900]: Train loss: 62.2321, Valid loss: 70.8678\n",
      "Saving model with loss 70.868...\n",
      "Epoch [32/100], Step[13000]: Train loss: 69.8167, Valid loss: 71.3278\n",
      "Epoch [32/100], Step[13100]: Train loss: 64.5877, Valid loss: 70.8559\n",
      "Saving model with loss 70.856...\n",
      "Epoch [32/100], Step[13200]: Train loss: 73.6373, Valid loss: 71.4279\n",
      "Epoch [32/100], Step[13300]: Train loss: 75.7956, Valid loss: 71.1458\n",
      "Epoch [33/100], Step[13400]: Train loss: 61.6680, Valid loss: 71.3839\n",
      "Epoch [33/100], Step[13500]: Train loss: 75.3800, Valid loss: 71.1829\n",
      "Epoch [33/100], Step[13600]: Train loss: 76.0971, Valid loss: 71.2345\n",
      "Epoch [33/100], Step[13700]: Train loss: 62.9525, Valid loss: 70.9086\n",
      "Epoch [34/100], Step[13800]: Train loss: 70.4848, Valid loss: 71.1673\n",
      "Epoch [34/100], Step[13900]: Train loss: 80.8182, Valid loss: 71.0433\n",
      "Epoch [34/100], Step[14000]: Train loss: 60.9907, Valid loss: 71.3520\n",
      "Epoch [34/100], Step[14100]: Train loss: 79.8240, Valid loss: 70.9243\n",
      "Epoch [34/100], Step[14200]: Train loss: 69.6499, Valid loss: 71.2245\n",
      "Epoch [35/100], Step[14300]: Train loss: 71.1514, Valid loss: 71.1423\n",
      "Epoch [35/100], Step[14400]: Train loss: 71.0396, Valid loss: 71.1074\n",
      "Epoch [35/100], Step[14500]: Train loss: 65.2307, Valid loss: 71.2111\n",
      "Epoch [35/100], Step[14600]: Train loss: 65.7602, Valid loss: 71.1482\n",
      "Epoch [36/100], Step[14700]: Train loss: 65.0180, Valid loss: 70.9348\n",
      "Epoch [36/100], Step[14800]: Train loss: 75.9267, Valid loss: 70.7806\n",
      "Saving model with loss 70.781...\n",
      "Epoch [36/100], Step[14900]: Train loss: 62.3560, Valid loss: 71.0721\n",
      "Epoch [36/100], Step[15000]: Train loss: 71.1460, Valid loss: 70.8502\n",
      "Epoch [37/100], Step[15100]: Train loss: 79.0906, Valid loss: 70.7274\n",
      "Saving model with loss 70.727...\n",
      "Epoch [37/100], Step[15200]: Train loss: 72.9344, Valid loss: 71.4767\n",
      "Epoch [37/100], Step[15300]: Train loss: 73.1911, Valid loss: 70.7128\n",
      "Saving model with loss 70.713...\n",
      "Epoch [37/100], Step[15400]: Train loss: 75.0389, Valid loss: 70.7422\n",
      "Epoch [38/100], Step[15500]: Train loss: 72.3491, Valid loss: 70.9522\n",
      "Epoch [38/100], Step[15600]: Train loss: 64.7446, Valid loss: 70.9459\n",
      "Epoch [38/100], Step[15700]: Train loss: 69.8731, Valid loss: 71.0948\n",
      "Epoch [38/100], Step[15800]: Train loss: 68.0098, Valid loss: 71.5211\n",
      "Epoch [39/100], Step[15900]: Train loss: 73.8809, Valid loss: 70.5841\n",
      "Saving model with loss 70.584...\n",
      "Epoch [39/100], Step[16000]: Train loss: 73.5821, Valid loss: 71.0147\n",
      "Epoch [39/100], Step[16100]: Train loss: 63.6183, Valid loss: 71.3812\n",
      "Epoch [39/100], Step[16200]: Train loss: 68.2919, Valid loss: 70.5962\n",
      "Epoch [39/100], Step[16300]: Train loss: 84.4315, Valid loss: 71.2720\n",
      "Epoch [40/100], Step[16400]: Train loss: 77.5694, Valid loss: 70.7621\n",
      "Epoch [40/100], Step[16500]: Train loss: 74.9182, Valid loss: 70.9767\n",
      "Epoch [40/100], Step[16600]: Train loss: 71.9486, Valid loss: 70.8836\n",
      "Epoch [40/100], Step[16700]: Train loss: 69.3082, Valid loss: 70.7183\n",
      "Epoch [41/100], Step[16800]: Train loss: 72.1031, Valid loss: 71.3779\n",
      "Epoch [41/100], Step[16900]: Train loss: 64.4882, Valid loss: 70.6410\n",
      "Epoch [41/100], Step[17000]: Train loss: 67.1795, Valid loss: 70.9464\n",
      "Epoch [41/100], Step[17100]: Train loss: 74.0432, Valid loss: 70.3360\n",
      "Saving model with loss 70.336...\n",
      "Epoch [42/100], Step[17200]: Train loss: 73.3706, Valid loss: 70.5977\n",
      "Epoch [42/100], Step[17300]: Train loss: 65.7131, Valid loss: 71.4248\n",
      "Epoch [42/100], Step[17400]: Train loss: 72.8227, Valid loss: 70.5161\n",
      "Epoch [42/100], Step[17500]: Train loss: 69.7869, Valid loss: 70.8493\n",
      "Epoch [43/100], Step[17600]: Train loss: 68.0969, Valid loss: 70.9237\n",
      "Epoch [43/100], Step[17700]: Train loss: 72.3438, Valid loss: 70.8703\n",
      "Epoch [43/100], Step[17800]: Train loss: 67.8207, Valid loss: 70.6506\n",
      "Epoch [43/100], Step[17900]: Train loss: 71.4266, Valid loss: 70.6286\n",
      "Epoch [44/100], Step[18000]: Train loss: 66.2367, Valid loss: 70.9180\n",
      "Epoch [44/100], Step[18100]: Train loss: 64.4139, Valid loss: 70.6447\n",
      "Epoch [44/100], Step[18200]: Train loss: 66.8172, Valid loss: 71.1721\n",
      "Epoch [44/100], Step[18300]: Train loss: 78.7550, Valid loss: 71.0583\n",
      "Epoch [45/100], Step[18400]: Train loss: 73.1223, Valid loss: 70.8047\n",
      "Epoch [45/100], Step[18500]: Train loss: 66.0645, Valid loss: 70.7768\n",
      "Epoch [45/100], Step[18600]: Train loss: 56.9312, Valid loss: 70.8158\n",
      "Epoch [45/100], Step[18700]: Train loss: 69.8257, Valid loss: 70.7454\n",
      "Epoch [45/100], Step[18800]: Train loss: 69.9454, Valid loss: 70.9616\n",
      "Epoch [46/100], Step[18900]: Train loss: 71.7741, Valid loss: 70.8772\n",
      "Epoch [46/100], Step[19000]: Train loss: 62.5330, Valid loss: 70.6842\n",
      "Epoch [46/100], Step[19100]: Train loss: 67.8840, Valid loss: 70.7527\n",
      "Epoch [46/100], Step[19200]: Train loss: 73.3183, Valid loss: 70.3776\n",
      "Epoch [47/100], Step[19300]: Train loss: 66.1575, Valid loss: 70.6431\n",
      "Epoch [47/100], Step[19400]: Train loss: 69.2802, Valid loss: 70.7740\n",
      "Epoch [47/100], Step[19500]: Train loss: 82.0830, Valid loss: 70.7594\n",
      "Epoch [47/100], Step[19600]: Train loss: 61.4706, Valid loss: 70.3623\n",
      "Epoch [48/100], Step[19700]: Train loss: 65.5669, Valid loss: 70.8257\n",
      "Epoch [48/100], Step[19800]: Train loss: 70.8097, Valid loss: 70.3313\n",
      "Saving model with loss 70.331...\n",
      "Epoch [48/100], Step[19900]: Train loss: 68.5809, Valid loss: 71.0390\n",
      "Epoch [48/100], Step[20000]: Train loss: 63.3391, Valid loss: 70.6021\n",
      "Epoch [49/100], Step[20100]: Train loss: 69.0648, Valid loss: 70.6524\n",
      "Epoch [49/100], Step[20200]: Train loss: 71.7000, Valid loss: 70.6954\n",
      "Epoch [49/100], Step[20300]: Train loss: 73.7728, Valid loss: 71.1313\n",
      "Epoch [49/100], Step[20400]: Train loss: 74.4680, Valid loss: 70.8389\n",
      "Epoch [50/100], Step[20500]: Train loss: 64.1384, Valid loss: 71.5445\n",
      "Epoch [50/100], Step[20600]: Train loss: 66.8573, Valid loss: 71.0094\n",
      "Epoch [50/100], Step[20700]: Train loss: 62.8870, Valid loss: 70.7080\n",
      "Epoch [50/100], Step[20800]: Train loss: 66.7421, Valid loss: 70.6003\n",
      "Epoch [50/100], Step[20900]: Train loss: 67.1315, Valid loss: 71.0484\n",
      "Epoch [51/100], Step[21000]: Train loss: 76.5557, Valid loss: 71.1321\n",
      "Epoch [51/100], Step[21100]: Train loss: 69.6092, Valid loss: 70.5431\n",
      "Epoch [51/100], Step[21200]: Train loss: 61.0320, Valid loss: 70.7582\n",
      "Epoch [51/100], Step[21300]: Train loss: 70.9942, Valid loss: 70.9675\n",
      "Epoch [52/100], Step[21400]: Train loss: 64.7059, Valid loss: 70.8374\n",
      "Epoch [52/100], Step[21500]: Train loss: 71.7347, Valid loss: 71.5946\n",
      "Epoch [52/100], Step[21600]: Train loss: 73.7900, Valid loss: 70.4729\n",
      "Epoch [52/100], Step[21700]: Train loss: 78.6752, Valid loss: 70.2596\n",
      "Saving model with loss 70.260...\n",
      "Epoch [53/100], Step[21800]: Train loss: 66.9786, Valid loss: 70.7099\n",
      "Epoch [53/100], Step[21900]: Train loss: 72.1914, Valid loss: 70.5537\n",
      "Epoch [53/100], Step[22000]: Train loss: 68.8364, Valid loss: 70.8338\n",
      "Epoch [53/100], Step[22100]: Train loss: 70.5867, Valid loss: 70.7272\n",
      "Epoch [54/100], Step[22200]: Train loss: 61.4666, Valid loss: 71.0108\n",
      "Epoch [54/100], Step[22300]: Train loss: 74.7259, Valid loss: 70.4234\n",
      "Epoch [54/100], Step[22400]: Train loss: 70.2271, Valid loss: 70.9655\n",
      "Epoch [54/100], Step[22500]: Train loss: 78.5038, Valid loss: 70.8987\n",
      "Epoch [55/100], Step[22600]: Train loss: 63.3425, Valid loss: 70.9460\n",
      "Epoch [55/100], Step[22700]: Train loss: 69.9084, Valid loss: 70.4951\n",
      "Epoch [55/100], Step[22800]: Train loss: 66.3834, Valid loss: 70.7893\n",
      "Epoch [55/100], Step[22900]: Train loss: 60.3571, Valid loss: 70.5350\n",
      "Epoch [56/100], Step[23000]: Train loss: 74.4150, Valid loss: 70.3977\n",
      "Epoch [56/100], Step[23100]: Train loss: 67.7464, Valid loss: 71.1738\n",
      "Epoch [56/100], Step[23200]: Train loss: 68.8813, Valid loss: 71.1377\n",
      "Epoch [56/100], Step[23300]: Train loss: 67.1521, Valid loss: 70.6654\n",
      "Epoch [56/100], Step[23400]: Train loss: 70.7805, Valid loss: 70.5236\n",
      "Epoch [57/100], Step[23500]: Train loss: 65.8344, Valid loss: 70.8186\n",
      "Epoch [57/100], Step[23600]: Train loss: 75.2046, Valid loss: 70.8571\n",
      "Epoch [57/100], Step[23700]: Train loss: 63.6219, Valid loss: 70.7141\n",
      "Epoch [57/100], Step[23800]: Train loss: 70.5991, Valid loss: 70.8764\n",
      "Epoch [58/100], Step[23900]: Train loss: 64.8056, Valid loss: 71.0694\n",
      "Epoch [58/100], Step[24000]: Train loss: 68.5190, Valid loss: 70.9618\n",
      "Epoch [58/100], Step[24100]: Train loss: 62.9884, Valid loss: 70.2403\n",
      "Saving model with loss 70.240...\n",
      "Epoch [58/100], Step[24200]: Train loss: 65.6991, Valid loss: 71.0404\n",
      "Epoch [59/100], Step[24300]: Train loss: 69.4348, Valid loss: 70.5510\n",
      "Epoch [59/100], Step[24400]: Train loss: 71.3951, Valid loss: 70.6370\n",
      "Epoch [59/100], Step[24500]: Train loss: 75.1695, Valid loss: 70.5561\n",
      "Epoch [59/100], Step[24600]: Train loss: 71.0671, Valid loss: 70.5931\n",
      "Epoch [60/100], Step[24700]: Train loss: 73.2123, Valid loss: 70.9693\n",
      "Epoch [60/100], Step[24800]: Train loss: 66.9938, Valid loss: 70.5454\n",
      "Epoch [60/100], Step[24900]: Train loss: 63.2657, Valid loss: 70.5157\n",
      "Epoch [60/100], Step[25000]: Train loss: 65.9373, Valid loss: 71.0555\n",
      "Epoch [61/100], Step[25100]: Train loss: 71.9335, Valid loss: 70.9978\n",
      "Epoch [61/100], Step[25200]: Train loss: 71.5685, Valid loss: 71.1819\n",
      "Epoch [61/100], Step[25300]: Train loss: 70.1421, Valid loss: 70.9539\n",
      "Epoch [61/100], Step[25400]: Train loss: 75.3264, Valid loss: 70.8835\n",
      "Epoch [62/100], Step[25500]: Train loss: 69.4468, Valid loss: 70.9262\n",
      "Epoch [62/100], Step[25600]: Train loss: 67.9917, Valid loss: 71.3520\n",
      "Epoch [62/100], Step[25700]: Train loss: 65.0493, Valid loss: 70.9838\n",
      "Epoch [62/100], Step[25800]: Train loss: 71.1715, Valid loss: 70.8778\n",
      "Epoch [62/100], Step[25900]: Train loss: 71.8314, Valid loss: 70.8128\n",
      "Epoch [63/100], Step[26000]: Train loss: 63.4686, Valid loss: 70.4508\n",
      "Epoch [63/100], Step[26100]: Train loss: 64.3578, Valid loss: 70.6925\n",
      "Epoch [63/100], Step[26200]: Train loss: 70.7945, Valid loss: 70.5426\n",
      "Epoch [63/100], Step[26300]: Train loss: 72.3242, Valid loss: 70.4270\n",
      "Epoch [64/100], Step[26400]: Train loss: 81.0769, Valid loss: 70.4983\n",
      "Epoch [64/100], Step[26500]: Train loss: 69.1020, Valid loss: 70.7147\n",
      "Epoch [64/100], Step[26600]: Train loss: 62.7174, Valid loss: 70.7195\n",
      "Epoch [64/100], Step[26700]: Train loss: 63.4310, Valid loss: 70.5174\n",
      "Epoch [65/100], Step[26800]: Train loss: 75.0737, Valid loss: 70.6189\n",
      "Epoch [65/100], Step[26900]: Train loss: 64.1124, Valid loss: 70.3802\n",
      "Epoch [65/100], Step[27000]: Train loss: 66.9646, Valid loss: 70.5503\n",
      "Epoch [65/100], Step[27100]: Train loss: 62.7640, Valid loss: 71.1287\n",
      "Epoch [66/100], Step[27200]: Train loss: 63.6378, Valid loss: 70.7314\n",
      "Epoch [66/100], Step[27300]: Train loss: 56.1043, Valid loss: 70.7411\n",
      "Epoch [66/100], Step[27400]: Train loss: 70.3267, Valid loss: 70.6509\n",
      "Epoch [66/100], Step[27500]: Train loss: 70.9657, Valid loss: 70.5464\n",
      "Epoch [67/100], Step[27600]: Train loss: 70.9388, Valid loss: 70.6170\n",
      "Epoch [67/100], Step[27700]: Train loss: 72.1496, Valid loss: 70.5622\n",
      "Epoch [67/100], Step[27800]: Train loss: 58.7850, Valid loss: 70.3754\n",
      "Epoch [67/100], Step[27900]: Train loss: 73.9034, Valid loss: 70.8429\n",
      "Epoch [67/100], Step[28000]: Train loss: 62.4610, Valid loss: 70.5890\n",
      "Epoch [68/100], Step[28100]: Train loss: 78.5777, Valid loss: 70.5647\n",
      "Epoch [68/100], Step[28200]: Train loss: 71.8655, Valid loss: 70.3816\n",
      "Epoch [68/100], Step[28300]: Train loss: 64.5544, Valid loss: 70.8146\n",
      "Epoch [68/100], Step[28400]: Train loss: 69.6632, Valid loss: 70.5469\n",
      "Epoch [69/100], Step[28500]: Train loss: 68.1108, Valid loss: 70.2140\n",
      "Saving model with loss 70.214...\n",
      "Epoch [69/100], Step[28600]: Train loss: 67.0709, Valid loss: 70.3759\n",
      "Epoch [69/100], Step[28700]: Train loss: 67.7548, Valid loss: 70.5991\n",
      "Epoch [69/100], Step[28800]: Train loss: 67.5550, Valid loss: 70.5530\n",
      "Epoch [70/100], Step[28900]: Train loss: 67.2493, Valid loss: 70.1040\n",
      "Saving model with loss 70.104...\n",
      "Epoch [70/100], Step[29000]: Train loss: 69.2639, Valid loss: 70.2810\n",
      "Epoch [70/100], Step[29100]: Train loss: 58.6317, Valid loss: 70.5882\n",
      "Epoch [70/100], Step[29200]: Train loss: 64.7970, Valid loss: 70.7414\n",
      "Epoch [71/100], Step[29300]: Train loss: 60.2548, Valid loss: 70.6394\n",
      "Epoch [71/100], Step[29400]: Train loss: 62.5855, Valid loss: 70.6201\n",
      "Epoch [71/100], Step[29500]: Train loss: 69.0795, Valid loss: 70.6446\n",
      "Epoch [71/100], Step[29600]: Train loss: 72.3500, Valid loss: 70.6139\n",
      "Epoch [72/100], Step[29700]: Train loss: 68.3292, Valid loss: 70.2985\n",
      "Epoch [72/100], Step[29800]: Train loss: 60.6598, Valid loss: 69.9506\n",
      "Saving model with loss 69.951...\n",
      "Epoch [72/100], Step[29900]: Train loss: 63.0841, Valid loss: 70.4659\n",
      "Epoch [72/100], Step[30000]: Train loss: 65.4577, Valid loss: 70.1116\n",
      "Epoch [73/100], Step[30100]: Train loss: 60.9291, Valid loss: 70.3514\n",
      "Epoch [73/100], Step[30200]: Train loss: 75.0114, Valid loss: 70.1003\n",
      "Epoch [73/100], Step[30300]: Train loss: 67.0365, Valid loss: 70.2354\n",
      "Epoch [73/100], Step[30400]: Train loss: 62.4370, Valid loss: 70.3765\n",
      "Epoch [73/100], Step[30500]: Train loss: 80.7108, Valid loss: 70.9150\n",
      "Epoch [74/100], Step[30600]: Train loss: 68.4411, Valid loss: 70.6981\n",
      "Epoch [74/100], Step[30700]: Train loss: 60.0766, Valid loss: 70.2163\n",
      "Epoch [74/100], Step[30800]: Train loss: 65.2745, Valid loss: 70.4780\n",
      "Epoch [74/100], Step[30900]: Train loss: 60.3376, Valid loss: 70.3263\n",
      "Epoch [75/100], Step[31000]: Train loss: 67.3834, Valid loss: 70.5645\n",
      "Epoch [75/100], Step[31100]: Train loss: 61.7066, Valid loss: 70.6186\n",
      "Epoch [75/100], Step[31200]: Train loss: 69.6956, Valid loss: 70.3911\n",
      "Epoch [75/100], Step[31300]: Train loss: 77.9446, Valid loss: 70.7676\n",
      "Epoch [76/100], Step[31400]: Train loss: 77.0113, Valid loss: 70.0983\n",
      "Epoch [76/100], Step[31500]: Train loss: 62.1455, Valid loss: 70.2799\n",
      "Epoch [76/100], Step[31600]: Train loss: 76.2707, Valid loss: 70.3437\n",
      "Epoch [76/100], Step[31700]: Train loss: 65.8111, Valid loss: 70.8511\n",
      "Epoch [77/100], Step[31800]: Train loss: 69.2170, Valid loss: 70.4785\n",
      "Epoch [77/100], Step[31900]: Train loss: 83.2815, Valid loss: 70.5896\n",
      "Epoch [77/100], Step[32000]: Train loss: 70.8895, Valid loss: 70.3842\n",
      "Epoch [77/100], Step[32100]: Train loss: 79.3806, Valid loss: 70.7113\n",
      "Epoch [78/100], Step[32200]: Train loss: 62.8835, Valid loss: 69.9153\n",
      "Saving model with loss 69.915...\n",
      "Epoch [78/100], Step[32300]: Train loss: 69.2427, Valid loss: 70.3482\n",
      "Epoch [78/100], Step[32400]: Train loss: 62.6419, Valid loss: 70.7208\n",
      "Epoch [78/100], Step[32500]: Train loss: 63.9758, Valid loss: 70.2736\n",
      "Epoch [78/100], Step[32600]: Train loss: 57.5788, Valid loss: 70.8453\n",
      "Epoch [79/100], Step[32700]: Train loss: 67.4535, Valid loss: 70.3945\n",
      "Epoch [79/100], Step[32800]: Train loss: 69.2054, Valid loss: 70.1563\n",
      "Epoch [79/100], Step[32900]: Train loss: 67.4319, Valid loss: 70.6652\n",
      "Epoch [79/100], Step[33000]: Train loss: 65.9930, Valid loss: 70.0017\n",
      "Epoch [80/100], Step[33100]: Train loss: 64.5837, Valid loss: 70.2277\n",
      "Epoch [80/100], Step[33200]: Train loss: 59.1066, Valid loss: 70.4999\n",
      "Epoch [80/100], Step[33300]: Train loss: 79.1812, Valid loss: 70.7556\n",
      "Epoch [80/100], Step[33400]: Train loss: 59.8221, Valid loss: 70.3752\n",
      "Epoch [81/100], Step[33500]: Train loss: 59.5474, Valid loss: 70.4713\n",
      "Epoch [81/100], Step[33600]: Train loss: 69.5214, Valid loss: 70.3557\n",
      "Epoch [81/100], Step[33700]: Train loss: 68.8582, Valid loss: 70.1261\n",
      "Epoch [81/100], Step[33800]: Train loss: 79.6534, Valid loss: 70.3080\n",
      "Epoch [82/100], Step[33900]: Train loss: 66.0490, Valid loss: 70.2690\n",
      "Epoch [82/100], Step[34000]: Train loss: 60.5751, Valid loss: 70.6139\n",
      "Epoch [82/100], Step[34100]: Train loss: 66.7854, Valid loss: 70.1969\n",
      "Epoch [82/100], Step[34200]: Train loss: 70.3229, Valid loss: 70.1677\n",
      "Epoch [83/100], Step[34300]: Train loss: 72.3522, Valid loss: 70.5340\n",
      "Epoch [83/100], Step[34400]: Train loss: 54.7749, Valid loss: 70.0630\n",
      "Epoch [83/100], Step[34500]: Train loss: 61.1751, Valid loss: 70.3701\n",
      "Epoch [83/100], Step[34600]: Train loss: 62.1438, Valid loss: 70.4858\n",
      "Epoch [84/100], Step[34700]: Train loss: 66.5657, Valid loss: 70.0898\n",
      "Epoch [84/100], Step[34800]: Train loss: 61.2129, Valid loss: 70.8339\n",
      "Epoch [84/100], Step[34900]: Train loss: 60.9860, Valid loss: 70.2910\n",
      "Epoch [84/100], Step[35000]: Train loss: 67.4736, Valid loss: 70.1570\n",
      "Epoch [84/100], Step[35100]: Train loss: 72.6653, Valid loss: 70.8361\n",
      "Epoch [85/100], Step[35200]: Train loss: 71.2896, Valid loss: 70.3584\n",
      "Epoch [85/100], Step[35300]: Train loss: 58.2825, Valid loss: 70.1282\n",
      "Epoch [85/100], Step[35400]: Train loss: 65.3249, Valid loss: 70.3987\n",
      "Epoch [85/100], Step[35500]: Train loss: 60.9615, Valid loss: 70.2014\n",
      "Epoch [86/100], Step[35600]: Train loss: 64.0074, Valid loss: 70.3707\n",
      "Epoch [86/100], Step[35700]: Train loss: 64.7418, Valid loss: 70.2026\n",
      "Epoch [86/100], Step[35800]: Train loss: 63.1165, Valid loss: 69.9782\n",
      "Epoch [86/100], Step[35900]: Train loss: 70.1337, Valid loss: 70.2915\n",
      "Epoch [87/100], Step[36000]: Train loss: 74.4734, Valid loss: 70.0372\n",
      "Epoch [87/100], Step[36100]: Train loss: 67.1279, Valid loss: 69.9603\n",
      "Epoch [87/100], Step[36200]: Train loss: 76.7654, Valid loss: 70.7608\n",
      "Epoch [87/100], Step[36300]: Train loss: 70.5983, Valid loss: 70.0239\n",
      "Epoch [88/100], Step[36400]: Train loss: 64.5197, Valid loss: 70.1511\n",
      "Epoch [88/100], Step[36500]: Train loss: 62.4836, Valid loss: 70.3933\n",
      "Epoch [88/100], Step[36600]: Train loss: 72.8331, Valid loss: 69.8124\n",
      "Saving model with loss 69.812...\n",
      "Epoch [88/100], Step[36700]: Train loss: 74.8462, Valid loss: 70.2017\n",
      "Epoch [89/100], Step[36800]: Train loss: 64.7023, Valid loss: 70.1663\n",
      "Epoch [89/100], Step[36900]: Train loss: 63.2083, Valid loss: 70.3926\n",
      "Epoch [89/100], Step[37000]: Train loss: 74.1464, Valid loss: 70.1463\n",
      "Epoch [89/100], Step[37100]: Train loss: 71.5533, Valid loss: 70.3513\n",
      "Epoch [89/100], Step[37200]: Train loss: 82.3343, Valid loss: 70.5523\n",
      "Epoch [90/100], Step[37300]: Train loss: 57.3697, Valid loss: 70.0414\n",
      "Epoch [90/100], Step[37400]: Train loss: 58.9319, Valid loss: 70.3815\n",
      "Epoch [90/100], Step[37500]: Train loss: 66.8584, Valid loss: 70.1531\n",
      "Epoch [90/100], Step[37600]: Train loss: 66.7478, Valid loss: 70.5573\n",
      "Epoch [91/100], Step[37700]: Train loss: 66.0317, Valid loss: 70.2010\n",
      "Epoch [91/100], Step[37800]: Train loss: 60.1039, Valid loss: 70.0933\n",
      "Epoch [91/100], Step[37900]: Train loss: 65.3341, Valid loss: 70.1294\n",
      "Epoch [91/100], Step[38000]: Train loss: 66.6710, Valid loss: 70.1860\n",
      "Epoch [92/100], Step[38100]: Train loss: 71.9435, Valid loss: 70.1979\n",
      "Epoch [92/100], Step[38200]: Train loss: 71.3323, Valid loss: 70.2985\n",
      "Epoch [92/100], Step[38300]: Train loss: 66.1162, Valid loss: 70.8151\n",
      "Epoch [92/100], Step[38400]: Train loss: 67.9056, Valid loss: 70.5679\n",
      "Epoch [93/100], Step[38500]: Train loss: 58.8386, Valid loss: 70.5955\n",
      "Epoch [93/100], Step[38600]: Train loss: 68.0585, Valid loss: 70.0916\n",
      "Epoch [93/100], Step[38700]: Train loss: 61.8287, Valid loss: 70.3973\n",
      "Epoch [93/100], Step[38800]: Train loss: 58.3301, Valid loss: 70.7697\n",
      "Epoch [94/100], Step[38900]: Train loss: 66.4568, Valid loss: 71.2437\n",
      "Epoch [94/100], Step[39000]: Train loss: 68.1920, Valid loss: 70.1268\n",
      "Epoch [94/100], Step[39100]: Train loss: 65.3679, Valid loss: 70.4383\n",
      "Epoch [94/100], Step[39200]: Train loss: 68.0487, Valid loss: 70.6277\n",
      "Epoch [95/100], Step[39300]: Train loss: 65.1417, Valid loss: 70.3636\n",
      "Epoch [95/100], Step[39400]: Train loss: 63.0388, Valid loss: 70.2613\n",
      "Epoch [95/100], Step[39500]: Train loss: 64.4868, Valid loss: 70.5311\n",
      "Epoch [95/100], Step[39600]: Train loss: 67.6370, Valid loss: 70.5814\n",
      "Epoch [95/100], Step[39700]: Train loss: 67.0852, Valid loss: 70.3394\n",
      "Epoch [96/100], Step[39800]: Train loss: 68.1715, Valid loss: 70.5104\n",
      "Epoch [96/100], Step[39900]: Train loss: 66.8370, Valid loss: 70.5797\n",
      "Epoch [96/100], Step[40000]: Train loss: 70.3981, Valid loss: 70.5700\n",
      "Epoch [96/100], Step[40100]: Train loss: 65.0124, Valid loss: 70.5072\n",
      "Epoch [97/100], Step[40200]: Train loss: 71.8864, Valid loss: 69.8505\n",
      "Epoch [97/100], Step[40300]: Train loss: 69.9253, Valid loss: 70.1499\n",
      "Epoch [97/100], Step[40400]: Train loss: 66.2632, Valid loss: 70.4213\n",
      "Epoch [97/100], Step[40500]: Train loss: 68.6877, Valid loss: 70.3067\n",
      "Epoch [98/100], Step[40600]: Train loss: 77.3912, Valid loss: 70.0132\n",
      "Epoch [98/100], Step[40700]: Train loss: 70.3627, Valid loss: 69.9940\n",
      "Epoch [98/100], Step[40800]: Train loss: 56.2043, Valid loss: 70.1417\n",
      "Epoch [98/100], Step[40900]: Train loss: 69.2388, Valid loss: 70.0170\n",
      "Epoch [99/100], Step[41000]: Train loss: 60.5583, Valid loss: 70.3454\n",
      "Epoch [99/100], Step[41100]: Train loss: 71.9256, Valid loss: 69.9119\n",
      "Epoch [99/100], Step[41200]: Train loss: 67.7803, Valid loss: 70.0939\n",
      "Epoch [99/100], Step[41300]: Train loss: 74.3330, Valid loss: 70.2349\n",
      "Epoch [100/100], Step[41400]: Train loss: 68.3208, Valid loss: 70.1107\n",
      "Epoch [100/100], Step[41500]: Train loss: 63.9163, Valid loss: 69.9810\n",
      "Epoch [100/100], Step[41600]: Train loss: 76.2012, Valid loss: 70.4868\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "h_arr = []\n",
    "test_RMSE_arr = []\n",
    "\n",
    "for h in [20, 45, 180, 360]:\n",
    "    # config\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    config = {\n",
    "        'H': h,\n",
    "        'optimizer': \"Adam\",\n",
    "        'weight_decay': 0,\n",
    "        'n_epochs': 100,     # Number of epochs.            \n",
    "        'learning_rate': 0.001,              \n",
    "        'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "        'save_path': './models/model6_' + str(h) + '.ckpt'  # Your model will be saved here.\n",
    "    }\n",
    "\n",
    "    # training\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "    step_arr = []\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    trainer(train_loader, valid_loader, model, config, device)\n",
    "    \n",
    "    # testing\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "    model.load_state_dict(torch.load(config['save_path']))\n",
    "    preds = predict(test_loader, model, device)\n",
    "    test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "    \n",
    "    # append to array\n",
    "    h_arr.append(h)\n",
    "    test_RMSE_arr.append(test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65f9194-756c-4a67-8d91-0cc11ac3964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>9.042443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>8.857091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>8.756114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>8.747357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H  test RMSE\n",
       "0   20   9.042443\n",
       "1   45   8.857091\n",
       "2  180   8.756114\n",
       "3  360   8.747357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"H\": h_arr,\n",
    "       \"test RMSE\": test_RMSE_arr}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbdba3-10cd-4eb3-aa41-e9466474a366",
   "metadata": {},
   "source": [
    "According to the chart above, we can see that as H increases, test RMSE decreases. So we sould pick H = 360 as the best model above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc53a39-b1ac-490c-a23d-7f0eab112397",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "636485a4-a280-444a-9321-510db7b0443c",
   "metadata": {
    "id": "k4Rq8_TztAhq"
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def l1l2_loss(output, target, z):\n",
    "    loss = z * torch.sum((output - target)**2) + (1 - z) * torch.sum(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "    # Define your optimization algorithm. \n",
    "    if config['optimizer'] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count, z = config['n_epochs'], math.inf, 0, 0, config['z']\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            model.train() # Set your model to train mode.\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
    "            pred = model(x)             \n",
    "            loss = l1l2_loss(pred, y, z)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            # loss_record.append(loss.detach().item())\n",
    "            if step % 100 == 0:\n",
    "                mean_train_loss = criterion(pred, y).detach().item()\n",
    "                step_arr.append(step)\n",
    "                train_loss.append(mean_train_loss)\n",
    "\n",
    "                model.eval() # Set your model to evaluation mode.\n",
    "                loss_record = []\n",
    "                for x, y in valid_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        pred = model(x)\n",
    "                        loss = criterion(pred, y)\n",
    "\n",
    "                    loss_record.append(loss.item())\n",
    "\n",
    "                mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "                valid_loss.append(mean_valid_loss)\n",
    "\n",
    "                print(f'Epoch [{epoch+1}/{n_epochs}], Step[{step}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "\n",
    "                if mean_valid_loss < best_loss:\n",
    "                    best_loss = mean_valid_loss\n",
    "                    best_step_count = step\n",
    "                    torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "                    print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1 * 100\n",
    "                \n",
    "                if early_stop_count >= config['early_stop']:\n",
    "                    print('\\nModel is not improving, so we halt the training session.')\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d93dc06-aa9e-4dab-b62e-d1f644c16bb6",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuweien/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py:191: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 110.1659, Valid loss: 90.1538\n",
      "Saving model with loss 90.154...\n",
      "Epoch [1/100], Step[200]: Train loss: 93.6751, Valid loss: 82.9010\n",
      "Saving model with loss 82.901...\n",
      "Epoch [1/100], Step[300]: Train loss: 90.7892, Valid loss: 81.2018\n",
      "Saving model with loss 81.202...\n",
      "Epoch [1/100], Step[400]: Train loss: 83.2891, Valid loss: 80.4566\n",
      "Saving model with loss 80.457...\n",
      "Epoch [2/100], Step[500]: Train loss: 86.2609, Valid loss: 79.3374\n",
      "Saving model with loss 79.337...\n",
      "Epoch [2/100], Step[600]: Train loss: 82.3259, Valid loss: 79.2036\n",
      "Saving model with loss 79.204...\n",
      "Epoch [2/100], Step[700]: Train loss: 76.8943, Valid loss: 78.8872\n",
      "Saving model with loss 78.887...\n",
      "Epoch [2/100], Step[800]: Train loss: 78.8623, Valid loss: 78.0850\n",
      "Saving model with loss 78.085...\n",
      "Epoch [3/100], Step[900]: Train loss: 95.1142, Valid loss: 77.6287\n",
      "Saving model with loss 77.629...\n",
      "Epoch [3/100], Step[1000]: Train loss: 78.9057, Valid loss: 77.0546\n",
      "Saving model with loss 77.055...\n",
      "Epoch [3/100], Step[1100]: Train loss: 71.3547, Valid loss: 76.7527\n",
      "Saving model with loss 76.753...\n",
      "Epoch [3/100], Step[1200]: Train loss: 74.7026, Valid loss: 77.4530\n",
      "Epoch [4/100], Step[1300]: Train loss: 97.9925, Valid loss: 76.6212\n",
      "Saving model with loss 76.621...\n",
      "Epoch [4/100], Step[1400]: Train loss: 72.5979, Valid loss: 76.6440\n",
      "Epoch [4/100], Step[1500]: Train loss: 79.6187, Valid loss: 76.5482\n",
      "Saving model with loss 76.548...\n",
      "Epoch [4/100], Step[1600]: Train loss: 86.1504, Valid loss: 76.6660\n",
      "Epoch [5/100], Step[1700]: Train loss: 85.0619, Valid loss: 76.6768\n",
      "Epoch [5/100], Step[1800]: Train loss: 75.3146, Valid loss: 76.5233\n",
      "Saving model with loss 76.523...\n",
      "Epoch [5/100], Step[1900]: Train loss: 91.3219, Valid loss: 76.5875\n",
      "Epoch [5/100], Step[2000]: Train loss: 77.0905, Valid loss: 76.3346\n",
      "Saving model with loss 76.335...\n",
      "Epoch [6/100], Step[2100]: Train loss: 80.6554, Valid loss: 76.1561\n",
      "Saving model with loss 76.156...\n",
      "Epoch [6/100], Step[2200]: Train loss: 87.8427, Valid loss: 75.8996\n",
      "Saving model with loss 75.900...\n",
      "Epoch [6/100], Step[2300]: Train loss: 76.7261, Valid loss: 76.2970\n",
      "Epoch [6/100], Step[2400]: Train loss: 74.4903, Valid loss: 76.0815\n",
      "Epoch [6/100], Step[2500]: Train loss: 77.8890, Valid loss: 76.0014\n",
      "Epoch [7/100], Step[2600]: Train loss: 72.6249, Valid loss: 76.2130\n",
      "Epoch [7/100], Step[2700]: Train loss: 74.7024, Valid loss: 75.8227\n",
      "Saving model with loss 75.823...\n",
      "Epoch [7/100], Step[2800]: Train loss: 86.1737, Valid loss: 75.4843\n",
      "Saving model with loss 75.484...\n",
      "Epoch [7/100], Step[2900]: Train loss: 74.4290, Valid loss: 76.0146\n",
      "Epoch [8/100], Step[3000]: Train loss: 70.0582, Valid loss: 75.3074\n",
      "Saving model with loss 75.307...\n",
      "Epoch [8/100], Step[3100]: Train loss: 79.3306, Valid loss: 76.2186\n",
      "Epoch [8/100], Step[3200]: Train loss: 94.6367, Valid loss: 75.5229\n",
      "Epoch [8/100], Step[3300]: Train loss: 82.9131, Valid loss: 75.1226\n",
      "Saving model with loss 75.123...\n",
      "Epoch [9/100], Step[3400]: Train loss: 82.9584, Valid loss: 75.5347\n",
      "Epoch [9/100], Step[3500]: Train loss: 88.6994, Valid loss: 75.5155\n",
      "Epoch [9/100], Step[3600]: Train loss: 75.3869, Valid loss: 75.2948\n",
      "Epoch [9/100], Step[3700]: Train loss: 73.6247, Valid loss: 75.5415\n",
      "Epoch [10/100], Step[3800]: Train loss: 70.8298, Valid loss: 75.7430\n",
      "Epoch [10/100], Step[3900]: Train loss: 66.6099, Valid loss: 75.0516\n",
      "Saving model with loss 75.052...\n",
      "Epoch [10/100], Step[4000]: Train loss: 87.8946, Valid loss: 75.5458\n",
      "Epoch [10/100], Step[4100]: Train loss: 83.4734, Valid loss: 75.4216\n",
      "Epoch [11/100], Step[4200]: Train loss: 79.2369, Valid loss: 74.8110\n",
      "Saving model with loss 74.811...\n",
      "Epoch [11/100], Step[4300]: Train loss: 90.7323, Valid loss: 74.7964\n",
      "Saving model with loss 74.796...\n",
      "Epoch [11/100], Step[4400]: Train loss: 76.6015, Valid loss: 75.3779\n",
      "Epoch [11/100], Step[4500]: Train loss: 83.8322, Valid loss: 74.7278\n",
      "Saving model with loss 74.728...\n",
      "Epoch [12/100], Step[4600]: Train loss: 70.1488, Valid loss: 74.9360\n",
      "Epoch [12/100], Step[4700]: Train loss: 82.0741, Valid loss: 74.8692\n",
      "Epoch [12/100], Step[4800]: Train loss: 65.7908, Valid loss: 74.6980\n",
      "Saving model with loss 74.698...\n",
      "Epoch [12/100], Step[4900]: Train loss: 79.1018, Valid loss: 74.7314\n",
      "Epoch [12/100], Step[5000]: Train loss: 87.3339, Valid loss: 74.9757\n",
      "Epoch [13/100], Step[5100]: Train loss: 70.7500, Valid loss: 74.5043\n",
      "Saving model with loss 74.504...\n",
      "Epoch [13/100], Step[5200]: Train loss: 84.5013, Valid loss: 74.7360\n",
      "Epoch [13/100], Step[5300]: Train loss: 86.6784, Valid loss: 75.1672\n",
      "Epoch [13/100], Step[5400]: Train loss: 83.9136, Valid loss: 74.5434\n",
      "Epoch [14/100], Step[5500]: Train loss: 74.4450, Valid loss: 75.1513\n",
      "Epoch [14/100], Step[5600]: Train loss: 70.1298, Valid loss: 74.4892\n",
      "Saving model with loss 74.489...\n",
      "Epoch [14/100], Step[5700]: Train loss: 78.9525, Valid loss: 74.6103\n",
      "Epoch [14/100], Step[5800]: Train loss: 82.2819, Valid loss: 74.6188\n",
      "Epoch [15/100], Step[5900]: Train loss: 75.2611, Valid loss: 74.5512\n",
      "Epoch [15/100], Step[6000]: Train loss: 69.5623, Valid loss: 74.9593\n",
      "Epoch [15/100], Step[6100]: Train loss: 71.9660, Valid loss: 74.8138\n",
      "Epoch [15/100], Step[6200]: Train loss: 74.8236, Valid loss: 74.9075\n",
      "Epoch [16/100], Step[6300]: Train loss: 78.6936, Valid loss: 74.5407\n",
      "Epoch [16/100], Step[6400]: Train loss: 79.2472, Valid loss: 74.9904\n",
      "Epoch [16/100], Step[6500]: Train loss: 77.3665, Valid loss: 74.7443\n",
      "Epoch [16/100], Step[6600]: Train loss: 77.5828, Valid loss: 74.7318\n",
      "Epoch [17/100], Step[6700]: Train loss: 78.8543, Valid loss: 74.5319\n",
      "Epoch [17/100], Step[6800]: Train loss: 72.3750, Valid loss: 74.7442\n",
      "Epoch [17/100], Step[6900]: Train loss: 79.4188, Valid loss: 74.2045\n",
      "Saving model with loss 74.204...\n",
      "Epoch [17/100], Step[7000]: Train loss: 81.2691, Valid loss: 74.7171\n",
      "Epoch [17/100], Step[7100]: Train loss: 70.9624, Valid loss: 74.2323\n",
      "Epoch [18/100], Step[7200]: Train loss: 86.6408, Valid loss: 74.6213\n",
      "Epoch [18/100], Step[7300]: Train loss: 82.4357, Valid loss: 74.1549\n",
      "Saving model with loss 74.155...\n",
      "Epoch [18/100], Step[7400]: Train loss: 68.8008, Valid loss: 74.5271\n",
      "Epoch [18/100], Step[7500]: Train loss: 73.4389, Valid loss: 74.5148\n",
      "Epoch [19/100], Step[7600]: Train loss: 85.2017, Valid loss: 74.1118\n",
      "Saving model with loss 74.112...\n",
      "Epoch [19/100], Step[7700]: Train loss: 75.9679, Valid loss: 74.9320\n",
      "Epoch [19/100], Step[7800]: Train loss: 87.5316, Valid loss: 74.4664\n",
      "Epoch [19/100], Step[7900]: Train loss: 78.4249, Valid loss: 74.0077\n",
      "Saving model with loss 74.008...\n",
      "Epoch [20/100], Step[8000]: Train loss: 80.5676, Valid loss: 74.2366\n",
      "Epoch [20/100], Step[8100]: Train loss: 74.0801, Valid loss: 74.8093\n",
      "Epoch [20/100], Step[8200]: Train loss: 81.3516, Valid loss: 74.0905\n",
      "Epoch [20/100], Step[8300]: Train loss: 76.4909, Valid loss: 74.0729\n",
      "Epoch [21/100], Step[8400]: Train loss: 82.3786, Valid loss: 74.2905\n",
      "Epoch [21/100], Step[8500]: Train loss: 83.9514, Valid loss: 74.2344\n",
      "Epoch [21/100], Step[8600]: Train loss: 79.2423, Valid loss: 74.3436\n",
      "Epoch [21/100], Step[8700]: Train loss: 77.8743, Valid loss: 74.0259\n",
      "Epoch [22/100], Step[8800]: Train loss: 78.0765, Valid loss: 74.4756\n",
      "Epoch [22/100], Step[8900]: Train loss: 81.3616, Valid loss: 74.4249\n",
      "Epoch [22/100], Step[9000]: Train loss: 77.4226, Valid loss: 74.5277\n",
      "Epoch [22/100], Step[9100]: Train loss: 74.9462, Valid loss: 74.3015\n",
      "Epoch [23/100], Step[9200]: Train loss: 86.2062, Valid loss: 74.2819\n",
      "Epoch [23/100], Step[9300]: Train loss: 70.3801, Valid loss: 74.3197\n",
      "Epoch [23/100], Step[9400]: Train loss: 82.6211, Valid loss: 73.7708\n",
      "Saving model with loss 73.771...\n",
      "Epoch [23/100], Step[9500]: Train loss: 83.5970, Valid loss: 73.9160\n",
      "Epoch [23/100], Step[9600]: Train loss: 71.7461, Valid loss: 74.1961\n",
      "Epoch [24/100], Step[9700]: Train loss: 78.4266, Valid loss: 74.1941\n",
      "Epoch [24/100], Step[9800]: Train loss: 71.5431, Valid loss: 74.3294\n",
      "Epoch [24/100], Step[9900]: Train loss: 75.8447, Valid loss: 73.9397\n",
      "Epoch [24/100], Step[10000]: Train loss: 73.0914, Valid loss: 74.1582\n",
      "Epoch [25/100], Step[10100]: Train loss: 81.6342, Valid loss: 74.2671\n",
      "Epoch [25/100], Step[10200]: Train loss: 72.0380, Valid loss: 74.2623\n",
      "Epoch [25/100], Step[10300]: Train loss: 74.4898, Valid loss: 74.3013\n",
      "Epoch [25/100], Step[10400]: Train loss: 73.3289, Valid loss: 74.2714\n",
      "Epoch [26/100], Step[10500]: Train loss: 82.3017, Valid loss: 74.0038\n",
      "Epoch [26/100], Step[10600]: Train loss: 71.1685, Valid loss: 74.3209\n",
      "Epoch [26/100], Step[10700]: Train loss: 76.7832, Valid loss: 73.7946\n",
      "Epoch [26/100], Step[10800]: Train loss: 79.3435, Valid loss: 74.2659\n",
      "Epoch [27/100], Step[10900]: Train loss: 68.5751, Valid loss: 74.2931\n",
      "Epoch [27/100], Step[11000]: Train loss: 77.1179, Valid loss: 73.9013\n",
      "Epoch [27/100], Step[11100]: Train loss: 78.9156, Valid loss: 74.1501\n",
      "Epoch [27/100], Step[11200]: Train loss: 72.4258, Valid loss: 74.1383\n",
      "Epoch [28/100], Step[11300]: Train loss: 77.6966, Valid loss: 74.3775\n",
      "Epoch [28/100], Step[11400]: Train loss: 84.5275, Valid loss: 73.8857\n",
      "Epoch [28/100], Step[11500]: Train loss: 83.4010, Valid loss: 74.2372\n",
      "Epoch [28/100], Step[11600]: Train loss: 77.5214, Valid loss: 73.9062\n",
      "Epoch [28/100], Step[11700]: Train loss: 87.9481, Valid loss: 74.0147\n",
      "Epoch [29/100], Step[11800]: Train loss: 81.4990, Valid loss: 74.2910\n",
      "Epoch [29/100], Step[11900]: Train loss: 74.4731, Valid loss: 74.0167\n",
      "Epoch [29/100], Step[12000]: Train loss: 79.0568, Valid loss: 74.0716\n",
      "Epoch [29/100], Step[12100]: Train loss: 76.2368, Valid loss: 74.1767\n",
      "Epoch [30/100], Step[12200]: Train loss: 80.9511, Valid loss: 74.0693\n",
      "Epoch [30/100], Step[12300]: Train loss: 76.3632, Valid loss: 74.8309\n",
      "Epoch [30/100], Step[12400]: Train loss: 65.3313, Valid loss: 74.1607\n",
      "Epoch [30/100], Step[12500]: Train loss: 82.6112, Valid loss: 73.9894\n",
      "Epoch [31/100], Step[12600]: Train loss: 78.8799, Valid loss: 74.1989\n",
      "Epoch [31/100], Step[12700]: Train loss: 69.5929, Valid loss: 74.4390\n",
      "Epoch [31/100], Step[12800]: Train loss: 72.6053, Valid loss: 74.2121\n",
      "Epoch [31/100], Step[12900]: Train loss: 86.5047, Valid loss: 74.1057\n",
      "Epoch [32/100], Step[13000]: Train loss: 82.0623, Valid loss: 73.8500\n",
      "Epoch [32/100], Step[13100]: Train loss: 75.2480, Valid loss: 73.9482\n",
      "Epoch [32/100], Step[13200]: Train loss: 82.9431, Valid loss: 74.4487\n",
      "Epoch [32/100], Step[13300]: Train loss: 79.8680, Valid loss: 74.0414\n",
      "Epoch [33/100], Step[13400]: Train loss: 74.2066, Valid loss: 73.6721\n",
      "Saving model with loss 73.672...\n",
      "Epoch [33/100], Step[13500]: Train loss: 76.9673, Valid loss: 74.3658\n",
      "Epoch [33/100], Step[13600]: Train loss: 70.0444, Valid loss: 73.9338\n",
      "Epoch [33/100], Step[13700]: Train loss: 72.3927, Valid loss: 73.9958\n",
      "Epoch [34/100], Step[13800]: Train loss: 64.3307, Valid loss: 73.9305\n",
      "Epoch [34/100], Step[13900]: Train loss: 69.0527, Valid loss: 74.1368\n",
      "Epoch [34/100], Step[14000]: Train loss: 86.4250, Valid loss: 73.9961\n",
      "Epoch [34/100], Step[14100]: Train loss: 86.8295, Valid loss: 74.0788\n",
      "Epoch [34/100], Step[14200]: Train loss: 85.0688, Valid loss: 74.0958\n",
      "Epoch [35/100], Step[14300]: Train loss: 73.4620, Valid loss: 73.7008\n",
      "Epoch [35/100], Step[14400]: Train loss: 76.1820, Valid loss: 74.2673\n",
      "Epoch [35/100], Step[14500]: Train loss: 92.5404, Valid loss: 74.3578\n",
      "Epoch [35/100], Step[14600]: Train loss: 73.1076, Valid loss: 74.1985\n",
      "Epoch [36/100], Step[14700]: Train loss: 70.5707, Valid loss: 74.0146\n",
      "Epoch [36/100], Step[14800]: Train loss: 69.5834, Valid loss: 73.9889\n",
      "Epoch [36/100], Step[14900]: Train loss: 83.2306, Valid loss: 73.8870\n",
      "Epoch [36/100], Step[15000]: Train loss: 81.4531, Valid loss: 74.0280\n",
      "Epoch [37/100], Step[15100]: Train loss: 78.1108, Valid loss: 74.4667\n",
      "Epoch [37/100], Step[15200]: Train loss: 72.9972, Valid loss: 73.6617\n",
      "Saving model with loss 73.662...\n",
      "Epoch [37/100], Step[15300]: Train loss: 69.7696, Valid loss: 74.1868\n",
      "Epoch [37/100], Step[15400]: Train loss: 86.5055, Valid loss: 74.2596\n",
      "Epoch [38/100], Step[15500]: Train loss: 89.8192, Valid loss: 73.7232\n",
      "Epoch [38/100], Step[15600]: Train loss: 82.0126, Valid loss: 73.6796\n",
      "Epoch [38/100], Step[15700]: Train loss: 80.0857, Valid loss: 73.8887\n",
      "Epoch [38/100], Step[15800]: Train loss: 76.1091, Valid loss: 74.4582\n",
      "Epoch [39/100], Step[15900]: Train loss: 72.6943, Valid loss: 73.9659\n",
      "Epoch [39/100], Step[16000]: Train loss: 76.9798, Valid loss: 73.9982\n",
      "Epoch [39/100], Step[16100]: Train loss: 73.7501, Valid loss: 73.7576\n",
      "Epoch [39/100], Step[16200]: Train loss: 73.1980, Valid loss: 74.3971\n",
      "Epoch [39/100], Step[16300]: Train loss: 73.7158, Valid loss: 74.5193\n",
      "Epoch [40/100], Step[16400]: Train loss: 74.8625, Valid loss: 74.5109\n",
      "Epoch [40/100], Step[16500]: Train loss: 84.9667, Valid loss: 73.8959\n",
      "Epoch [40/100], Step[16600]: Train loss: 82.8328, Valid loss: 74.3411\n",
      "Epoch [40/100], Step[16700]: Train loss: 77.3049, Valid loss: 73.7553\n",
      "Epoch [41/100], Step[16800]: Train loss: 71.3088, Valid loss: 74.2175\n",
      "Epoch [41/100], Step[16900]: Train loss: 70.6850, Valid loss: 73.8434\n",
      "Epoch [41/100], Step[17000]: Train loss: 83.6814, Valid loss: 73.6626\n",
      "Epoch [41/100], Step[17100]: Train loss: 63.9688, Valid loss: 73.9032\n",
      "Epoch [42/100], Step[17200]: Train loss: 78.9554, Valid loss: 73.8575\n",
      "Epoch [42/100], Step[17300]: Train loss: 79.6309, Valid loss: 74.1832\n",
      "Epoch [42/100], Step[17400]: Train loss: 70.8375, Valid loss: 73.7041\n",
      "Epoch [42/100], Step[17500]: Train loss: 70.6241, Valid loss: 74.1560\n",
      "Epoch [43/100], Step[17600]: Train loss: 69.5589, Valid loss: 73.9717\n",
      "Epoch [43/100], Step[17700]: Train loss: 78.4128, Valid loss: 73.8225\n",
      "Epoch [43/100], Step[17800]: Train loss: 75.6005, Valid loss: 74.2502\n",
      "Epoch [43/100], Step[17900]: Train loss: 77.1482, Valid loss: 73.7306\n",
      "Epoch [44/100], Step[18000]: Train loss: 77.4387, Valid loss: 73.9248\n",
      "Epoch [44/100], Step[18100]: Train loss: 72.0091, Valid loss: 73.8551\n",
      "Epoch [44/100], Step[18200]: Train loss: 75.8977, Valid loss: 74.1047\n",
      "Epoch [44/100], Step[18300]: Train loss: 71.7207, Valid loss: 74.2054\n",
      "Epoch [45/100], Step[18400]: Train loss: 84.7112, Valid loss: 74.1095\n",
      "Epoch [45/100], Step[18500]: Train loss: 74.7324, Valid loss: 73.9248\n",
      "Epoch [45/100], Step[18600]: Train loss: 66.6351, Valid loss: 73.5973\n",
      "Saving model with loss 73.597...\n",
      "Epoch [45/100], Step[18700]: Train loss: 68.5644, Valid loss: 73.7220\n",
      "Epoch [45/100], Step[18800]: Train loss: 74.9003, Valid loss: 74.1950\n",
      "Epoch [46/100], Step[18900]: Train loss: 73.3145, Valid loss: 73.9480\n",
      "Epoch [46/100], Step[19000]: Train loss: 77.8351, Valid loss: 74.1063\n",
      "Epoch [46/100], Step[19100]: Train loss: 72.8191, Valid loss: 73.9589\n",
      "Epoch [46/100], Step[19200]: Train loss: 76.2463, Valid loss: 73.9047\n",
      "Epoch [47/100], Step[19300]: Train loss: 78.7451, Valid loss: 73.4946\n",
      "Saving model with loss 73.495...\n",
      "Epoch [47/100], Step[19400]: Train loss: 76.9704, Valid loss: 73.7722\n",
      "Epoch [47/100], Step[19500]: Train loss: 70.5462, Valid loss: 73.6347\n",
      "Epoch [47/100], Step[19600]: Train loss: 72.1633, Valid loss: 73.9178\n",
      "Epoch [48/100], Step[19700]: Train loss: 75.8734, Valid loss: 73.9191\n",
      "Epoch [48/100], Step[19800]: Train loss: 75.0134, Valid loss: 74.2568\n",
      "Epoch [48/100], Step[19900]: Train loss: 75.5219, Valid loss: 73.7423\n",
      "Epoch [48/100], Step[20000]: Train loss: 76.7289, Valid loss: 74.3927\n",
      "Epoch [49/100], Step[20100]: Train loss: 78.2712, Valid loss: 73.8261\n",
      "Epoch [49/100], Step[20200]: Train loss: 88.5458, Valid loss: 73.7385\n",
      "Epoch [49/100], Step[20300]: Train loss: 73.5705, Valid loss: 74.0125\n",
      "Epoch [49/100], Step[20400]: Train loss: 77.5530, Valid loss: 73.8916\n",
      "Epoch [50/100], Step[20500]: Train loss: 74.3643, Valid loss: 74.3153\n",
      "Epoch [50/100], Step[20600]: Train loss: 72.3423, Valid loss: 73.9837\n",
      "Epoch [50/100], Step[20700]: Train loss: 77.6254, Valid loss: 74.0794\n",
      "Epoch [50/100], Step[20800]: Train loss: 78.1285, Valid loss: 73.4657\n",
      "Saving model with loss 73.466...\n",
      "Epoch [50/100], Step[20900]: Train loss: 89.1042, Valid loss: 73.8744\n",
      "Epoch [51/100], Step[21000]: Train loss: 82.3184, Valid loss: 73.8130\n",
      "Epoch [51/100], Step[21100]: Train loss: 78.4667, Valid loss: 74.2405\n",
      "Epoch [51/100], Step[21200]: Train loss: 91.4734, Valid loss: 74.0329\n",
      "Epoch [51/100], Step[21300]: Train loss: 72.5040, Valid loss: 74.2417\n",
      "Epoch [52/100], Step[21400]: Train loss: 69.9583, Valid loss: 73.8590\n",
      "Epoch [52/100], Step[21500]: Train loss: 86.4730, Valid loss: 74.0832\n",
      "Epoch [52/100], Step[21600]: Train loss: 83.9114, Valid loss: 74.2005\n",
      "Epoch [52/100], Step[21700]: Train loss: 81.2711, Valid loss: 74.1465\n",
      "Epoch [53/100], Step[21800]: Train loss: 88.6755, Valid loss: 73.8352\n",
      "Epoch [53/100], Step[21900]: Train loss: 85.8290, Valid loss: 73.9625\n",
      "Epoch [53/100], Step[22000]: Train loss: 72.7368, Valid loss: 74.0529\n",
      "Epoch [53/100], Step[22100]: Train loss: 72.9367, Valid loss: 73.9179\n",
      "Epoch [54/100], Step[22200]: Train loss: 81.5164, Valid loss: 73.8234\n",
      "Epoch [54/100], Step[22300]: Train loss: 86.8165, Valid loss: 74.0823\n",
      "Epoch [54/100], Step[22400]: Train loss: 82.9573, Valid loss: 73.9392\n",
      "Epoch [54/100], Step[22500]: Train loss: 90.4402, Valid loss: 74.1887\n",
      "Epoch [55/100], Step[22600]: Train loss: 71.3533, Valid loss: 73.8328\n",
      "Epoch [55/100], Step[22700]: Train loss: 81.7375, Valid loss: 73.7750\n",
      "Epoch [55/100], Step[22800]: Train loss: 83.2696, Valid loss: 73.7236\n",
      "Epoch [55/100], Step[22900]: Train loss: 87.8708, Valid loss: 73.9783\n",
      "Epoch [56/100], Step[23000]: Train loss: 70.6020, Valid loss: 73.5715\n",
      "Epoch [56/100], Step[23100]: Train loss: 83.0982, Valid loss: 73.4796\n",
      "Epoch [56/100], Step[23200]: Train loss: 73.5668, Valid loss: 73.9538\n",
      "Epoch [56/100], Step[23300]: Train loss: 86.2725, Valid loss: 74.3586\n",
      "Epoch [56/100], Step[23400]: Train loss: 72.8934, Valid loss: 73.5035\n",
      "Epoch [57/100], Step[23500]: Train loss: 71.9564, Valid loss: 73.8482\n",
      "Epoch [57/100], Step[23600]: Train loss: 79.5824, Valid loss: 73.4774\n",
      "Epoch [57/100], Step[23700]: Train loss: 72.3897, Valid loss: 73.5232\n",
      "Epoch [57/100], Step[23800]: Train loss: 83.6648, Valid loss: 73.7458\n",
      "Epoch [58/100], Step[23900]: Train loss: 78.8482, Valid loss: 73.5818\n",
      "Epoch [58/100], Step[24000]: Train loss: 70.0894, Valid loss: 73.9514\n",
      "Epoch [58/100], Step[24100]: Train loss: 71.1959, Valid loss: 73.8876\n",
      "Epoch [58/100], Step[24200]: Train loss: 70.3698, Valid loss: 73.9667\n",
      "Epoch [59/100], Step[24300]: Train loss: 70.2346, Valid loss: 73.7470\n",
      "Epoch [59/100], Step[24400]: Train loss: 72.1108, Valid loss: 74.0161\n",
      "Epoch [59/100], Step[24500]: Train loss: 88.4882, Valid loss: 73.7551\n",
      "Epoch [59/100], Step[24600]: Train loss: 79.1334, Valid loss: 73.3688\n",
      "Saving model with loss 73.369...\n",
      "Epoch [60/100], Step[24700]: Train loss: 83.5416, Valid loss: 73.5668\n",
      "Epoch [60/100], Step[24800]: Train loss: 81.8581, Valid loss: 73.8863\n",
      "Epoch [60/100], Step[24900]: Train loss: 72.0779, Valid loss: 74.0215\n",
      "Epoch [60/100], Step[25000]: Train loss: 77.9441, Valid loss: 73.8706\n",
      "Epoch [61/100], Step[25100]: Train loss: 78.8910, Valid loss: 73.5303\n",
      "Epoch [61/100], Step[25200]: Train loss: 69.8625, Valid loss: 73.6634\n",
      "Epoch [61/100], Step[25300]: Train loss: 86.9422, Valid loss: 73.5909\n",
      "Epoch [61/100], Step[25400]: Train loss: 70.5400, Valid loss: 73.9660\n",
      "Epoch [62/100], Step[25500]: Train loss: 72.7083, Valid loss: 73.8470\n",
      "Epoch [62/100], Step[25600]: Train loss: 76.0552, Valid loss: 73.9676\n",
      "Epoch [62/100], Step[25700]: Train loss: 79.7077, Valid loss: 74.2061\n",
      "Epoch [62/100], Step[25800]: Train loss: 73.7588, Valid loss: 73.7267\n",
      "Epoch [62/100], Step[25900]: Train loss: 72.2568, Valid loss: 73.7326\n",
      "Epoch [63/100], Step[26000]: Train loss: 75.4834, Valid loss: 73.4747\n",
      "Epoch [63/100], Step[26100]: Train loss: 82.8469, Valid loss: 73.3595\n",
      "Saving model with loss 73.360...\n",
      "Epoch [63/100], Step[26200]: Train loss: 84.7375, Valid loss: 73.7785\n",
      "Epoch [63/100], Step[26300]: Train loss: 66.0469, Valid loss: 73.4712\n",
      "Epoch [64/100], Step[26400]: Train loss: 77.4700, Valid loss: 73.6529\n",
      "Epoch [64/100], Step[26500]: Train loss: 77.1881, Valid loss: 73.5904\n",
      "Epoch [64/100], Step[26600]: Train loss: 72.7523, Valid loss: 74.0525\n",
      "Epoch [64/100], Step[26700]: Train loss: 71.1302, Valid loss: 73.8946\n",
      "Epoch [65/100], Step[26800]: Train loss: 75.8775, Valid loss: 73.7808\n",
      "Epoch [65/100], Step[26900]: Train loss: 75.3489, Valid loss: 73.8653\n",
      "Epoch [65/100], Step[27000]: Train loss: 71.1629, Valid loss: 74.0626\n",
      "Epoch [65/100], Step[27100]: Train loss: 91.7359, Valid loss: 73.6802\n",
      "Epoch [66/100], Step[27200]: Train loss: 75.3327, Valid loss: 73.4854\n",
      "Epoch [66/100], Step[27300]: Train loss: 75.1199, Valid loss: 73.5435\n",
      "Epoch [66/100], Step[27400]: Train loss: 76.1697, Valid loss: 73.6913\n",
      "Epoch [66/100], Step[27500]: Train loss: 79.5997, Valid loss: 73.7825\n",
      "Epoch [67/100], Step[27600]: Train loss: 71.0675, Valid loss: 73.6808\n",
      "Epoch [67/100], Step[27700]: Train loss: 78.8338, Valid loss: 74.0728\n",
      "Epoch [67/100], Step[27800]: Train loss: 75.1992, Valid loss: 73.3527\n",
      "Saving model with loss 73.353...\n",
      "Epoch [67/100], Step[27900]: Train loss: 77.2757, Valid loss: 73.9028\n",
      "Epoch [67/100], Step[28000]: Train loss: 69.8402, Valid loss: 73.6539\n",
      "Epoch [68/100], Step[28100]: Train loss: 75.4228, Valid loss: 73.5992\n",
      "Epoch [68/100], Step[28200]: Train loss: 80.1667, Valid loss: 73.8661\n",
      "Epoch [68/100], Step[28300]: Train loss: 63.0005, Valid loss: 73.7906\n",
      "Epoch [68/100], Step[28400]: Train loss: 83.0636, Valid loss: 73.7756\n",
      "Epoch [69/100], Step[28500]: Train loss: 75.5906, Valid loss: 73.7054\n",
      "Epoch [69/100], Step[28600]: Train loss: 64.2018, Valid loss: 73.9526\n",
      "Epoch [69/100], Step[28700]: Train loss: 78.3442, Valid loss: 73.7474\n",
      "Epoch [69/100], Step[28800]: Train loss: 76.5451, Valid loss: 73.9285\n",
      "Epoch [70/100], Step[28900]: Train loss: 78.2598, Valid loss: 73.8555\n",
      "Epoch [70/100], Step[29000]: Train loss: 77.5670, Valid loss: 73.6229\n",
      "Epoch [70/100], Step[29100]: Train loss: 76.8924, Valid loss: 73.9952\n",
      "Epoch [70/100], Step[29200]: Train loss: 77.6437, Valid loss: 73.6951\n",
      "Epoch [71/100], Step[29300]: Train loss: 71.0615, Valid loss: 73.6478\n",
      "Epoch [71/100], Step[29400]: Train loss: 71.3685, Valid loss: 73.6422\n",
      "Epoch [71/100], Step[29500]: Train loss: 74.0397, Valid loss: 73.5801\n",
      "Epoch [71/100], Step[29600]: Train loss: 84.1574, Valid loss: 73.8415\n",
      "Epoch [72/100], Step[29700]: Train loss: 80.4036, Valid loss: 73.6314\n",
      "Epoch [72/100], Step[29800]: Train loss: 77.5432, Valid loss: 73.9334\n",
      "Epoch [72/100], Step[29900]: Train loss: 71.3736, Valid loss: 73.6556\n",
      "Epoch [72/100], Step[30000]: Train loss: 76.9454, Valid loss: 73.5084\n",
      "Epoch [73/100], Step[30100]: Train loss: 74.4987, Valid loss: 73.8196\n",
      "Epoch [73/100], Step[30200]: Train loss: 74.4080, Valid loss: 73.6852\n",
      "Epoch [73/100], Step[30300]: Train loss: 76.6942, Valid loss: 73.9395\n",
      "Epoch [73/100], Step[30400]: Train loss: 71.9096, Valid loss: 74.2455\n",
      "Epoch [73/100], Step[30500]: Train loss: 71.7924, Valid loss: 74.1277\n",
      "Epoch [74/100], Step[30600]: Train loss: 77.4590, Valid loss: 73.5158\n",
      "Epoch [74/100], Step[30700]: Train loss: 84.9356, Valid loss: 73.3375\n",
      "Saving model with loss 73.337...\n",
      "Epoch [74/100], Step[30800]: Train loss: 69.7329, Valid loss: 73.8816\n",
      "Epoch [74/100], Step[30900]: Train loss: 61.4633, Valid loss: 73.7770\n",
      "Epoch [75/100], Step[31000]: Train loss: 79.9013, Valid loss: 73.7403\n",
      "Epoch [75/100], Step[31100]: Train loss: 79.3710, Valid loss: 73.6050\n",
      "Epoch [75/100], Step[31200]: Train loss: 75.8111, Valid loss: 73.3270\n",
      "Saving model with loss 73.327...\n",
      "Epoch [75/100], Step[31300]: Train loss: 74.8999, Valid loss: 73.9675\n",
      "Epoch [76/100], Step[31400]: Train loss: 71.9708, Valid loss: 73.9801\n",
      "Epoch [76/100], Step[31500]: Train loss: 76.2073, Valid loss: 73.3984\n",
      "Epoch [76/100], Step[31600]: Train loss: 75.2394, Valid loss: 73.7861\n",
      "Epoch [76/100], Step[31700]: Train loss: 68.8491, Valid loss: 74.0177\n",
      "Epoch [77/100], Step[31800]: Train loss: 70.0600, Valid loss: 73.6651\n",
      "Epoch [77/100], Step[31900]: Train loss: 84.5107, Valid loss: 73.6263\n",
      "Epoch [77/100], Step[32000]: Train loss: 81.0117, Valid loss: 73.5875\n",
      "Epoch [77/100], Step[32100]: Train loss: 75.2118, Valid loss: 73.6655\n",
      "Epoch [78/100], Step[32200]: Train loss: 69.9983, Valid loss: 73.5588\n",
      "Epoch [78/100], Step[32300]: Train loss: 88.3380, Valid loss: 73.6930\n",
      "Epoch [78/100], Step[32400]: Train loss: 88.3961, Valid loss: 73.3379\n",
      "Epoch [78/100], Step[32500]: Train loss: 79.4010, Valid loss: 73.7857\n",
      "Epoch [78/100], Step[32600]: Train loss: 77.9986, Valid loss: 73.6251\n",
      "Epoch [79/100], Step[32700]: Train loss: 75.9563, Valid loss: 74.1264\n",
      "Epoch [79/100], Step[32800]: Train loss: 66.7310, Valid loss: 73.6657\n",
      "Epoch [79/100], Step[32900]: Train loss: 83.0135, Valid loss: 73.8215\n",
      "Epoch [79/100], Step[33000]: Train loss: 77.5636, Valid loss: 73.4843\n",
      "Epoch [80/100], Step[33100]: Train loss: 74.2768, Valid loss: 73.6251\n",
      "Epoch [80/100], Step[33200]: Train loss: 79.5362, Valid loss: 73.5483\n",
      "Epoch [80/100], Step[33300]: Train loss: 70.8837, Valid loss: 73.5734\n",
      "Epoch [80/100], Step[33400]: Train loss: 89.8117, Valid loss: 74.0233\n",
      "Epoch [81/100], Step[33500]: Train loss: 75.3766, Valid loss: 73.3327\n",
      "Epoch [81/100], Step[33600]: Train loss: 66.9643, Valid loss: 73.5718\n",
      "Epoch [81/100], Step[33700]: Train loss: 80.1150, Valid loss: 73.4372\n",
      "Epoch [81/100], Step[33800]: Train loss: 84.8645, Valid loss: 73.9054\n",
      "Epoch [82/100], Step[33900]: Train loss: 69.4357, Valid loss: 73.7846\n",
      "Epoch [82/100], Step[34000]: Train loss: 76.8785, Valid loss: 73.6114\n",
      "Epoch [82/100], Step[34100]: Train loss: 74.8707, Valid loss: 73.5536\n",
      "Epoch [82/100], Step[34200]: Train loss: 81.0488, Valid loss: 73.3358\n",
      "Epoch [83/100], Step[34300]: Train loss: 83.3787, Valid loss: 73.4183\n",
      "Epoch [83/100], Step[34400]: Train loss: 74.9813, Valid loss: 73.6655\n",
      "Epoch [83/100], Step[34500]: Train loss: 75.4033, Valid loss: 73.6425\n",
      "Epoch [83/100], Step[34600]: Train loss: 72.0353, Valid loss: 73.4737\n",
      "Epoch [84/100], Step[34700]: Train loss: 71.3317, Valid loss: 73.6756\n",
      "Epoch [84/100], Step[34800]: Train loss: 70.7084, Valid loss: 73.4718\n",
      "Epoch [84/100], Step[34900]: Train loss: 70.3374, Valid loss: 73.6898\n",
      "Epoch [84/100], Step[35000]: Train loss: 71.9133, Valid loss: 73.3360\n",
      "Epoch [84/100], Step[35100]: Train loss: 72.5271, Valid loss: 73.5331\n",
      "Epoch [85/100], Step[35200]: Train loss: 93.7425, Valid loss: 73.6364\n",
      "Epoch [85/100], Step[35300]: Train loss: 78.1016, Valid loss: 73.6582\n",
      "Epoch [85/100], Step[35400]: Train loss: 68.8522, Valid loss: 73.1758\n",
      "Saving model with loss 73.176...\n",
      "Epoch [85/100], Step[35500]: Train loss: 75.8927, Valid loss: 73.9235\n",
      "Epoch [86/100], Step[35600]: Train loss: 75.1157, Valid loss: 73.4083\n",
      "Epoch [86/100], Step[35700]: Train loss: 74.3339, Valid loss: 73.4919\n",
      "Epoch [86/100], Step[35800]: Train loss: 81.2350, Valid loss: 73.3966\n",
      "Epoch [86/100], Step[35900]: Train loss: 68.8906, Valid loss: 73.3052\n",
      "Epoch [87/100], Step[36000]: Train loss: 79.6207, Valid loss: 73.3225\n",
      "Epoch [87/100], Step[36100]: Train loss: 81.1078, Valid loss: 73.2126\n",
      "Epoch [87/100], Step[36200]: Train loss: 67.5614, Valid loss: 73.3935\n",
      "Epoch [87/100], Step[36300]: Train loss: 77.8509, Valid loss: 73.2030\n",
      "Epoch [88/100], Step[36400]: Train loss: 76.2431, Valid loss: 73.4401\n",
      "Epoch [88/100], Step[36500]: Train loss: 77.2117, Valid loss: 73.3711\n",
      "Epoch [88/100], Step[36600]: Train loss: 76.7367, Valid loss: 73.2408\n",
      "Epoch [88/100], Step[36700]: Train loss: 87.1049, Valid loss: 73.4096\n",
      "Epoch [89/100], Step[36800]: Train loss: 77.4061, Valid loss: 73.2892\n",
      "Epoch [89/100], Step[36900]: Train loss: 77.0987, Valid loss: 73.5896\n",
      "Epoch [89/100], Step[37000]: Train loss: 78.7717, Valid loss: 73.9337\n",
      "Epoch [89/100], Step[37100]: Train loss: 67.5663, Valid loss: 73.6506\n",
      "Epoch [89/100], Step[37200]: Train loss: 77.0894, Valid loss: 73.6692\n",
      "Epoch [90/100], Step[37300]: Train loss: 74.1027, Valid loss: 73.8148\n",
      "Epoch [90/100], Step[37400]: Train loss: 86.4120, Valid loss: 73.3681\n",
      "Epoch [90/100], Step[37500]: Train loss: 69.3893, Valid loss: 73.5042\n",
      "Epoch [90/100], Step[37600]: Train loss: 87.4620, Valid loss: 73.5415\n",
      "Epoch [91/100], Step[37700]: Train loss: 79.8249, Valid loss: 73.5158\n",
      "Epoch [91/100], Step[37800]: Train loss: 77.3287, Valid loss: 73.3390\n",
      "Epoch [91/100], Step[37900]: Train loss: 74.3510, Valid loss: 73.4311\n",
      "Epoch [91/100], Step[38000]: Train loss: 76.7259, Valid loss: 73.4077\n",
      "Epoch [92/100], Step[38100]: Train loss: 67.4315, Valid loss: 73.6759\n",
      "Epoch [92/100], Step[38200]: Train loss: 76.6191, Valid loss: 73.5260\n",
      "Epoch [92/100], Step[38300]: Train loss: 66.5221, Valid loss: 73.6456\n",
      "Epoch [92/100], Step[38400]: Train loss: 81.8850, Valid loss: 73.5211\n",
      "Epoch [93/100], Step[38500]: Train loss: 76.2790, Valid loss: 73.5546\n",
      "Epoch [93/100], Step[38600]: Train loss: 73.4100, Valid loss: 73.2715\n",
      "Epoch [93/100], Step[38700]: Train loss: 66.7623, Valid loss: 73.6392\n",
      "Epoch [93/100], Step[38800]: Train loss: 76.4736, Valid loss: 73.9614\n",
      "Epoch [94/100], Step[38900]: Train loss: 66.5503, Valid loss: 73.5407\n",
      "Epoch [94/100], Step[39000]: Train loss: 68.3453, Valid loss: 73.7028\n",
      "Epoch [94/100], Step[39100]: Train loss: 78.9835, Valid loss: 73.2987\n",
      "Epoch [94/100], Step[39200]: Train loss: 81.5422, Valid loss: 73.5786\n",
      "Epoch [95/100], Step[39300]: Train loss: 70.5475, Valid loss: 73.2758\n",
      "Epoch [95/100], Step[39400]: Train loss: 73.7656, Valid loss: 73.4765\n",
      "Epoch [95/100], Step[39500]: Train loss: 79.0858, Valid loss: 73.8494\n",
      "Epoch [95/100], Step[39600]: Train loss: 69.4791, Valid loss: 73.6623\n",
      "Epoch [95/100], Step[39700]: Train loss: 67.7845, Valid loss: 73.7827\n",
      "Epoch [96/100], Step[39800]: Train loss: 74.9503, Valid loss: 73.6528\n",
      "Epoch [96/100], Step[39900]: Train loss: 81.6155, Valid loss: 73.6997\n",
      "Epoch [96/100], Step[40000]: Train loss: 71.4919, Valid loss: 73.7799\n",
      "Epoch [96/100], Step[40100]: Train loss: 77.4527, Valid loss: 73.7508\n",
      "Epoch [97/100], Step[40200]: Train loss: 78.1468, Valid loss: 73.6496\n",
      "Epoch [97/100], Step[40300]: Train loss: 80.8280, Valid loss: 73.2229\n",
      "Epoch [97/100], Step[40400]: Train loss: 81.4862, Valid loss: 73.5339\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 90,\n",
    "    'z': 0.5,\n",
    "    'optimizer': \"Adam\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model7_0.5.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8489dadb-5ae2-4800-8ae9-6431f4a053d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f4fb760-11dd-408c-9cdc-f9867b44cfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 8.742596\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "\n",
    "# Change mse to rmse\n",
    "train_loss = np.sqrt(train_loss)\n",
    "valid_loss = np.sqrt(valid_loss)\n",
    "\n",
    "# Draw test, valid RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(step_arr, train_loss ,color = 'r', label=\"Training_RMSE\")\n",
    "plt.plot(step_arr, valid_loss ,color = 'g', label=\"Validation_RMSE\")\n",
    "plt.title(\"Training vs Validation RMSE\")\n",
    "plt.xlabel(\"step (batches)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17505b-386a-48c1-89bb-915bd26f1f96",
   "metadata": {},
   "source": [
    "This is a better model compared with the previous models, we can see significant decrease of Validation RMSE with the Training RMSE decreases and finally stablizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8880a2f-e97b-4a37-9f6e-b6e91ca6a4d2",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 117.5715, Valid loss: 112.2038\n",
      "Saving model with loss 112.204...\n",
      "Epoch [1/100], Step[200]: Train loss: 113.2742, Valid loss: 101.7296\n",
      "Saving model with loss 101.730...\n",
      "Epoch [1/100], Step[300]: Train loss: 96.1377, Valid loss: 89.0405\n",
      "Saving model with loss 89.041...\n",
      "Epoch [1/100], Step[400]: Train loss: 80.0840, Valid loss: 86.7423\n",
      "Saving model with loss 86.742...\n",
      "Epoch [2/100], Step[500]: Train loss: 107.5401, Valid loss: 85.1521\n",
      "Saving model with loss 85.152...\n",
      "Epoch [2/100], Step[600]: Train loss: 96.8539, Valid loss: 83.3410\n",
      "Saving model with loss 83.341...\n",
      "Epoch [2/100], Step[700]: Train loss: 84.5248, Valid loss: 83.8596\n",
      "Epoch [2/100], Step[800]: Train loss: 87.1753, Valid loss: 82.1575\n",
      "Saving model with loss 82.157...\n",
      "Epoch [3/100], Step[900]: Train loss: 95.8421, Valid loss: 83.4351\n",
      "Epoch [3/100], Step[1000]: Train loss: 90.0653, Valid loss: 82.5300\n",
      "Epoch [3/100], Step[1100]: Train loss: 88.9019, Valid loss: 81.4825\n",
      "Saving model with loss 81.482...\n",
      "Epoch [3/100], Step[1200]: Train loss: 89.4614, Valid loss: 82.0782\n",
      "Epoch [4/100], Step[1300]: Train loss: 81.7570, Valid loss: 81.2612\n",
      "Saving model with loss 81.261...\n",
      "Epoch [4/100], Step[1400]: Train loss: 88.9833, Valid loss: 80.3908\n",
      "Saving model with loss 80.391...\n",
      "Epoch [4/100], Step[1500]: Train loss: 86.9003, Valid loss: 81.8672\n",
      "Epoch [4/100], Step[1600]: Train loss: 80.9650, Valid loss: 80.7968\n",
      "Epoch [5/100], Step[1700]: Train loss: 82.0428, Valid loss: 81.4077\n",
      "Epoch [5/100], Step[1800]: Train loss: 111.3724, Valid loss: 80.8936\n",
      "Epoch [5/100], Step[1900]: Train loss: 78.6089, Valid loss: 80.1134\n",
      "Saving model with loss 80.113...\n",
      "Epoch [5/100], Step[2000]: Train loss: 88.3632, Valid loss: 80.6856\n",
      "Epoch [6/100], Step[2100]: Train loss: 86.1776, Valid loss: 81.0918\n",
      "Epoch [6/100], Step[2200]: Train loss: 68.0308, Valid loss: 80.6292\n",
      "Epoch [6/100], Step[2300]: Train loss: 75.6620, Valid loss: 79.6341\n",
      "Saving model with loss 79.634...\n",
      "Epoch [6/100], Step[2400]: Train loss: 77.6621, Valid loss: 79.8732\n",
      "Epoch [6/100], Step[2500]: Train loss: 86.9621, Valid loss: 79.7232\n",
      "Epoch [7/100], Step[2600]: Train loss: 86.6797, Valid loss: 79.5517\n",
      "Saving model with loss 79.552...\n",
      "Epoch [7/100], Step[2700]: Train loss: 77.1595, Valid loss: 80.5966\n",
      "Epoch [7/100], Step[2800]: Train loss: 73.1202, Valid loss: 80.8468\n",
      "Epoch [7/100], Step[2900]: Train loss: 91.3466, Valid loss: 80.2887\n",
      "Epoch [8/100], Step[3000]: Train loss: 73.9900, Valid loss: 80.1663\n",
      "Epoch [8/100], Step[3100]: Train loss: 88.4835, Valid loss: 79.9062\n",
      "Epoch [8/100], Step[3200]: Train loss: 86.8933, Valid loss: 79.5715\n",
      "Epoch [8/100], Step[3300]: Train loss: 94.5902, Valid loss: 80.9142\n",
      "Epoch [9/100], Step[3400]: Train loss: 73.8596, Valid loss: 79.8277\n",
      "Epoch [9/100], Step[3500]: Train loss: 82.7859, Valid loss: 79.6123\n",
      "Epoch [9/100], Step[3600]: Train loss: 90.8398, Valid loss: 78.8817\n",
      "Saving model with loss 78.882...\n",
      "Epoch [9/100], Step[3700]: Train loss: 92.3635, Valid loss: 79.5095\n",
      "Epoch [10/100], Step[3800]: Train loss: 89.9940, Valid loss: 80.1977\n",
      "Epoch [10/100], Step[3900]: Train loss: 92.5622, Valid loss: 79.4943\n",
      "Epoch [10/100], Step[4000]: Train loss: 90.2929, Valid loss: 79.3002\n",
      "Epoch [10/100], Step[4100]: Train loss: 86.7982, Valid loss: 79.4836\n",
      "Epoch [11/100], Step[4200]: Train loss: 80.9480, Valid loss: 80.2972\n",
      "Epoch [11/100], Step[4300]: Train loss: 87.0276, Valid loss: 79.2822\n",
      "Epoch [11/100], Step[4400]: Train loss: 84.4496, Valid loss: 79.3714\n",
      "Epoch [11/100], Step[4500]: Train loss: 87.6700, Valid loss: 79.4344\n",
      "Epoch [12/100], Step[4600]: Train loss: 86.3185, Valid loss: 79.6511\n",
      "Epoch [12/100], Step[4700]: Train loss: 95.1862, Valid loss: 79.1779\n",
      "Epoch [12/100], Step[4800]: Train loss: 84.2969, Valid loss: 79.1892\n",
      "Epoch [12/100], Step[4900]: Train loss: 92.4073, Valid loss: 79.7533\n",
      "Epoch [12/100], Step[5000]: Train loss: 79.5836, Valid loss: 80.0113\n",
      "Epoch [13/100], Step[5100]: Train loss: 76.9851, Valid loss: 79.7492\n",
      "Epoch [13/100], Step[5200]: Train loss: 83.7963, Valid loss: 80.1034\n",
      "Epoch [13/100], Step[5300]: Train loss: 86.9267, Valid loss: 79.5832\n",
      "Epoch [13/100], Step[5400]: Train loss: 72.4756, Valid loss: 79.8658\n",
      "Epoch [14/100], Step[5500]: Train loss: 85.1453, Valid loss: 78.9707\n",
      "Epoch [14/100], Step[5600]: Train loss: 88.7538, Valid loss: 78.7174\n",
      "Saving model with loss 78.717...\n",
      "Epoch [14/100], Step[5700]: Train loss: 88.5479, Valid loss: 79.1931\n",
      "Epoch [14/100], Step[5800]: Train loss: 76.6470, Valid loss: 79.5493\n",
      "Epoch [15/100], Step[5900]: Train loss: 92.9852, Valid loss: 79.3048\n",
      "Epoch [15/100], Step[6000]: Train loss: 99.6918, Valid loss: 79.1665\n",
      "Epoch [15/100], Step[6100]: Train loss: 82.0386, Valid loss: 78.6626\n",
      "Saving model with loss 78.663...\n",
      "Epoch [15/100], Step[6200]: Train loss: 81.9061, Valid loss: 79.3453\n",
      "Epoch [16/100], Step[6300]: Train loss: 82.0159, Valid loss: 78.8923\n",
      "Epoch [16/100], Step[6400]: Train loss: 83.3914, Valid loss: 79.4494\n",
      "Epoch [16/100], Step[6500]: Train loss: 94.6922, Valid loss: 79.4024\n",
      "Epoch [16/100], Step[6600]: Train loss: 79.6976, Valid loss: 79.3763\n",
      "Epoch [17/100], Step[6700]: Train loss: 88.8506, Valid loss: 79.3471\n",
      "Epoch [17/100], Step[6800]: Train loss: 89.6689, Valid loss: 79.4775\n",
      "Epoch [17/100], Step[6900]: Train loss: 81.8640, Valid loss: 79.5766\n",
      "Epoch [17/100], Step[7000]: Train loss: 74.3903, Valid loss: 78.7632\n",
      "Epoch [17/100], Step[7100]: Train loss: 84.9411, Valid loss: 78.8434\n",
      "Epoch [18/100], Step[7200]: Train loss: 86.7500, Valid loss: 79.4886\n",
      "Epoch [18/100], Step[7300]: Train loss: 80.7201, Valid loss: 78.9229\n",
      "Epoch [18/100], Step[7400]: Train loss: 84.4880, Valid loss: 78.8148\n",
      "Epoch [18/100], Step[7500]: Train loss: 71.1290, Valid loss: 78.9203\n",
      "Epoch [19/100], Step[7600]: Train loss: 80.0292, Valid loss: 78.5140\n",
      "Saving model with loss 78.514...\n",
      "Epoch [19/100], Step[7700]: Train loss: 86.9763, Valid loss: 78.8340\n",
      "Epoch [19/100], Step[7800]: Train loss: 79.2884, Valid loss: 79.8063\n",
      "Epoch [19/100], Step[7900]: Train loss: 77.2993, Valid loss: 79.4127\n",
      "Epoch [20/100], Step[8000]: Train loss: 85.4256, Valid loss: 79.4826\n",
      "Epoch [20/100], Step[8100]: Train loss: 82.0268, Valid loss: 79.1674\n",
      "Epoch [20/100], Step[8200]: Train loss: 90.5801, Valid loss: 79.3568\n",
      "Epoch [20/100], Step[8300]: Train loss: 100.7257, Valid loss: 79.3071\n",
      "Epoch [21/100], Step[8400]: Train loss: 84.5807, Valid loss: 78.9069\n",
      "Epoch [21/100], Step[8500]: Train loss: 93.7404, Valid loss: 79.2184\n",
      "Epoch [21/100], Step[8600]: Train loss: 88.5056, Valid loss: 79.2170\n",
      "Epoch [21/100], Step[8700]: Train loss: 88.4296, Valid loss: 78.8106\n",
      "Epoch [22/100], Step[8800]: Train loss: 89.0082, Valid loss: 79.1658\n",
      "Epoch [22/100], Step[8900]: Train loss: 78.6822, Valid loss: 78.8815\n",
      "Epoch [22/100], Step[9000]: Train loss: 78.4115, Valid loss: 78.3499\n",
      "Saving model with loss 78.350...\n",
      "Epoch [22/100], Step[9100]: Train loss: 89.4127, Valid loss: 78.2107\n",
      "Saving model with loss 78.211...\n",
      "Epoch [23/100], Step[9200]: Train loss: 81.0659, Valid loss: 78.3260\n",
      "Epoch [23/100], Step[9300]: Train loss: 97.7295, Valid loss: 79.4478\n",
      "Epoch [23/100], Step[9400]: Train loss: 99.4141, Valid loss: 78.0239\n",
      "Saving model with loss 78.024...\n",
      "Epoch [23/100], Step[9500]: Train loss: 81.5374, Valid loss: 78.9234\n",
      "Epoch [23/100], Step[9600]: Train loss: 78.3200, Valid loss: 79.1134\n",
      "Epoch [24/100], Step[9700]: Train loss: 81.3726, Valid loss: 78.5791\n",
      "Epoch [24/100], Step[9800]: Train loss: 70.9187, Valid loss: 78.4533\n",
      "Epoch [24/100], Step[9900]: Train loss: 75.3039, Valid loss: 78.4225\n",
      "Epoch [24/100], Step[10000]: Train loss: 82.4478, Valid loss: 78.5457\n",
      "Epoch [25/100], Step[10100]: Train loss: 85.3570, Valid loss: 78.4553\n",
      "Epoch [25/100], Step[10200]: Train loss: 79.4855, Valid loss: 78.7795\n",
      "Epoch [25/100], Step[10300]: Train loss: 89.1607, Valid loss: 78.5351\n",
      "Epoch [25/100], Step[10400]: Train loss: 79.7295, Valid loss: 79.1969\n",
      "Epoch [26/100], Step[10500]: Train loss: 75.2019, Valid loss: 79.2065\n",
      "Epoch [26/100], Step[10600]: Train loss: 80.8815, Valid loss: 78.3140\n",
      "Epoch [26/100], Step[10700]: Train loss: 76.9947, Valid loss: 78.3083\n",
      "Epoch [26/100], Step[10800]: Train loss: 87.1163, Valid loss: 78.3340\n",
      "Epoch [27/100], Step[10900]: Train loss: 84.3060, Valid loss: 78.3730\n",
      "Epoch [27/100], Step[11000]: Train loss: 74.5372, Valid loss: 78.3000\n",
      "Epoch [27/100], Step[11100]: Train loss: 83.8084, Valid loss: 78.2183\n",
      "Epoch [27/100], Step[11200]: Train loss: 74.1780, Valid loss: 77.9175\n",
      "Saving model with loss 77.917...\n",
      "Epoch [28/100], Step[11300]: Train loss: 84.4657, Valid loss: 79.0405\n",
      "Epoch [28/100], Step[11400]: Train loss: 75.3954, Valid loss: 79.0082\n",
      "Epoch [28/100], Step[11500]: Train loss: 88.9520, Valid loss: 78.9027\n",
      "Epoch [28/100], Step[11600]: Train loss: 86.5958, Valid loss: 78.7766\n",
      "Epoch [28/100], Step[11700]: Train loss: 78.3286, Valid loss: 78.1169\n",
      "Epoch [29/100], Step[11800]: Train loss: 78.9933, Valid loss: 78.7102\n",
      "Epoch [29/100], Step[11900]: Train loss: 77.7058, Valid loss: 78.5083\n",
      "Epoch [29/100], Step[12000]: Train loss: 76.6904, Valid loss: 78.9489\n",
      "Epoch [29/100], Step[12100]: Train loss: 103.9973, Valid loss: 78.8894\n",
      "Epoch [30/100], Step[12200]: Train loss: 76.0169, Valid loss: 79.0739\n",
      "Epoch [30/100], Step[12300]: Train loss: 77.0022, Valid loss: 78.8677\n",
      "Epoch [30/100], Step[12400]: Train loss: 87.8126, Valid loss: 78.3217\n",
      "Epoch [30/100], Step[12500]: Train loss: 81.4438, Valid loss: 77.9558\n",
      "Epoch [31/100], Step[12600]: Train loss: 67.6132, Valid loss: 78.5823\n",
      "Epoch [31/100], Step[12700]: Train loss: 77.4109, Valid loss: 78.5913\n",
      "Epoch [31/100], Step[12800]: Train loss: 78.0662, Valid loss: 78.2700\n",
      "Epoch [31/100], Step[12900]: Train loss: 87.6448, Valid loss: 78.9396\n",
      "Epoch [32/100], Step[13000]: Train loss: 71.3071, Valid loss: 78.5563\n",
      "Epoch [32/100], Step[13100]: Train loss: 87.3811, Valid loss: 78.8722\n",
      "Epoch [32/100], Step[13200]: Train loss: 84.0129, Valid loss: 78.5517\n",
      "Epoch [32/100], Step[13300]: Train loss: 83.5310, Valid loss: 79.3802\n",
      "Epoch [33/100], Step[13400]: Train loss: 86.4480, Valid loss: 78.6468\n",
      "Epoch [33/100], Step[13500]: Train loss: 83.2314, Valid loss: 78.2465\n",
      "Epoch [33/100], Step[13600]: Train loss: 81.7141, Valid loss: 79.3691\n",
      "Epoch [33/100], Step[13700]: Train loss: 80.6380, Valid loss: 78.8783\n",
      "Epoch [34/100], Step[13800]: Train loss: 96.7384, Valid loss: 79.1688\n",
      "Epoch [34/100], Step[13900]: Train loss: 83.7747, Valid loss: 78.7715\n",
      "Epoch [34/100], Step[14000]: Train loss: 95.3909, Valid loss: 78.9248\n",
      "Epoch [34/100], Step[14100]: Train loss: 74.3812, Valid loss: 78.7252\n",
      "Epoch [34/100], Step[14200]: Train loss: 90.5185, Valid loss: 78.1040\n",
      "Epoch [35/100], Step[14300]: Train loss: 83.6669, Valid loss: 78.6683\n",
      "Epoch [35/100], Step[14400]: Train loss: 85.3705, Valid loss: 78.5217\n",
      "Epoch [35/100], Step[14500]: Train loss: 77.1477, Valid loss: 78.7765\n",
      "Epoch [35/100], Step[14600]: Train loss: 66.5979, Valid loss: 78.9572\n",
      "Epoch [36/100], Step[14700]: Train loss: 84.7136, Valid loss: 78.2722\n",
      "Epoch [36/100], Step[14800]: Train loss: 90.8204, Valid loss: 78.4717\n",
      "Epoch [36/100], Step[14900]: Train loss: 86.5004, Valid loss: 78.8007\n",
      "Epoch [36/100], Step[15000]: Train loss: 75.1774, Valid loss: 78.3944\n",
      "Epoch [37/100], Step[15100]: Train loss: 77.4262, Valid loss: 78.2626\n",
      "Epoch [37/100], Step[15200]: Train loss: 98.0366, Valid loss: 78.5408\n",
      "Epoch [37/100], Step[15300]: Train loss: 74.0503, Valid loss: 79.0660\n",
      "Epoch [37/100], Step[15400]: Train loss: 82.3447, Valid loss: 78.3815\n",
      "Epoch [38/100], Step[15500]: Train loss: 78.9264, Valid loss: 78.5199\n",
      "Epoch [38/100], Step[15600]: Train loss: 84.2959, Valid loss: 79.4888\n",
      "Epoch [38/100], Step[15700]: Train loss: 79.5241, Valid loss: 78.4056\n",
      "Epoch [38/100], Step[15800]: Train loss: 73.2218, Valid loss: 78.6263\n",
      "Epoch [39/100], Step[15900]: Train loss: 91.7786, Valid loss: 78.8415\n",
      "Epoch [39/100], Step[16000]: Train loss: 90.7881, Valid loss: 78.3032\n",
      "Epoch [39/100], Step[16100]: Train loss: 88.2580, Valid loss: 78.4552\n",
      "Epoch [39/100], Step[16200]: Train loss: 81.3559, Valid loss: 78.4395\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 100.1811, Valid loss: 93.9114\n",
      "Saving model with loss 93.911...\n",
      "Epoch [1/100], Step[200]: Train loss: 80.6920, Valid loss: 83.6934\n",
      "Saving model with loss 83.693...\n",
      "Epoch [1/100], Step[300]: Train loss: 89.9072, Valid loss: 82.0478\n",
      "Saving model with loss 82.048...\n",
      "Epoch [1/100], Step[400]: Train loss: 75.6446, Valid loss: 79.9478\n",
      "Saving model with loss 79.948...\n",
      "Epoch [2/100], Step[500]: Train loss: 72.7316, Valid loss: 79.1380\n",
      "Saving model with loss 79.138...\n",
      "Epoch [2/100], Step[600]: Train loss: 84.3596, Valid loss: 78.3239\n",
      "Saving model with loss 78.324...\n",
      "Epoch [2/100], Step[700]: Train loss: 77.9742, Valid loss: 78.4105\n",
      "Epoch [2/100], Step[800]: Train loss: 77.8488, Valid loss: 77.7719\n",
      "Saving model with loss 77.772...\n",
      "Epoch [3/100], Step[900]: Train loss: 73.0028, Valid loss: 77.7683\n",
      "Saving model with loss 77.768...\n",
      "Epoch [3/100], Step[1000]: Train loss: 87.0672, Valid loss: 77.1314\n",
      "Saving model with loss 77.131...\n",
      "Epoch [3/100], Step[1100]: Train loss: 79.7131, Valid loss: 77.0606\n",
      "Saving model with loss 77.061...\n",
      "Epoch [3/100], Step[1200]: Train loss: 82.5180, Valid loss: 77.3870\n",
      "Epoch [4/100], Step[1300]: Train loss: 85.3524, Valid loss: 77.0898\n",
      "Epoch [4/100], Step[1400]: Train loss: 81.9111, Valid loss: 76.6293\n",
      "Saving model with loss 76.629...\n",
      "Epoch [4/100], Step[1500]: Train loss: 73.9169, Valid loss: 76.5492\n",
      "Saving model with loss 76.549...\n",
      "Epoch [4/100], Step[1600]: Train loss: 93.4008, Valid loss: 76.4832\n",
      "Saving model with loss 76.483...\n",
      "Epoch [5/100], Step[1700]: Train loss: 74.3019, Valid loss: 76.4014\n",
      "Saving model with loss 76.401...\n",
      "Epoch [5/100], Step[1800]: Train loss: 77.9082, Valid loss: 76.1331\n",
      "Saving model with loss 76.133...\n",
      "Epoch [5/100], Step[1900]: Train loss: 82.6978, Valid loss: 76.0944\n",
      "Saving model with loss 76.094...\n",
      "Epoch [5/100], Step[2000]: Train loss: 81.6685, Valid loss: 76.4698\n",
      "Epoch [6/100], Step[2100]: Train loss: 67.4667, Valid loss: 75.9604\n",
      "Saving model with loss 75.960...\n",
      "Epoch [6/100], Step[2200]: Train loss: 85.1780, Valid loss: 75.6330\n",
      "Saving model with loss 75.633...\n",
      "Epoch [6/100], Step[2300]: Train loss: 76.7539, Valid loss: 76.0649\n",
      "Epoch [6/100], Step[2400]: Train loss: 72.1931, Valid loss: 75.9512\n",
      "Epoch [6/100], Step[2500]: Train loss: 85.1701, Valid loss: 76.0992\n",
      "Epoch [7/100], Step[2600]: Train loss: 85.1838, Valid loss: 75.4669\n",
      "Saving model with loss 75.467...\n",
      "Epoch [7/100], Step[2700]: Train loss: 92.1818, Valid loss: 76.0668\n",
      "Epoch [7/100], Step[2800]: Train loss: 67.4761, Valid loss: 75.7097\n",
      "Epoch [7/100], Step[2900]: Train loss: 76.3855, Valid loss: 75.4730\n",
      "Epoch [8/100], Step[3000]: Train loss: 75.4993, Valid loss: 75.3530\n",
      "Saving model with loss 75.353...\n",
      "Epoch [8/100], Step[3100]: Train loss: 83.9626, Valid loss: 75.6352\n",
      "Epoch [8/100], Step[3200]: Train loss: 72.5419, Valid loss: 75.6698\n",
      "Epoch [8/100], Step[3300]: Train loss: 93.8894, Valid loss: 75.3028\n",
      "Saving model with loss 75.303...\n",
      "Epoch [9/100], Step[3400]: Train loss: 74.4486, Valid loss: 75.7895\n",
      "Epoch [9/100], Step[3500]: Train loss: 76.7507, Valid loss: 75.2054\n",
      "Saving model with loss 75.205...\n",
      "Epoch [9/100], Step[3600]: Train loss: 81.7022, Valid loss: 75.0207\n",
      "Saving model with loss 75.021...\n",
      "Epoch [9/100], Step[3700]: Train loss: 88.3203, Valid loss: 75.4004\n",
      "Epoch [10/100], Step[3800]: Train loss: 79.8974, Valid loss: 75.3651\n",
      "Epoch [10/100], Step[3900]: Train loss: 82.7632, Valid loss: 75.6316\n",
      "Epoch [10/100], Step[4000]: Train loss: 82.6078, Valid loss: 75.1849\n",
      "Epoch [10/100], Step[4100]: Train loss: 78.1524, Valid loss: 75.4669\n",
      "Epoch [11/100], Step[4200]: Train loss: 83.9721, Valid loss: 75.3767\n",
      "Epoch [11/100], Step[4300]: Train loss: 81.8579, Valid loss: 74.8291\n",
      "Saving model with loss 74.829...\n",
      "Epoch [11/100], Step[4400]: Train loss: 78.0674, Valid loss: 75.5554\n",
      "Epoch [11/100], Step[4500]: Train loss: 82.5245, Valid loss: 75.1211\n",
      "Epoch [12/100], Step[4600]: Train loss: 74.2210, Valid loss: 75.2456\n",
      "Epoch [12/100], Step[4700]: Train loss: 85.3789, Valid loss: 74.7674\n",
      "Saving model with loss 74.767...\n",
      "Epoch [12/100], Step[4800]: Train loss: 78.4944, Valid loss: 74.9317\n",
      "Epoch [12/100], Step[4900]: Train loss: 93.8299, Valid loss: 74.9864\n",
      "Epoch [12/100], Step[5000]: Train loss: 98.3691, Valid loss: 75.1214\n",
      "Epoch [13/100], Step[5100]: Train loss: 93.1627, Valid loss: 74.9245\n",
      "Epoch [13/100], Step[5200]: Train loss: 69.0516, Valid loss: 75.1272\n",
      "Epoch [13/100], Step[5300]: Train loss: 76.5186, Valid loss: 74.8665\n",
      "Epoch [13/100], Step[5400]: Train loss: 87.0527, Valid loss: 75.0407\n",
      "Epoch [14/100], Step[5500]: Train loss: 69.6197, Valid loss: 75.0967\n",
      "Epoch [14/100], Step[5600]: Train loss: 80.4951, Valid loss: 74.7440\n",
      "Saving model with loss 74.744...\n",
      "Epoch [14/100], Step[5700]: Train loss: 69.2522, Valid loss: 75.0556\n",
      "Epoch [14/100], Step[5800]: Train loss: 82.2166, Valid loss: 75.2323\n",
      "Epoch [15/100], Step[5900]: Train loss: 89.6953, Valid loss: 75.0620\n",
      "Epoch [15/100], Step[6000]: Train loss: 79.4428, Valid loss: 74.9180\n",
      "Epoch [15/100], Step[6100]: Train loss: 71.0905, Valid loss: 74.6104\n",
      "Saving model with loss 74.610...\n",
      "Epoch [15/100], Step[6200]: Train loss: 87.1485, Valid loss: 74.8465\n",
      "Epoch [16/100], Step[6300]: Train loss: 85.5264, Valid loss: 74.7569\n",
      "Epoch [16/100], Step[6400]: Train loss: 72.3706, Valid loss: 74.6910\n",
      "Epoch [16/100], Step[6500]: Train loss: 82.6510, Valid loss: 74.5374\n",
      "Saving model with loss 74.537...\n",
      "Epoch [16/100], Step[6600]: Train loss: 85.2494, Valid loss: 74.9579\n",
      "Epoch [17/100], Step[6700]: Train loss: 75.5777, Valid loss: 74.8691\n",
      "Epoch [17/100], Step[6800]: Train loss: 89.6839, Valid loss: 74.5918\n",
      "Epoch [17/100], Step[6900]: Train loss: 95.6173, Valid loss: 74.4943\n",
      "Saving model with loss 74.494...\n",
      "Epoch [17/100], Step[7000]: Train loss: 76.1727, Valid loss: 74.8238\n",
      "Epoch [17/100], Step[7100]: Train loss: 80.7398, Valid loss: 74.8729\n",
      "Epoch [18/100], Step[7200]: Train loss: 71.2111, Valid loss: 75.1852\n",
      "Epoch [18/100], Step[7300]: Train loss: 81.1605, Valid loss: 74.8938\n",
      "Epoch [18/100], Step[7400]: Train loss: 80.2617, Valid loss: 75.0514\n",
      "Epoch [18/100], Step[7500]: Train loss: 75.0702, Valid loss: 75.4966\n",
      "Epoch [19/100], Step[7600]: Train loss: 81.8732, Valid loss: 74.9012\n",
      "Epoch [19/100], Step[7700]: Train loss: 86.2527, Valid loss: 74.7621\n",
      "Epoch [19/100], Step[7800]: Train loss: 89.8537, Valid loss: 74.9276\n",
      "Epoch [19/100], Step[7900]: Train loss: 92.1086, Valid loss: 74.5615\n",
      "Epoch [20/100], Step[8000]: Train loss: 68.7861, Valid loss: 75.1679\n",
      "Epoch [20/100], Step[8100]: Train loss: 73.0915, Valid loss: 74.4385\n",
      "Saving model with loss 74.439...\n",
      "Epoch [20/100], Step[8200]: Train loss: 89.2410, Valid loss: 74.2242\n",
      "Saving model with loss 74.224...\n",
      "Epoch [20/100], Step[8300]: Train loss: 81.3266, Valid loss: 74.5448\n",
      "Epoch [21/100], Step[8400]: Train loss: 81.9656, Valid loss: 74.6869\n",
      "Epoch [21/100], Step[8500]: Train loss: 85.9302, Valid loss: 74.2811\n",
      "Epoch [21/100], Step[8600]: Train loss: 80.4890, Valid loss: 74.6819\n",
      "Epoch [21/100], Step[8700]: Train loss: 77.4125, Valid loss: 74.6098\n",
      "Epoch [22/100], Step[8800]: Train loss: 83.2017, Valid loss: 74.7616\n",
      "Epoch [22/100], Step[8900]: Train loss: 85.3444, Valid loss: 74.5334\n",
      "Epoch [22/100], Step[9000]: Train loss: 97.2353, Valid loss: 75.2036\n",
      "Epoch [22/100], Step[9100]: Train loss: 82.4545, Valid loss: 74.5338\n",
      "Epoch [23/100], Step[9200]: Train loss: 81.7024, Valid loss: 74.8432\n",
      "Epoch [23/100], Step[9300]: Train loss: 71.6250, Valid loss: 74.8935\n",
      "Epoch [23/100], Step[9400]: Train loss: 58.6728, Valid loss: 74.4209\n",
      "Epoch [23/100], Step[9500]: Train loss: 76.8474, Valid loss: 74.3061\n",
      "Epoch [23/100], Step[9600]: Train loss: 87.3165, Valid loss: 74.3125\n",
      "Epoch [24/100], Step[9700]: Train loss: 79.0774, Valid loss: 74.5570\n",
      "Epoch [24/100], Step[9800]: Train loss: 72.4506, Valid loss: 74.6049\n",
      "Epoch [24/100], Step[9900]: Train loss: 90.1372, Valid loss: 74.5271\n",
      "Epoch [24/100], Step[10000]: Train loss: 81.7052, Valid loss: 74.5877\n",
      "Epoch [25/100], Step[10100]: Train loss: 91.7604, Valid loss: 74.6105\n",
      "Epoch [25/100], Step[10200]: Train loss: 78.4594, Valid loss: 74.5957\n",
      "Epoch [25/100], Step[10300]: Train loss: 78.8967, Valid loss: 74.4135\n",
      "Epoch [25/100], Step[10400]: Train loss: 90.1889, Valid loss: 74.7096\n",
      "Epoch [26/100], Step[10500]: Train loss: 85.7449, Valid loss: 74.3497\n",
      "Epoch [26/100], Step[10600]: Train loss: 76.0642, Valid loss: 73.9977\n",
      "Saving model with loss 73.998...\n",
      "Epoch [26/100], Step[10700]: Train loss: 74.4625, Valid loss: 74.7505\n",
      "Epoch [26/100], Step[10800]: Train loss: 80.6056, Valid loss: 74.4883\n",
      "Epoch [27/100], Step[10900]: Train loss: 91.5548, Valid loss: 74.4274\n",
      "Epoch [27/100], Step[11000]: Train loss: 83.5316, Valid loss: 74.9035\n",
      "Epoch [27/100], Step[11100]: Train loss: 77.0574, Valid loss: 74.4129\n",
      "Epoch [27/100], Step[11200]: Train loss: 72.2798, Valid loss: 74.4834\n",
      "Epoch [28/100], Step[11300]: Train loss: 88.5097, Valid loss: 74.3339\n",
      "Epoch [28/100], Step[11400]: Train loss: 77.7047, Valid loss: 74.1898\n",
      "Epoch [28/100], Step[11500]: Train loss: 79.5527, Valid loss: 74.5806\n",
      "Epoch [28/100], Step[11600]: Train loss: 68.9767, Valid loss: 74.5961\n",
      "Epoch [28/100], Step[11700]: Train loss: 79.2034, Valid loss: 74.3496\n",
      "Epoch [29/100], Step[11800]: Train loss: 81.7062, Valid loss: 73.9727\n",
      "Saving model with loss 73.973...\n",
      "Epoch [29/100], Step[11900]: Train loss: 77.3952, Valid loss: 74.4009\n",
      "Epoch [29/100], Step[12000]: Train loss: 86.4036, Valid loss: 73.9918\n",
      "Epoch [29/100], Step[12100]: Train loss: 80.5540, Valid loss: 74.6177\n",
      "Epoch [30/100], Step[12200]: Train loss: 89.1770, Valid loss: 74.5098\n",
      "Epoch [30/100], Step[12300]: Train loss: 69.1238, Valid loss: 74.2693\n",
      "Epoch [30/100], Step[12400]: Train loss: 67.3328, Valid loss: 74.2776\n",
      "Epoch [30/100], Step[12500]: Train loss: 71.0294, Valid loss: 74.4378\n",
      "Epoch [31/100], Step[12600]: Train loss: 80.4434, Valid loss: 74.3519\n",
      "Epoch [31/100], Step[12700]: Train loss: 75.0828, Valid loss: 74.3200\n",
      "Epoch [31/100], Step[12800]: Train loss: 72.1028, Valid loss: 74.5100\n",
      "Epoch [31/100], Step[12900]: Train loss: 77.0250, Valid loss: 74.3754\n",
      "Epoch [32/100], Step[13000]: Train loss: 68.5582, Valid loss: 74.2129\n",
      "Epoch [32/100], Step[13100]: Train loss: 74.0326, Valid loss: 74.5279\n",
      "Epoch [32/100], Step[13200]: Train loss: 71.4813, Valid loss: 74.1318\n",
      "Epoch [32/100], Step[13300]: Train loss: 84.7920, Valid loss: 74.0412\n",
      "Epoch [33/100], Step[13400]: Train loss: 80.4187, Valid loss: 74.4357\n",
      "Epoch [33/100], Step[13500]: Train loss: 74.5323, Valid loss: 74.2531\n",
      "Epoch [33/100], Step[13600]: Train loss: 76.6474, Valid loss: 73.9461\n",
      "Saving model with loss 73.946...\n",
      "Epoch [33/100], Step[13700]: Train loss: 77.3462, Valid loss: 74.5478\n",
      "Epoch [34/100], Step[13800]: Train loss: 79.4930, Valid loss: 74.3544\n",
      "Epoch [34/100], Step[13900]: Train loss: 75.2658, Valid loss: 73.9842\n",
      "Epoch [34/100], Step[14000]: Train loss: 73.2640, Valid loss: 74.1974\n",
      "Epoch [34/100], Step[14100]: Train loss: 67.8965, Valid loss: 74.3884\n",
      "Epoch [34/100], Step[14200]: Train loss: 77.2816, Valid loss: 74.2679\n",
      "Epoch [35/100], Step[14300]: Train loss: 93.2698, Valid loss: 74.0278\n",
      "Epoch [35/100], Step[14400]: Train loss: 80.4075, Valid loss: 74.1610\n",
      "Epoch [35/100], Step[14500]: Train loss: 94.3567, Valid loss: 74.1759\n",
      "Epoch [35/100], Step[14600]: Train loss: 68.2331, Valid loss: 74.9337\n",
      "Epoch [36/100], Step[14700]: Train loss: 87.0335, Valid loss: 74.2851\n",
      "Epoch [36/100], Step[14800]: Train loss: 84.2750, Valid loss: 73.9973\n",
      "Epoch [36/100], Step[14900]: Train loss: 78.6416, Valid loss: 74.3277\n",
      "Epoch [36/100], Step[15000]: Train loss: 88.5305, Valid loss: 74.0278\n",
      "Epoch [37/100], Step[15100]: Train loss: 85.6710, Valid loss: 74.2093\n",
      "Epoch [37/100], Step[15200]: Train loss: 89.1596, Valid loss: 74.4186\n",
      "Epoch [37/100], Step[15300]: Train loss: 80.5918, Valid loss: 74.3714\n",
      "Epoch [37/100], Step[15400]: Train loss: 68.6062, Valid loss: 74.0018\n",
      "Epoch [38/100], Step[15500]: Train loss: 89.8951, Valid loss: 74.2985\n",
      "Epoch [38/100], Step[15600]: Train loss: 80.7964, Valid loss: 74.3532\n",
      "Epoch [38/100], Step[15700]: Train loss: 87.6689, Valid loss: 74.3286\n",
      "Epoch [38/100], Step[15800]: Train loss: 75.2884, Valid loss: 74.1580\n",
      "Epoch [39/100], Step[15900]: Train loss: 74.4221, Valid loss: 73.8481\n",
      "Saving model with loss 73.848...\n",
      "Epoch [39/100], Step[16000]: Train loss: 85.2940, Valid loss: 74.4734\n",
      "Epoch [39/100], Step[16100]: Train loss: 83.8552, Valid loss: 74.5428\n",
      "Epoch [39/100], Step[16200]: Train loss: 75.9620, Valid loss: 74.3415\n",
      "Epoch [39/100], Step[16300]: Train loss: 92.6909, Valid loss: 74.1799\n",
      "Epoch [40/100], Step[16400]: Train loss: 77.2007, Valid loss: 74.0712\n",
      "Epoch [40/100], Step[16500]: Train loss: 80.2102, Valid loss: 74.3251\n",
      "Epoch [40/100], Step[16600]: Train loss: 78.4459, Valid loss: 74.4185\n",
      "Epoch [40/100], Step[16700]: Train loss: 71.9422, Valid loss: 74.8273\n",
      "Epoch [41/100], Step[16800]: Train loss: 84.1319, Valid loss: 73.9484\n",
      "Epoch [41/100], Step[16900]: Train loss: 72.5706, Valid loss: 73.8420\n",
      "Saving model with loss 73.842...\n",
      "Epoch [41/100], Step[17000]: Train loss: 78.7081, Valid loss: 74.1987\n",
      "Epoch [41/100], Step[17100]: Train loss: 71.3863, Valid loss: 74.0733\n",
      "Epoch [42/100], Step[17200]: Train loss: 78.1265, Valid loss: 74.3297\n",
      "Epoch [42/100], Step[17300]: Train loss: 65.1751, Valid loss: 74.0264\n",
      "Epoch [42/100], Step[17400]: Train loss: 79.4962, Valid loss: 73.9525\n",
      "Epoch [42/100], Step[17500]: Train loss: 80.1055, Valid loss: 74.4156\n",
      "Epoch [43/100], Step[17600]: Train loss: 68.5076, Valid loss: 74.2914\n",
      "Epoch [43/100], Step[17700]: Train loss: 71.3882, Valid loss: 74.2871\n",
      "Epoch [43/100], Step[17800]: Train loss: 73.6455, Valid loss: 74.2163\n",
      "Epoch [43/100], Step[17900]: Train loss: 72.8819, Valid loss: 74.4935\n",
      "Epoch [44/100], Step[18000]: Train loss: 71.5385, Valid loss: 74.4084\n",
      "Epoch [44/100], Step[18100]: Train loss: 75.8494, Valid loss: 74.4592\n",
      "Epoch [44/100], Step[18200]: Train loss: 77.3094, Valid loss: 74.6902\n",
      "Epoch [44/100], Step[18300]: Train loss: 84.8670, Valid loss: 73.8113\n",
      "Saving model with loss 73.811...\n",
      "Epoch [45/100], Step[18400]: Train loss: 81.2443, Valid loss: 73.8647\n",
      "Epoch [45/100], Step[18500]: Train loss: 81.0645, Valid loss: 74.0497\n",
      "Epoch [45/100], Step[18600]: Train loss: 75.7678, Valid loss: 74.4176\n",
      "Epoch [45/100], Step[18700]: Train loss: 80.6435, Valid loss: 74.1097\n",
      "Epoch [45/100], Step[18800]: Train loss: 77.5586, Valid loss: 73.8098\n",
      "Saving model with loss 73.810...\n",
      "Epoch [46/100], Step[18900]: Train loss: 82.7623, Valid loss: 74.4135\n",
      "Epoch [46/100], Step[19000]: Train loss: 75.6827, Valid loss: 74.7238\n",
      "Epoch [46/100], Step[19100]: Train loss: 92.0142, Valid loss: 74.5062\n",
      "Epoch [46/100], Step[19200]: Train loss: 79.0352, Valid loss: 74.1330\n",
      "Epoch [47/100], Step[19300]: Train loss: 70.1390, Valid loss: 74.1172\n",
      "Epoch [47/100], Step[19400]: Train loss: 81.6140, Valid loss: 74.1961\n",
      "Epoch [47/100], Step[19500]: Train loss: 81.8722, Valid loss: 74.0012\n",
      "Epoch [47/100], Step[19600]: Train loss: 79.9906, Valid loss: 74.3345\n",
      "Epoch [48/100], Step[19700]: Train loss: 74.2502, Valid loss: 73.8261\n",
      "Epoch [48/100], Step[19800]: Train loss: 72.1969, Valid loss: 74.0826\n",
      "Epoch [48/100], Step[19900]: Train loss: 74.2573, Valid loss: 74.1110\n",
      "Epoch [48/100], Step[20000]: Train loss: 76.7660, Valid loss: 74.2422\n",
      "Epoch [49/100], Step[20100]: Train loss: 71.7971, Valid loss: 73.9409\n",
      "Epoch [49/100], Step[20200]: Train loss: 74.5423, Valid loss: 74.3092\n",
      "Epoch [49/100], Step[20300]: Train loss: 94.3778, Valid loss: 74.2771\n",
      "Epoch [49/100], Step[20400]: Train loss: 80.7807, Valid loss: 74.0341\n",
      "Epoch [50/100], Step[20500]: Train loss: 81.9941, Valid loss: 74.4413\n",
      "Epoch [50/100], Step[20600]: Train loss: 76.4567, Valid loss: 74.2128\n",
      "Epoch [50/100], Step[20700]: Train loss: 84.1509, Valid loss: 74.4497\n",
      "Epoch [50/100], Step[20800]: Train loss: 72.5823, Valid loss: 73.8355\n",
      "Epoch [50/100], Step[20900]: Train loss: 81.1596, Valid loss: 74.0027\n",
      "Epoch [51/100], Step[21000]: Train loss: 62.9632, Valid loss: 74.1596\n",
      "Epoch [51/100], Step[21100]: Train loss: 71.7583, Valid loss: 73.9911\n",
      "Epoch [51/100], Step[21200]: Train loss: 74.2824, Valid loss: 73.9509\n",
      "Epoch [51/100], Step[21300]: Train loss: 77.4567, Valid loss: 73.9304\n",
      "Epoch [52/100], Step[21400]: Train loss: 68.0755, Valid loss: 74.1082\n",
      "Epoch [52/100], Step[21500]: Train loss: 76.6875, Valid loss: 74.1306\n",
      "Epoch [52/100], Step[21600]: Train loss: 70.7478, Valid loss: 73.9543\n",
      "Epoch [52/100], Step[21700]: Train loss: 66.8304, Valid loss: 74.2786\n",
      "Epoch [53/100], Step[21800]: Train loss: 79.9850, Valid loss: 73.9485\n",
      "Epoch [53/100], Step[21900]: Train loss: 82.1409, Valid loss: 74.0683\n",
      "Epoch [53/100], Step[22000]: Train loss: 83.3707, Valid loss: 74.5821\n",
      "Epoch [53/100], Step[22100]: Train loss: 89.6002, Valid loss: 73.9625\n",
      "Epoch [54/100], Step[22200]: Train loss: 89.1716, Valid loss: 74.1794\n",
      "Epoch [54/100], Step[22300]: Train loss: 77.5747, Valid loss: 73.9286\n",
      "Epoch [54/100], Step[22400]: Train loss: 75.7877, Valid loss: 74.1070\n",
      "Epoch [54/100], Step[22500]: Train loss: 88.9070, Valid loss: 73.9167\n",
      "Epoch [55/100], Step[22600]: Train loss: 78.7191, Valid loss: 74.0906\n",
      "Epoch [55/100], Step[22700]: Train loss: 87.2386, Valid loss: 74.2003\n",
      "Epoch [55/100], Step[22800]: Train loss: 87.7605, Valid loss: 73.7214\n",
      "Saving model with loss 73.721...\n",
      "Epoch [55/100], Step[22900]: Train loss: 72.2173, Valid loss: 74.1077\n",
      "Epoch [56/100], Step[23000]: Train loss: 82.1251, Valid loss: 74.4483\n",
      "Epoch [56/100], Step[23100]: Train loss: 89.8574, Valid loss: 74.1898\n",
      "Epoch [56/100], Step[23200]: Train loss: 83.8819, Valid loss: 74.0532\n",
      "Epoch [56/100], Step[23300]: Train loss: 82.3911, Valid loss: 74.1958\n",
      "Epoch [56/100], Step[23400]: Train loss: 74.8746, Valid loss: 73.9066\n",
      "Epoch [57/100], Step[23500]: Train loss: 68.8061, Valid loss: 73.7211\n",
      "Saving model with loss 73.721...\n",
      "Epoch [57/100], Step[23600]: Train loss: 69.1511, Valid loss: 73.7870\n",
      "Epoch [57/100], Step[23700]: Train loss: 72.9789, Valid loss: 73.6613\n",
      "Saving model with loss 73.661...\n",
      "Epoch [57/100], Step[23800]: Train loss: 77.1243, Valid loss: 74.0692\n",
      "Epoch [58/100], Step[23900]: Train loss: 73.1661, Valid loss: 73.6645\n",
      "Epoch [58/100], Step[24000]: Train loss: 71.9314, Valid loss: 73.7245\n",
      "Epoch [58/100], Step[24100]: Train loss: 81.1545, Valid loss: 73.9178\n",
      "Epoch [58/100], Step[24200]: Train loss: 70.3416, Valid loss: 74.1223\n",
      "Epoch [59/100], Step[24300]: Train loss: 79.0948, Valid loss: 74.0075\n",
      "Epoch [59/100], Step[24400]: Train loss: 74.0202, Valid loss: 74.0967\n",
      "Epoch [59/100], Step[24500]: Train loss: 78.7884, Valid loss: 74.5508\n",
      "Epoch [59/100], Step[24600]: Train loss: 93.2328, Valid loss: 73.8985\n",
      "Epoch [60/100], Step[24700]: Train loss: 71.8904, Valid loss: 74.0494\n",
      "Epoch [60/100], Step[24800]: Train loss: 85.3191, Valid loss: 73.9837\n",
      "Epoch [60/100], Step[24900]: Train loss: 75.9841, Valid loss: 74.3301\n",
      "Epoch [60/100], Step[25000]: Train loss: 73.3528, Valid loss: 74.0922\n",
      "Epoch [61/100], Step[25100]: Train loss: 79.1591, Valid loss: 74.5591\n",
      "Epoch [61/100], Step[25200]: Train loss: 88.3143, Valid loss: 74.1066\n",
      "Epoch [61/100], Step[25300]: Train loss: 79.5478, Valid loss: 74.0221\n",
      "Epoch [61/100], Step[25400]: Train loss: 75.2234, Valid loss: 73.9928\n",
      "Epoch [62/100], Step[25500]: Train loss: 79.9770, Valid loss: 74.3066\n",
      "Epoch [62/100], Step[25600]: Train loss: 76.2555, Valid loss: 74.4310\n",
      "Epoch [62/100], Step[25700]: Train loss: 75.9827, Valid loss: 73.8013\n",
      "Epoch [62/100], Step[25800]: Train loss: 78.8196, Valid loss: 74.0933\n",
      "Epoch [62/100], Step[25900]: Train loss: 90.5114, Valid loss: 74.1699\n",
      "Epoch [63/100], Step[26000]: Train loss: 84.8965, Valid loss: 73.9571\n",
      "Epoch [63/100], Step[26100]: Train loss: 88.3821, Valid loss: 74.1776\n",
      "Epoch [63/100], Step[26200]: Train loss: 81.2080, Valid loss: 73.9750\n",
      "Epoch [63/100], Step[26300]: Train loss: 77.2211, Valid loss: 74.5444\n",
      "Epoch [64/100], Step[26400]: Train loss: 79.0687, Valid loss: 74.1873\n",
      "Epoch [64/100], Step[26500]: Train loss: 56.7148, Valid loss: 74.5792\n",
      "Epoch [64/100], Step[26600]: Train loss: 84.0722, Valid loss: 74.0688\n",
      "Epoch [64/100], Step[26700]: Train loss: 77.2375, Valid loss: 74.3592\n",
      "Epoch [65/100], Step[26800]: Train loss: 81.6177, Valid loss: 74.3888\n",
      "Epoch [65/100], Step[26900]: Train loss: 69.0883, Valid loss: 74.0160\n",
      "Epoch [65/100], Step[27000]: Train loss: 82.2999, Valid loss: 73.9378\n",
      "Epoch [65/100], Step[27100]: Train loss: 83.5315, Valid loss: 74.1487\n",
      "Epoch [66/100], Step[27200]: Train loss: 80.4828, Valid loss: 74.0108\n",
      "Epoch [66/100], Step[27300]: Train loss: 84.9056, Valid loss: 74.3352\n",
      "Epoch [66/100], Step[27400]: Train loss: 88.5739, Valid loss: 74.5259\n",
      "Epoch [66/100], Step[27500]: Train loss: 80.9785, Valid loss: 74.3488\n",
      "Epoch [67/100], Step[27600]: Train loss: 77.2696, Valid loss: 73.9546\n",
      "Epoch [67/100], Step[27700]: Train loss: 77.2148, Valid loss: 74.1621\n",
      "Epoch [67/100], Step[27800]: Train loss: 79.4910, Valid loss: 74.0047\n",
      "Epoch [67/100], Step[27900]: Train loss: 80.8032, Valid loss: 74.0077\n",
      "Epoch [67/100], Step[28000]: Train loss: 75.5629, Valid loss: 74.1185\n",
      "Epoch [68/100], Step[28100]: Train loss: 81.8850, Valid loss: 73.9635\n",
      "Epoch [68/100], Step[28200]: Train loss: 75.4419, Valid loss: 73.9956\n",
      "Epoch [68/100], Step[28300]: Train loss: 70.5374, Valid loss: 74.1053\n",
      "Epoch [68/100], Step[28400]: Train loss: 81.1117, Valid loss: 74.2846\n",
      "Epoch [69/100], Step[28500]: Train loss: 75.5165, Valid loss: 73.9870\n",
      "Epoch [69/100], Step[28600]: Train loss: 67.6112, Valid loss: 74.2961\n",
      "Epoch [69/100], Step[28700]: Train loss: 80.5385, Valid loss: 73.9372\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 109.8380, Valid loss: 88.3637\n",
      "Saving model with loss 88.364...\n",
      "Epoch [1/100], Step[200]: Train loss: 80.4910, Valid loss: 83.2767\n",
      "Saving model with loss 83.277...\n",
      "Epoch [1/100], Step[300]: Train loss: 82.7289, Valid loss: 81.0708\n",
      "Saving model with loss 81.071...\n",
      "Epoch [1/100], Step[400]: Train loss: 95.3009, Valid loss: 80.2091\n",
      "Saving model with loss 80.209...\n",
      "Epoch [2/100], Step[500]: Train loss: 76.4443, Valid loss: 79.0066\n",
      "Saving model with loss 79.007...\n",
      "Epoch [2/100], Step[600]: Train loss: 93.7243, Valid loss: 78.9107\n",
      "Saving model with loss 78.911...\n",
      "Epoch [2/100], Step[700]: Train loss: 90.2228, Valid loss: 78.2029\n",
      "Saving model with loss 78.203...\n",
      "Epoch [2/100], Step[800]: Train loss: 86.6150, Valid loss: 78.2869\n",
      "Epoch [3/100], Step[900]: Train loss: 76.0519, Valid loss: 77.6765\n",
      "Saving model with loss 77.676...\n",
      "Epoch [3/100], Step[1000]: Train loss: 78.8739, Valid loss: 77.6130\n",
      "Saving model with loss 77.613...\n",
      "Epoch [3/100], Step[1100]: Train loss: 74.5266, Valid loss: 77.5109\n",
      "Saving model with loss 77.511...\n",
      "Epoch [3/100], Step[1200]: Train loss: 84.0398, Valid loss: 76.6621\n",
      "Saving model with loss 76.662...\n",
      "Epoch [4/100], Step[1300]: Train loss: 90.0293, Valid loss: 76.4083\n",
      "Saving model with loss 76.408...\n",
      "Epoch [4/100], Step[1400]: Train loss: 73.8199, Valid loss: 76.8567\n",
      "Epoch [4/100], Step[1500]: Train loss: 81.0561, Valid loss: 76.5060\n",
      "Epoch [4/100], Step[1600]: Train loss: 96.7110, Valid loss: 76.3686\n",
      "Saving model with loss 76.369...\n",
      "Epoch [5/100], Step[1700]: Train loss: 81.7105, Valid loss: 76.1942\n",
      "Saving model with loss 76.194...\n",
      "Epoch [5/100], Step[1800]: Train loss: 80.8290, Valid loss: 76.2546\n",
      "Epoch [5/100], Step[1900]: Train loss: 96.0317, Valid loss: 76.0639\n",
      "Saving model with loss 76.064...\n",
      "Epoch [5/100], Step[2000]: Train loss: 79.1038, Valid loss: 75.8010\n",
      "Saving model with loss 75.801...\n",
      "Epoch [6/100], Step[2100]: Train loss: 79.6446, Valid loss: 75.8644\n",
      "Epoch [6/100], Step[2200]: Train loss: 80.3507, Valid loss: 75.6615\n",
      "Saving model with loss 75.662...\n",
      "Epoch [6/100], Step[2300]: Train loss: 87.6526, Valid loss: 75.8660\n",
      "Epoch [6/100], Step[2400]: Train loss: 71.4094, Valid loss: 75.6154\n",
      "Saving model with loss 75.615...\n",
      "Epoch [6/100], Step[2500]: Train loss: 72.6391, Valid loss: 75.9678\n",
      "Epoch [7/100], Step[2600]: Train loss: 81.0072, Valid loss: 75.5925\n",
      "Saving model with loss 75.592...\n",
      "Epoch [7/100], Step[2700]: Train loss: 79.8890, Valid loss: 75.5812\n",
      "Saving model with loss 75.581...\n",
      "Epoch [7/100], Step[2800]: Train loss: 92.6702, Valid loss: 75.0765\n",
      "Saving model with loss 75.077...\n",
      "Epoch [7/100], Step[2900]: Train loss: 79.5093, Valid loss: 75.3487\n",
      "Epoch [8/100], Step[3000]: Train loss: 84.1856, Valid loss: 75.4050\n",
      "Epoch [8/100], Step[3100]: Train loss: 81.0459, Valid loss: 75.5694\n",
      "Epoch [8/100], Step[3200]: Train loss: 76.4326, Valid loss: 75.4156\n",
      "Epoch [8/100], Step[3300]: Train loss: 75.9631, Valid loss: 75.1589\n",
      "Epoch [9/100], Step[3400]: Train loss: 93.7048, Valid loss: 75.2002\n",
      "Epoch [9/100], Step[3500]: Train loss: 82.9067, Valid loss: 75.1114\n",
      "Epoch [9/100], Step[3600]: Train loss: 77.6599, Valid loss: 75.4888\n",
      "Epoch [9/100], Step[3700]: Train loss: 74.9841, Valid loss: 75.5408\n",
      "Epoch [10/100], Step[3800]: Train loss: 76.3460, Valid loss: 75.0411\n",
      "Saving model with loss 75.041...\n",
      "Epoch [10/100], Step[3900]: Train loss: 86.4519, Valid loss: 74.8898\n",
      "Saving model with loss 74.890...\n",
      "Epoch [10/100], Step[4000]: Train loss: 78.9873, Valid loss: 74.8566\n",
      "Saving model with loss 74.857...\n",
      "Epoch [10/100], Step[4100]: Train loss: 65.5175, Valid loss: 74.9321\n",
      "Epoch [11/100], Step[4200]: Train loss: 86.0827, Valid loss: 74.8292\n",
      "Saving model with loss 74.829...\n",
      "Epoch [11/100], Step[4300]: Train loss: 82.1553, Valid loss: 74.9009\n",
      "Epoch [11/100], Step[4400]: Train loss: 80.3080, Valid loss: 74.7011\n",
      "Saving model with loss 74.701...\n",
      "Epoch [11/100], Step[4500]: Train loss: 73.9576, Valid loss: 74.5113\n",
      "Saving model with loss 74.511...\n",
      "Epoch [12/100], Step[4600]: Train loss: 75.7515, Valid loss: 74.9999\n",
      "Epoch [12/100], Step[4700]: Train loss: 76.5606, Valid loss: 75.2255\n",
      "Epoch [12/100], Step[4800]: Train loss: 60.9602, Valid loss: 74.7724\n",
      "Epoch [12/100], Step[4900]: Train loss: 82.2865, Valid loss: 74.9466\n",
      "Epoch [12/100], Step[5000]: Train loss: 78.8224, Valid loss: 74.7950\n",
      "Epoch [13/100], Step[5100]: Train loss: 76.1033, Valid loss: 74.7867\n",
      "Epoch [13/100], Step[5200]: Train loss: 80.0539, Valid loss: 74.3385\n",
      "Saving model with loss 74.339...\n",
      "Epoch [13/100], Step[5300]: Train loss: 69.9121, Valid loss: 74.7656\n",
      "Epoch [13/100], Step[5400]: Train loss: 82.4060, Valid loss: 74.4017\n",
      "Epoch [14/100], Step[5500]: Train loss: 80.5695, Valid loss: 74.8917\n",
      "Epoch [14/100], Step[5600]: Train loss: 86.5979, Valid loss: 74.7871\n",
      "Epoch [14/100], Step[5700]: Train loss: 74.3234, Valid loss: 74.3123\n",
      "Saving model with loss 74.312...\n",
      "Epoch [14/100], Step[5800]: Train loss: 94.4148, Valid loss: 74.3914\n",
      "Epoch [15/100], Step[5900]: Train loss: 72.2978, Valid loss: 74.7662\n",
      "Epoch [15/100], Step[6000]: Train loss: 72.3854, Valid loss: 74.6741\n",
      "Epoch [15/100], Step[6100]: Train loss: 76.5897, Valid loss: 74.8236\n",
      "Epoch [15/100], Step[6200]: Train loss: 77.9438, Valid loss: 74.2427\n",
      "Saving model with loss 74.243...\n",
      "Epoch [16/100], Step[6300]: Train loss: 61.2471, Valid loss: 74.4112\n",
      "Epoch [16/100], Step[6400]: Train loss: 76.8312, Valid loss: 74.3221\n",
      "Epoch [16/100], Step[6500]: Train loss: 71.8126, Valid loss: 74.6718\n",
      "Epoch [16/100], Step[6600]: Train loss: 81.4839, Valid loss: 74.5541\n",
      "Epoch [17/100], Step[6700]: Train loss: 78.9632, Valid loss: 74.5456\n",
      "Epoch [17/100], Step[6800]: Train loss: 79.0541, Valid loss: 74.2462\n",
      "Epoch [17/100], Step[6900]: Train loss: 73.3079, Valid loss: 74.2286\n",
      "Saving model with loss 74.229...\n",
      "Epoch [17/100], Step[7000]: Train loss: 76.3806, Valid loss: 74.2709\n",
      "Epoch [17/100], Step[7100]: Train loss: 72.7120, Valid loss: 74.3727\n",
      "Epoch [18/100], Step[7200]: Train loss: 78.3627, Valid loss: 74.3271\n",
      "Epoch [18/100], Step[7300]: Train loss: 77.8849, Valid loss: 74.3098\n",
      "Epoch [18/100], Step[7400]: Train loss: 72.8955, Valid loss: 74.2406\n",
      "Epoch [18/100], Step[7500]: Train loss: 71.3491, Valid loss: 74.2847\n",
      "Epoch [19/100], Step[7600]: Train loss: 86.9888, Valid loss: 74.3315\n",
      "Epoch [19/100], Step[7700]: Train loss: 79.2297, Valid loss: 74.2624\n",
      "Epoch [19/100], Step[7800]: Train loss: 76.3073, Valid loss: 74.3312\n",
      "Epoch [19/100], Step[7900]: Train loss: 75.7098, Valid loss: 74.3023\n",
      "Epoch [20/100], Step[8000]: Train loss: 71.2841, Valid loss: 74.0757\n",
      "Saving model with loss 74.076...\n",
      "Epoch [20/100], Step[8100]: Train loss: 69.1548, Valid loss: 74.0441\n",
      "Saving model with loss 74.044...\n",
      "Epoch [20/100], Step[8200]: Train loss: 80.5263, Valid loss: 74.0883\n",
      "Epoch [20/100], Step[8300]: Train loss: 85.6174, Valid loss: 74.0961\n",
      "Epoch [21/100], Step[8400]: Train loss: 86.1913, Valid loss: 74.1197\n",
      "Epoch [21/100], Step[8500]: Train loss: 68.6678, Valid loss: 73.8459\n",
      "Saving model with loss 73.846...\n",
      "Epoch [21/100], Step[8600]: Train loss: 86.2957, Valid loss: 74.3011\n",
      "Epoch [21/100], Step[8700]: Train loss: 74.3312, Valid loss: 74.1595\n",
      "Epoch [22/100], Step[8800]: Train loss: 74.7915, Valid loss: 74.4535\n",
      "Epoch [22/100], Step[8900]: Train loss: 80.9462, Valid loss: 74.3428\n",
      "Epoch [22/100], Step[9000]: Train loss: 80.2364, Valid loss: 73.9463\n",
      "Epoch [22/100], Step[9100]: Train loss: 76.9025, Valid loss: 73.7923\n",
      "Saving model with loss 73.792...\n",
      "Epoch [23/100], Step[9200]: Train loss: 72.1455, Valid loss: 74.4730\n",
      "Epoch [23/100], Step[9300]: Train loss: 86.2809, Valid loss: 74.1597\n",
      "Epoch [23/100], Step[9400]: Train loss: 82.8815, Valid loss: 74.2781\n",
      "Epoch [23/100], Step[9500]: Train loss: 94.7520, Valid loss: 73.9120\n",
      "Epoch [23/100], Step[9600]: Train loss: 74.8638, Valid loss: 73.8518\n",
      "Epoch [24/100], Step[9700]: Train loss: 98.6573, Valid loss: 74.0998\n",
      "Epoch [24/100], Step[9800]: Train loss: 71.4497, Valid loss: 73.8736\n",
      "Epoch [24/100], Step[9900]: Train loss: 80.7015, Valid loss: 73.8155\n",
      "Epoch [24/100], Step[10000]: Train loss: 77.8083, Valid loss: 74.1336\n",
      "Epoch [25/100], Step[10100]: Train loss: 80.2918, Valid loss: 74.5107\n",
      "Epoch [25/100], Step[10200]: Train loss: 72.1979, Valid loss: 74.0001\n",
      "Epoch [25/100], Step[10300]: Train loss: 88.1750, Valid loss: 74.0163\n",
      "Epoch [25/100], Step[10400]: Train loss: 76.7532, Valid loss: 73.8515\n",
      "Epoch [26/100], Step[10500]: Train loss: 81.7553, Valid loss: 73.8315\n",
      "Epoch [26/100], Step[10600]: Train loss: 74.0807, Valid loss: 73.8939\n",
      "Epoch [26/100], Step[10700]: Train loss: 88.4592, Valid loss: 73.9874\n",
      "Epoch [26/100], Step[10800]: Train loss: 69.3736, Valid loss: 73.9911\n",
      "Epoch [27/100], Step[10900]: Train loss: 81.5718, Valid loss: 74.0462\n",
      "Epoch [27/100], Step[11000]: Train loss: 83.1244, Valid loss: 73.8989\n",
      "Epoch [27/100], Step[11100]: Train loss: 73.7424, Valid loss: 73.6963\n",
      "Saving model with loss 73.696...\n",
      "Epoch [27/100], Step[11200]: Train loss: 80.5240, Valid loss: 74.0541\n",
      "Epoch [28/100], Step[11300]: Train loss: 70.2618, Valid loss: 73.9522\n",
      "Epoch [28/100], Step[11400]: Train loss: 77.6021, Valid loss: 73.9385\n",
      "Epoch [28/100], Step[11500]: Train loss: 83.8217, Valid loss: 73.8281\n",
      "Epoch [28/100], Step[11600]: Train loss: 73.4419, Valid loss: 73.7990\n",
      "Epoch [28/100], Step[11700]: Train loss: 71.8116, Valid loss: 73.7725\n",
      "Epoch [29/100], Step[11800]: Train loss: 75.7114, Valid loss: 73.9104\n",
      "Epoch [29/100], Step[11900]: Train loss: 76.0653, Valid loss: 73.8319\n",
      "Epoch [29/100], Step[12000]: Train loss: 76.6133, Valid loss: 74.4713\n",
      "Epoch [29/100], Step[12100]: Train loss: 77.9479, Valid loss: 73.9535\n",
      "Epoch [30/100], Step[12200]: Train loss: 74.9080, Valid loss: 74.0752\n",
      "Epoch [30/100], Step[12300]: Train loss: 95.2372, Valid loss: 74.0755\n",
      "Epoch [30/100], Step[12400]: Train loss: 78.1784, Valid loss: 74.0064\n",
      "Epoch [30/100], Step[12500]: Train loss: 77.6678, Valid loss: 74.1019\n",
      "Epoch [31/100], Step[12600]: Train loss: 80.8514, Valid loss: 73.8037\n",
      "Epoch [31/100], Step[12700]: Train loss: 81.1605, Valid loss: 73.6728\n",
      "Saving model with loss 73.673...\n",
      "Epoch [31/100], Step[12800]: Train loss: 84.4037, Valid loss: 73.7840\n",
      "Epoch [31/100], Step[12900]: Train loss: 76.0794, Valid loss: 73.9766\n",
      "Epoch [32/100], Step[13000]: Train loss: 74.0190, Valid loss: 73.9793\n",
      "Epoch [32/100], Step[13100]: Train loss: 70.2926, Valid loss: 73.8240\n",
      "Epoch [32/100], Step[13200]: Train loss: 80.8419, Valid loss: 74.0826\n",
      "Epoch [32/100], Step[13300]: Train loss: 75.0302, Valid loss: 73.8862\n",
      "Epoch [33/100], Step[13400]: Train loss: 74.6580, Valid loss: 74.0135\n",
      "Epoch [33/100], Step[13500]: Train loss: 68.8111, Valid loss: 74.0618\n",
      "Epoch [33/100], Step[13600]: Train loss: 79.9920, Valid loss: 73.7161\n",
      "Epoch [33/100], Step[13700]: Train loss: 78.6420, Valid loss: 74.0182\n",
      "Epoch [34/100], Step[13800]: Train loss: 80.8880, Valid loss: 73.8527\n",
      "Epoch [34/100], Step[13900]: Train loss: 80.6023, Valid loss: 73.7160\n",
      "Epoch [34/100], Step[14000]: Train loss: 84.3173, Valid loss: 73.5219\n",
      "Saving model with loss 73.522...\n",
      "Epoch [34/100], Step[14100]: Train loss: 75.2794, Valid loss: 73.8129\n",
      "Epoch [34/100], Step[14200]: Train loss: 82.3355, Valid loss: 74.0150\n",
      "Epoch [35/100], Step[14300]: Train loss: 75.1013, Valid loss: 73.9068\n",
      "Epoch [35/100], Step[14400]: Train loss: 72.6062, Valid loss: 73.8646\n",
      "Epoch [35/100], Step[14500]: Train loss: 79.9051, Valid loss: 73.9698\n",
      "Epoch [35/100], Step[14600]: Train loss: 83.5202, Valid loss: 74.0602\n",
      "Epoch [36/100], Step[14700]: Train loss: 79.8366, Valid loss: 73.5435\n",
      "Epoch [36/100], Step[14800]: Train loss: 71.8498, Valid loss: 74.5102\n",
      "Epoch [36/100], Step[14900]: Train loss: 84.7100, Valid loss: 73.8477\n",
      "Epoch [36/100], Step[15000]: Train loss: 75.7848, Valid loss: 73.4764\n",
      "Saving model with loss 73.476...\n",
      "Epoch [37/100], Step[15100]: Train loss: 83.0198, Valid loss: 73.7180\n",
      "Epoch [37/100], Step[15200]: Train loss: 75.3315, Valid loss: 73.7151\n",
      "Epoch [37/100], Step[15300]: Train loss: 80.6221, Valid loss: 73.9444\n",
      "Epoch [37/100], Step[15400]: Train loss: 95.2505, Valid loss: 73.8166\n",
      "Epoch [38/100], Step[15500]: Train loss: 76.1760, Valid loss: 73.3708\n",
      "Saving model with loss 73.371...\n",
      "Epoch [38/100], Step[15600]: Train loss: 73.4632, Valid loss: 73.7962\n",
      "Epoch [38/100], Step[15700]: Train loss: 81.1246, Valid loss: 74.0085\n",
      "Epoch [38/100], Step[15800]: Train loss: 64.1454, Valid loss: 73.4730\n",
      "Epoch [39/100], Step[15900]: Train loss: 80.8674, Valid loss: 73.5335\n",
      "Epoch [39/100], Step[16000]: Train loss: 76.3569, Valid loss: 74.0289\n",
      "Epoch [39/100], Step[16100]: Train loss: 72.5801, Valid loss: 73.9666\n",
      "Epoch [39/100], Step[16200]: Train loss: 78.8387, Valid loss: 73.5118\n",
      "Epoch [39/100], Step[16300]: Train loss: 79.6015, Valid loss: 73.6361\n",
      "Epoch [40/100], Step[16400]: Train loss: 76.7588, Valid loss: 74.0068\n",
      "Epoch [40/100], Step[16500]: Train loss: 79.5996, Valid loss: 73.6144\n",
      "Epoch [40/100], Step[16600]: Train loss: 76.1122, Valid loss: 73.8555\n",
      "Epoch [40/100], Step[16700]: Train loss: 74.2246, Valid loss: 73.7479\n",
      "Epoch [41/100], Step[16800]: Train loss: 74.9509, Valid loss: 73.5097\n",
      "Epoch [41/100], Step[16900]: Train loss: 86.2177, Valid loss: 73.6592\n",
      "Epoch [41/100], Step[17000]: Train loss: 74.7721, Valid loss: 73.9724\n",
      "Epoch [41/100], Step[17100]: Train loss: 71.7102, Valid loss: 73.8260\n",
      "Epoch [42/100], Step[17200]: Train loss: 79.5924, Valid loss: 73.8589\n",
      "Epoch [42/100], Step[17300]: Train loss: 75.9663, Valid loss: 73.6719\n",
      "Epoch [42/100], Step[17400]: Train loss: 72.5334, Valid loss: 74.0784\n",
      "Epoch [42/100], Step[17500]: Train loss: 76.2216, Valid loss: 73.3563\n",
      "Saving model with loss 73.356...\n",
      "Epoch [43/100], Step[17600]: Train loss: 80.5840, Valid loss: 74.0384\n",
      "Epoch [43/100], Step[17700]: Train loss: 74.5153, Valid loss: 73.6349\n",
      "Epoch [43/100], Step[17800]: Train loss: 78.0526, Valid loss: 73.6427\n",
      "Epoch [43/100], Step[17900]: Train loss: 85.7247, Valid loss: 73.8962\n",
      "Epoch [44/100], Step[18000]: Train loss: 82.2551, Valid loss: 73.6019\n",
      "Epoch [44/100], Step[18100]: Train loss: 74.5866, Valid loss: 73.6216\n",
      "Epoch [44/100], Step[18200]: Train loss: 67.6323, Valid loss: 73.5161\n",
      "Epoch [44/100], Step[18300]: Train loss: 72.8848, Valid loss: 73.8089\n",
      "Epoch [45/100], Step[18400]: Train loss: 83.1710, Valid loss: 73.7797\n",
      "Epoch [45/100], Step[18500]: Train loss: 68.4009, Valid loss: 73.7457\n",
      "Epoch [45/100], Step[18600]: Train loss: 77.8266, Valid loss: 73.3321\n",
      "Saving model with loss 73.332...\n",
      "Epoch [45/100], Step[18700]: Train loss: 80.8779, Valid loss: 73.5826\n",
      "Epoch [45/100], Step[18800]: Train loss: 81.1928, Valid loss: 73.7028\n",
      "Epoch [46/100], Step[18900]: Train loss: 75.0687, Valid loss: 73.8813\n",
      "Epoch [46/100], Step[19000]: Train loss: 80.9402, Valid loss: 73.4674\n",
      "Epoch [46/100], Step[19100]: Train loss: 90.6370, Valid loss: 73.7470\n",
      "Epoch [46/100], Step[19200]: Train loss: 78.2649, Valid loss: 73.3828\n",
      "Epoch [47/100], Step[19300]: Train loss: 69.3691, Valid loss: 73.7325\n",
      "Epoch [47/100], Step[19400]: Train loss: 70.8545, Valid loss: 73.6425\n",
      "Epoch [47/100], Step[19500]: Train loss: 79.6263, Valid loss: 73.4986\n",
      "Epoch [47/100], Step[19600]: Train loss: 78.8046, Valid loss: 73.5436\n",
      "Epoch [48/100], Step[19700]: Train loss: 75.4432, Valid loss: 74.2684\n",
      "Epoch [48/100], Step[19800]: Train loss: 76.1651, Valid loss: 73.5738\n",
      "Epoch [48/100], Step[19900]: Train loss: 64.8349, Valid loss: 73.4694\n",
      "Epoch [48/100], Step[20000]: Train loss: 80.6641, Valid loss: 73.7482\n",
      "Epoch [49/100], Step[20100]: Train loss: 77.2219, Valid loss: 73.6586\n",
      "Epoch [49/100], Step[20200]: Train loss: 74.2658, Valid loss: 73.6165\n",
      "Epoch [49/100], Step[20300]: Train loss: 70.0960, Valid loss: 73.5701\n",
      "Epoch [49/100], Step[20400]: Train loss: 80.4533, Valid loss: 73.4369\n",
      "Epoch [50/100], Step[20500]: Train loss: 73.0532, Valid loss: 73.3901\n",
      "Epoch [50/100], Step[20600]: Train loss: 87.6772, Valid loss: 73.8154\n",
      "Epoch [50/100], Step[20700]: Train loss: 76.3808, Valid loss: 73.7543\n",
      "Epoch [50/100], Step[20800]: Train loss: 74.1083, Valid loss: 73.4742\n",
      "Epoch [50/100], Step[20900]: Train loss: 85.3695, Valid loss: 73.5919\n",
      "Epoch [51/100], Step[21000]: Train loss: 82.6531, Valid loss: 73.7188\n",
      "Epoch [51/100], Step[21100]: Train loss: 80.5091, Valid loss: 73.9959\n",
      "Epoch [51/100], Step[21200]: Train loss: 84.7332, Valid loss: 73.7907\n",
      "Epoch [51/100], Step[21300]: Train loss: 71.9386, Valid loss: 73.5913\n",
      "Epoch [52/100], Step[21400]: Train loss: 79.2600, Valid loss: 73.2304\n",
      "Saving model with loss 73.230...\n",
      "Epoch [52/100], Step[21500]: Train loss: 76.4111, Valid loss: 73.6468\n",
      "Epoch [52/100], Step[21600]: Train loss: 71.6073, Valid loss: 73.9823\n",
      "Epoch [52/100], Step[21700]: Train loss: 76.0013, Valid loss: 73.4427\n",
      "Epoch [53/100], Step[21800]: Train loss: 90.7206, Valid loss: 73.5933\n",
      "Epoch [53/100], Step[21900]: Train loss: 76.3202, Valid loss: 73.7494\n",
      "Epoch [53/100], Step[22000]: Train loss: 72.9291, Valid loss: 73.6403\n",
      "Epoch [53/100], Step[22100]: Train loss: 78.8439, Valid loss: 73.3376\n",
      "Epoch [54/100], Step[22200]: Train loss: 72.6615, Valid loss: 73.8918\n",
      "Epoch [54/100], Step[22300]: Train loss: 81.9612, Valid loss: 73.5232\n",
      "Epoch [54/100], Step[22400]: Train loss: 82.3384, Valid loss: 73.6565\n",
      "Epoch [54/100], Step[22500]: Train loss: 73.5409, Valid loss: 73.5247\n",
      "Epoch [55/100], Step[22600]: Train loss: 68.6130, Valid loss: 73.5180\n",
      "Epoch [55/100], Step[22700]: Train loss: 70.4495, Valid loss: 73.6902\n",
      "Epoch [55/100], Step[22800]: Train loss: 87.4439, Valid loss: 73.5802\n",
      "Epoch [55/100], Step[22900]: Train loss: 69.4012, Valid loss: 73.9924\n",
      "Epoch [56/100], Step[23000]: Train loss: 84.8423, Valid loss: 73.3059\n",
      "Epoch [56/100], Step[23100]: Train loss: 76.5494, Valid loss: 73.6474\n",
      "Epoch [56/100], Step[23200]: Train loss: 79.2269, Valid loss: 73.5025\n",
      "Epoch [56/100], Step[23300]: Train loss: 78.1381, Valid loss: 73.3226\n",
      "Epoch [56/100], Step[23400]: Train loss: 66.6832, Valid loss: 73.5022\n",
      "Epoch [57/100], Step[23500]: Train loss: 85.2967, Valid loss: 73.6885\n",
      "Epoch [57/100], Step[23600]: Train loss: 78.2095, Valid loss: 73.6978\n",
      "Epoch [57/100], Step[23700]: Train loss: 81.4215, Valid loss: 73.3875\n",
      "Epoch [57/100], Step[23800]: Train loss: 75.6620, Valid loss: 73.4098\n",
      "Epoch [58/100], Step[23900]: Train loss: 59.3350, Valid loss: 73.7504\n",
      "Epoch [58/100], Step[24000]: Train loss: 80.3052, Valid loss: 73.1727\n",
      "Saving model with loss 73.173...\n",
      "Epoch [58/100], Step[24100]: Train loss: 73.3448, Valid loss: 73.7332\n",
      "Epoch [58/100], Step[24200]: Train loss: 69.3707, Valid loss: 73.3277\n",
      "Epoch [59/100], Step[24300]: Train loss: 75.9220, Valid loss: 73.6931\n",
      "Epoch [59/100], Step[24400]: Train loss: 70.7717, Valid loss: 73.4004\n",
      "Epoch [59/100], Step[24500]: Train loss: 88.3292, Valid loss: 73.7716\n",
      "Epoch [59/100], Step[24600]: Train loss: 76.2176, Valid loss: 73.3144\n",
      "Epoch [60/100], Step[24700]: Train loss: 80.6070, Valid loss: 73.4474\n",
      "Epoch [60/100], Step[24800]: Train loss: 74.7602, Valid loss: 73.2764\n",
      "Epoch [60/100], Step[24900]: Train loss: 69.7103, Valid loss: 73.7432\n",
      "Epoch [60/100], Step[25000]: Train loss: 70.8366, Valid loss: 73.5328\n",
      "Epoch [61/100], Step[25100]: Train loss: 79.0274, Valid loss: 73.3230\n",
      "Epoch [61/100], Step[25200]: Train loss: 81.0921, Valid loss: 73.6545\n",
      "Epoch [61/100], Step[25300]: Train loss: 71.6888, Valid loss: 73.2045\n",
      "Epoch [61/100], Step[25400]: Train loss: 84.6381, Valid loss: 73.4324\n",
      "Epoch [62/100], Step[25500]: Train loss: 71.5763, Valid loss: 73.4751\n",
      "Epoch [62/100], Step[25600]: Train loss: 77.9784, Valid loss: 73.6706\n",
      "Epoch [62/100], Step[25700]: Train loss: 78.6514, Valid loss: 73.6120\n",
      "Epoch [62/100], Step[25800]: Train loss: 76.5745, Valid loss: 73.5888\n",
      "Epoch [62/100], Step[25900]: Train loss: 72.1421, Valid loss: 73.2402\n",
      "Epoch [63/100], Step[26000]: Train loss: 86.4265, Valid loss: 73.1811\n",
      "Epoch [63/100], Step[26100]: Train loss: 84.4187, Valid loss: 73.2855\n",
      "Epoch [63/100], Step[26200]: Train loss: 85.7047, Valid loss: 73.3575\n",
      "Epoch [63/100], Step[26300]: Train loss: 72.7022, Valid loss: 73.3713\n",
      "Epoch [64/100], Step[26400]: Train loss: 69.0470, Valid loss: 73.6249\n",
      "Epoch [64/100], Step[26500]: Train loss: 69.0056, Valid loss: 73.3611\n",
      "Epoch [64/100], Step[26600]: Train loss: 73.9074, Valid loss: 73.5608\n",
      "Epoch [64/100], Step[26700]: Train loss: 82.9885, Valid loss: 73.5098\n",
      "Epoch [65/100], Step[26800]: Train loss: 71.0449, Valid loss: 73.5542\n",
      "Epoch [65/100], Step[26900]: Train loss: 65.7357, Valid loss: 73.6542\n",
      "Epoch [65/100], Step[27000]: Train loss: 83.0958, Valid loss: 73.6561\n",
      "Epoch [65/100], Step[27100]: Train loss: 75.0294, Valid loss: 73.3709\n",
      "Epoch [66/100], Step[27200]: Train loss: 72.7073, Valid loss: 73.4993\n",
      "Epoch [66/100], Step[27300]: Train loss: 63.8614, Valid loss: 73.3900\n",
      "Epoch [66/100], Step[27400]: Train loss: 70.3052, Valid loss: 73.5589\n",
      "Epoch [66/100], Step[27500]: Train loss: 75.4324, Valid loss: 73.6188\n",
      "Epoch [67/100], Step[27600]: Train loss: 79.0581, Valid loss: 73.2035\n",
      "Epoch [67/100], Step[27700]: Train loss: 80.4115, Valid loss: 73.4327\n",
      "Epoch [67/100], Step[27800]: Train loss: 74.5374, Valid loss: 73.4096\n",
      "Epoch [67/100], Step[27900]: Train loss: 71.1106, Valid loss: 73.2845\n",
      "Epoch [67/100], Step[28000]: Train loss: 78.3437, Valid loss: 73.2218\n",
      "Epoch [68/100], Step[28100]: Train loss: 72.3721, Valid loss: 73.2332\n",
      "Epoch [68/100], Step[28200]: Train loss: 72.1024, Valid loss: 73.7465\n",
      "Epoch [68/100], Step[28300]: Train loss: 85.4591, Valid loss: 73.3619\n",
      "Epoch [68/100], Step[28400]: Train loss: 73.2985, Valid loss: 73.2635\n",
      "Epoch [69/100], Step[28500]: Train loss: 78.8769, Valid loss: 73.3834\n",
      "Epoch [69/100], Step[28600]: Train loss: 83.3603, Valid loss: 73.2274\n",
      "Epoch [69/100], Step[28700]: Train loss: 87.8707, Valid loss: 73.4096\n",
      "Epoch [69/100], Step[28800]: Train loss: 65.8163, Valid loss: 73.6668\n",
      "Epoch [70/100], Step[28900]: Train loss: 72.3962, Valid loss: 73.2791\n",
      "Epoch [70/100], Step[29000]: Train loss: 73.7604, Valid loss: 73.9383\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 95.3163, Valid loss: 89.2538\n",
      "Saving model with loss 89.254...\n",
      "Epoch [1/100], Step[200]: Train loss: 80.6675, Valid loss: 82.6273\n",
      "Saving model with loss 82.627...\n",
      "Epoch [1/100], Step[300]: Train loss: 90.0745, Valid loss: 80.3258\n",
      "Saving model with loss 80.326...\n",
      "Epoch [1/100], Step[400]: Train loss: 80.1209, Valid loss: 79.5365\n",
      "Saving model with loss 79.537...\n",
      "Epoch [2/100], Step[500]: Train loss: 88.3182, Valid loss: 78.8038\n",
      "Saving model with loss 78.804...\n",
      "Epoch [2/100], Step[600]: Train loss: 81.7861, Valid loss: 78.3255\n",
      "Saving model with loss 78.326...\n",
      "Epoch [2/100], Step[700]: Train loss: 78.6667, Valid loss: 78.2615\n",
      "Saving model with loss 78.261...\n",
      "Epoch [2/100], Step[800]: Train loss: 89.5523, Valid loss: 77.6202\n",
      "Saving model with loss 77.620...\n",
      "Epoch [3/100], Step[900]: Train loss: 79.9827, Valid loss: 77.7689\n",
      "Epoch [3/100], Step[1000]: Train loss: 84.7291, Valid loss: 77.0949\n",
      "Saving model with loss 77.095...\n",
      "Epoch [3/100], Step[1100]: Train loss: 92.4174, Valid loss: 77.6512\n",
      "Epoch [3/100], Step[1200]: Train loss: 77.5124, Valid loss: 76.6177\n",
      "Saving model with loss 76.618...\n",
      "Epoch [4/100], Step[1300]: Train loss: 86.1035, Valid loss: 77.0267\n",
      "Epoch [4/100], Step[1400]: Train loss: 98.9269, Valid loss: 76.5152\n",
      "Saving model with loss 76.515...\n",
      "Epoch [4/100], Step[1500]: Train loss: 85.6846, Valid loss: 76.3916\n",
      "Saving model with loss 76.392...\n",
      "Epoch [4/100], Step[1600]: Train loss: 77.3533, Valid loss: 76.5141\n",
      "Epoch [5/100], Step[1700]: Train loss: 78.1629, Valid loss: 76.6592\n",
      "Epoch [5/100], Step[1800]: Train loss: 83.5630, Valid loss: 76.3459\n",
      "Saving model with loss 76.346...\n",
      "Epoch [5/100], Step[1900]: Train loss: 80.9282, Valid loss: 76.3402\n",
      "Saving model with loss 76.340...\n",
      "Epoch [5/100], Step[2000]: Train loss: 85.6729, Valid loss: 76.2743\n",
      "Saving model with loss 76.274...\n",
      "Epoch [6/100], Step[2100]: Train loss: 79.1834, Valid loss: 75.9986\n",
      "Saving model with loss 75.999...\n",
      "Epoch [6/100], Step[2200]: Train loss: 77.7020, Valid loss: 75.7014\n",
      "Saving model with loss 75.701...\n",
      "Epoch [6/100], Step[2300]: Train loss: 78.5658, Valid loss: 75.8638\n",
      "Epoch [6/100], Step[2400]: Train loss: 82.4278, Valid loss: 75.7736\n",
      "Epoch [6/100], Step[2500]: Train loss: 75.1739, Valid loss: 75.9589\n",
      "Epoch [7/100], Step[2600]: Train loss: 74.6878, Valid loss: 75.5567\n",
      "Saving model with loss 75.557...\n",
      "Epoch [7/100], Step[2700]: Train loss: 77.5530, Valid loss: 75.8683\n",
      "Epoch [7/100], Step[2800]: Train loss: 81.4046, Valid loss: 75.7755\n",
      "Epoch [7/100], Step[2900]: Train loss: 76.8740, Valid loss: 75.2546\n",
      "Saving model with loss 75.255...\n",
      "Epoch [8/100], Step[3000]: Train loss: 82.4876, Valid loss: 75.0898\n",
      "Saving model with loss 75.090...\n",
      "Epoch [8/100], Step[3100]: Train loss: 77.2965, Valid loss: 75.4839\n",
      "Epoch [8/100], Step[3200]: Train loss: 76.9034, Valid loss: 75.2843\n",
      "Epoch [8/100], Step[3300]: Train loss: 82.0748, Valid loss: 75.3539\n",
      "Epoch [9/100], Step[3400]: Train loss: 76.6033, Valid loss: 75.6146\n",
      "Epoch [9/100], Step[3500]: Train loss: 92.6602, Valid loss: 75.0691\n",
      "Saving model with loss 75.069...\n",
      "Epoch [9/100], Step[3600]: Train loss: 70.5422, Valid loss: 75.1143\n",
      "Epoch [9/100], Step[3700]: Train loss: 81.8372, Valid loss: 75.2772\n",
      "Epoch [10/100], Step[3800]: Train loss: 83.5875, Valid loss: 75.1402\n",
      "Epoch [10/100], Step[3900]: Train loss: 82.8692, Valid loss: 75.0369\n",
      "Saving model with loss 75.037...\n",
      "Epoch [10/100], Step[4000]: Train loss: 87.3492, Valid loss: 75.1589\n",
      "Epoch [10/100], Step[4100]: Train loss: 84.9240, Valid loss: 75.0648\n",
      "Epoch [11/100], Step[4200]: Train loss: 72.2079, Valid loss: 75.2560\n",
      "Epoch [11/100], Step[4300]: Train loss: 71.3913, Valid loss: 75.1194\n",
      "Epoch [11/100], Step[4400]: Train loss: 71.7982, Valid loss: 74.8439\n",
      "Saving model with loss 74.844...\n",
      "Epoch [11/100], Step[4500]: Train loss: 80.5300, Valid loss: 75.0269\n",
      "Epoch [12/100], Step[4600]: Train loss: 80.0393, Valid loss: 74.8308\n",
      "Saving model with loss 74.831...\n",
      "Epoch [12/100], Step[4700]: Train loss: 72.7711, Valid loss: 75.1978\n",
      "Epoch [12/100], Step[4800]: Train loss: 79.7703, Valid loss: 75.0252\n",
      "Epoch [12/100], Step[4900]: Train loss: 82.3692, Valid loss: 74.9275\n",
      "Epoch [12/100], Step[5000]: Train loss: 84.8990, Valid loss: 74.7767\n",
      "Saving model with loss 74.777...\n",
      "Epoch [13/100], Step[5100]: Train loss: 75.1501, Valid loss: 74.6990\n",
      "Saving model with loss 74.699...\n",
      "Epoch [13/100], Step[5200]: Train loss: 89.3317, Valid loss: 74.5815\n",
      "Saving model with loss 74.582...\n",
      "Epoch [13/100], Step[5300]: Train loss: 76.5835, Valid loss: 74.7813\n",
      "Epoch [13/100], Step[5400]: Train loss: 86.9942, Valid loss: 74.9207\n",
      "Epoch [14/100], Step[5500]: Train loss: 71.9344, Valid loss: 75.4948\n",
      "Epoch [14/100], Step[5600]: Train loss: 78.3527, Valid loss: 75.0317\n",
      "Epoch [14/100], Step[5700]: Train loss: 75.7591, Valid loss: 74.7339\n",
      "Epoch [14/100], Step[5800]: Train loss: 82.2577, Valid loss: 74.4033\n",
      "Saving model with loss 74.403...\n",
      "Epoch [15/100], Step[5900]: Train loss: 78.1026, Valid loss: 75.1698\n",
      "Epoch [15/100], Step[6000]: Train loss: 77.9004, Valid loss: 74.9803\n",
      "Epoch [15/100], Step[6100]: Train loss: 80.0258, Valid loss: 75.1498\n",
      "Epoch [15/100], Step[6200]: Train loss: 74.9535, Valid loss: 74.4916\n",
      "Epoch [16/100], Step[6300]: Train loss: 82.7113, Valid loss: 74.8859\n",
      "Epoch [16/100], Step[6400]: Train loss: 84.2559, Valid loss: 74.6079\n",
      "Epoch [16/100], Step[6500]: Train loss: 75.8126, Valid loss: 74.5199\n",
      "Epoch [16/100], Step[6600]: Train loss: 70.8532, Valid loss: 74.7907\n",
      "Epoch [17/100], Step[6700]: Train loss: 81.9589, Valid loss: 74.7324\n",
      "Epoch [17/100], Step[6800]: Train loss: 78.1868, Valid loss: 74.6009\n",
      "Epoch [17/100], Step[6900]: Train loss: 77.4678, Valid loss: 74.7645\n",
      "Epoch [17/100], Step[7000]: Train loss: 83.5015, Valid loss: 74.4869\n",
      "Epoch [17/100], Step[7100]: Train loss: 70.4566, Valid loss: 74.7436\n",
      "Epoch [18/100], Step[7200]: Train loss: 77.6470, Valid loss: 74.8120\n",
      "Epoch [18/100], Step[7300]: Train loss: 81.7067, Valid loss: 74.7794\n",
      "Epoch [18/100], Step[7400]: Train loss: 81.6987, Valid loss: 74.5658\n",
      "Epoch [18/100], Step[7500]: Train loss: 88.9461, Valid loss: 74.8496\n",
      "Epoch [19/100], Step[7600]: Train loss: 85.3662, Valid loss: 74.7499\n",
      "Epoch [19/100], Step[7700]: Train loss: 80.7159, Valid loss: 74.5857\n",
      "Epoch [19/100], Step[7800]: Train loss: 72.3340, Valid loss: 74.4655\n",
      "Epoch [19/100], Step[7900]: Train loss: 85.8511, Valid loss: 74.2979\n",
      "Saving model with loss 74.298...\n",
      "Epoch [20/100], Step[8000]: Train loss: 69.7233, Valid loss: 74.5067\n",
      "Epoch [20/100], Step[8100]: Train loss: 75.5462, Valid loss: 74.4600\n",
      "Epoch [20/100], Step[8200]: Train loss: 83.0492, Valid loss: 74.6110\n",
      "Epoch [20/100], Step[8300]: Train loss: 78.0348, Valid loss: 74.6961\n",
      "Epoch [21/100], Step[8400]: Train loss: 71.6888, Valid loss: 74.5911\n",
      "Epoch [21/100], Step[8500]: Train loss: 80.7951, Valid loss: 74.3800\n",
      "Epoch [21/100], Step[8600]: Train loss: 82.8686, Valid loss: 74.6609\n",
      "Epoch [21/100], Step[8700]: Train loss: 70.5658, Valid loss: 74.5116\n",
      "Epoch [22/100], Step[8800]: Train loss: 74.5279, Valid loss: 74.3106\n",
      "Epoch [22/100], Step[8900]: Train loss: 73.2224, Valid loss: 74.1194\n",
      "Saving model with loss 74.119...\n",
      "Epoch [22/100], Step[9000]: Train loss: 71.2414, Valid loss: 74.4566\n",
      "Epoch [22/100], Step[9100]: Train loss: 82.0229, Valid loss: 74.4952\n",
      "Epoch [23/100], Step[9200]: Train loss: 76.8913, Valid loss: 74.0186\n",
      "Saving model with loss 74.019...\n",
      "Epoch [23/100], Step[9300]: Train loss: 76.1658, Valid loss: 73.9464\n",
      "Saving model with loss 73.946...\n",
      "Epoch [23/100], Step[9400]: Train loss: 67.3324, Valid loss: 74.0577\n",
      "Epoch [23/100], Step[9500]: Train loss: 82.3877, Valid loss: 74.2970\n",
      "Epoch [23/100], Step[9600]: Train loss: 83.4841, Valid loss: 74.4076\n",
      "Epoch [24/100], Step[9700]: Train loss: 81.5074, Valid loss: 74.1954\n",
      "Epoch [24/100], Step[9800]: Train loss: 84.4234, Valid loss: 74.4544\n",
      "Epoch [24/100], Step[9900]: Train loss: 73.4714, Valid loss: 74.2384\n",
      "Epoch [24/100], Step[10000]: Train loss: 62.7765, Valid loss: 74.4779\n",
      "Epoch [25/100], Step[10100]: Train loss: 79.1248, Valid loss: 74.2851\n",
      "Epoch [25/100], Step[10200]: Train loss: 91.1530, Valid loss: 74.4940\n",
      "Epoch [25/100], Step[10300]: Train loss: 66.5220, Valid loss: 74.3210\n",
      "Epoch [25/100], Step[10400]: Train loss: 76.6027, Valid loss: 74.0016\n",
      "Epoch [26/100], Step[10500]: Train loss: 76.3571, Valid loss: 74.4376\n",
      "Epoch [26/100], Step[10600]: Train loss: 74.1676, Valid loss: 74.9053\n",
      "Epoch [26/100], Step[10700]: Train loss: 77.0217, Valid loss: 74.6682\n",
      "Epoch [26/100], Step[10800]: Train loss: 72.9893, Valid loss: 74.2070\n",
      "Epoch [27/100], Step[10900]: Train loss: 77.1583, Valid loss: 74.2819\n",
      "Epoch [27/100], Step[11000]: Train loss: 75.5831, Valid loss: 74.2445\n",
      "Epoch [27/100], Step[11100]: Train loss: 83.4141, Valid loss: 74.3722\n",
      "Epoch [27/100], Step[11200]: Train loss: 74.5988, Valid loss: 74.1119\n",
      "Epoch [28/100], Step[11300]: Train loss: 76.1832, Valid loss: 74.4232\n",
      "Epoch [28/100], Step[11400]: Train loss: 77.2415, Valid loss: 74.3978\n",
      "Epoch [28/100], Step[11500]: Train loss: 82.7962, Valid loss: 74.2184\n",
      "Epoch [28/100], Step[11600]: Train loss: 65.6191, Valid loss: 74.1949\n",
      "Epoch [28/100], Step[11700]: Train loss: 71.7863, Valid loss: 74.1846\n",
      "Epoch [29/100], Step[11800]: Train loss: 73.5188, Valid loss: 74.2820\n",
      "Epoch [29/100], Step[11900]: Train loss: 74.5263, Valid loss: 74.2659\n",
      "Epoch [29/100], Step[12000]: Train loss: 79.1410, Valid loss: 74.2538\n",
      "Epoch [29/100], Step[12100]: Train loss: 77.7038, Valid loss: 74.0306\n",
      "Epoch [30/100], Step[12200]: Train loss: 75.0029, Valid loss: 74.5586\n",
      "Epoch [30/100], Step[12300]: Train loss: 83.0044, Valid loss: 74.5818\n",
      "Epoch [30/100], Step[12400]: Train loss: 77.9976, Valid loss: 74.0959\n",
      "Epoch [30/100], Step[12500]: Train loss: 75.9032, Valid loss: 73.7638\n",
      "Saving model with loss 73.764...\n",
      "Epoch [31/100], Step[12600]: Train loss: 84.8421, Valid loss: 74.2080\n",
      "Epoch [31/100], Step[12700]: Train loss: 83.4890, Valid loss: 73.7965\n",
      "Epoch [31/100], Step[12800]: Train loss: 78.9239, Valid loss: 73.9458\n",
      "Epoch [31/100], Step[12900]: Train loss: 83.9663, Valid loss: 74.1294\n",
      "Epoch [32/100], Step[13000]: Train loss: 69.0699, Valid loss: 73.9886\n",
      "Epoch [32/100], Step[13100]: Train loss: 79.6039, Valid loss: 74.1252\n",
      "Epoch [32/100], Step[13200]: Train loss: 84.1513, Valid loss: 74.1968\n",
      "Epoch [32/100], Step[13300]: Train loss: 93.2039, Valid loss: 74.0226\n",
      "Epoch [33/100], Step[13400]: Train loss: 81.1038, Valid loss: 73.7863\n",
      "Epoch [33/100], Step[13500]: Train loss: 71.2436, Valid loss: 73.6778\n",
      "Saving model with loss 73.678...\n",
      "Epoch [33/100], Step[13600]: Train loss: 78.6060, Valid loss: 74.4046\n",
      "Epoch [33/100], Step[13700]: Train loss: 74.1838, Valid loss: 73.9953\n",
      "Epoch [34/100], Step[13800]: Train loss: 81.7026, Valid loss: 74.0924\n",
      "Epoch [34/100], Step[13900]: Train loss: 89.2063, Valid loss: 74.0081\n",
      "Epoch [34/100], Step[14000]: Train loss: 74.1312, Valid loss: 74.1700\n",
      "Epoch [34/100], Step[14100]: Train loss: 73.6997, Valid loss: 74.2748\n",
      "Epoch [34/100], Step[14200]: Train loss: 74.2574, Valid loss: 74.1360\n",
      "Epoch [35/100], Step[14300]: Train loss: 92.6091, Valid loss: 73.6469\n",
      "Saving model with loss 73.647...\n",
      "Epoch [35/100], Step[14400]: Train loss: 74.9901, Valid loss: 74.0659\n",
      "Epoch [35/100], Step[14500]: Train loss: 79.2502, Valid loss: 73.8232\n",
      "Epoch [35/100], Step[14600]: Train loss: 75.9111, Valid loss: 73.9685\n",
      "Epoch [36/100], Step[14700]: Train loss: 80.1932, Valid loss: 74.0509\n",
      "Epoch [36/100], Step[14800]: Train loss: 78.8267, Valid loss: 74.3357\n",
      "Epoch [36/100], Step[14900]: Train loss: 69.8624, Valid loss: 74.1647\n",
      "Epoch [36/100], Step[15000]: Train loss: 83.4704, Valid loss: 74.1791\n",
      "Epoch [37/100], Step[15100]: Train loss: 105.5541, Valid loss: 74.2463\n",
      "Epoch [37/100], Step[15200]: Train loss: 72.5659, Valid loss: 74.0709\n",
      "Epoch [37/100], Step[15300]: Train loss: 84.9935, Valid loss: 74.0279\n",
      "Epoch [37/100], Step[15400]: Train loss: 92.9471, Valid loss: 74.1279\n",
      "Epoch [38/100], Step[15500]: Train loss: 86.6917, Valid loss: 73.9609\n",
      "Epoch [38/100], Step[15600]: Train loss: 72.4798, Valid loss: 73.7981\n",
      "Epoch [38/100], Step[15700]: Train loss: 72.8576, Valid loss: 73.8804\n",
      "Epoch [38/100], Step[15800]: Train loss: 77.4030, Valid loss: 74.0659\n",
      "Epoch [39/100], Step[15900]: Train loss: 73.2819, Valid loss: 74.0693\n",
      "Epoch [39/100], Step[16000]: Train loss: 74.4055, Valid loss: 73.7441\n",
      "Epoch [39/100], Step[16100]: Train loss: 82.0496, Valid loss: 73.8547\n",
      "Epoch [39/100], Step[16200]: Train loss: 83.4865, Valid loss: 73.8581\n",
      "Epoch [39/100], Step[16300]: Train loss: 82.6761, Valid loss: 73.8146\n",
      "Epoch [40/100], Step[16400]: Train loss: 76.9721, Valid loss: 73.9506\n",
      "Epoch [40/100], Step[16500]: Train loss: 81.6585, Valid loss: 73.9470\n",
      "Epoch [40/100], Step[16600]: Train loss: 73.2442, Valid loss: 74.0798\n",
      "Epoch [40/100], Step[16700]: Train loss: 72.8880, Valid loss: 73.7258\n",
      "Epoch [41/100], Step[16800]: Train loss: 76.3695, Valid loss: 73.8288\n",
      "Epoch [41/100], Step[16900]: Train loss: 68.2561, Valid loss: 74.1649\n",
      "Epoch [41/100], Step[17000]: Train loss: 82.9700, Valid loss: 74.3109\n",
      "Epoch [41/100], Step[17100]: Train loss: 81.8671, Valid loss: 74.3551\n",
      "Epoch [42/100], Step[17200]: Train loss: 75.7261, Valid loss: 73.5651\n",
      "Saving model with loss 73.565...\n",
      "Epoch [42/100], Step[17300]: Train loss: 74.8658, Valid loss: 73.8507\n",
      "Epoch [42/100], Step[17400]: Train loss: 75.8761, Valid loss: 73.8958\n",
      "Epoch [42/100], Step[17500]: Train loss: 71.2862, Valid loss: 73.8048\n",
      "Epoch [43/100], Step[17600]: Train loss: 78.8436, Valid loss: 74.1376\n",
      "Epoch [43/100], Step[17700]: Train loss: 81.1281, Valid loss: 73.7781\n",
      "Epoch [43/100], Step[17800]: Train loss: 72.3057, Valid loss: 74.2586\n",
      "Epoch [43/100], Step[17900]: Train loss: 75.4096, Valid loss: 74.0526\n",
      "Epoch [44/100], Step[18000]: Train loss: 80.6241, Valid loss: 74.1241\n",
      "Epoch [44/100], Step[18100]: Train loss: 74.7878, Valid loss: 73.8700\n",
      "Epoch [44/100], Step[18200]: Train loss: 75.6182, Valid loss: 73.7756\n",
      "Epoch [44/100], Step[18300]: Train loss: 76.5285, Valid loss: 73.9473\n",
      "Epoch [45/100], Step[18400]: Train loss: 82.8352, Valid loss: 74.0744\n",
      "Epoch [45/100], Step[18500]: Train loss: 71.1184, Valid loss: 73.7909\n",
      "Epoch [45/100], Step[18600]: Train loss: 78.0762, Valid loss: 74.0618\n",
      "Epoch [45/100], Step[18700]: Train loss: 74.0900, Valid loss: 74.1049\n",
      "Epoch [45/100], Step[18800]: Train loss: 74.4178, Valid loss: 73.6883\n",
      "Epoch [46/100], Step[18900]: Train loss: 78.8111, Valid loss: 73.7343\n",
      "Epoch [46/100], Step[19000]: Train loss: 72.4197, Valid loss: 73.8504\n",
      "Epoch [46/100], Step[19100]: Train loss: 85.9856, Valid loss: 73.9029\n",
      "Epoch [46/100], Step[19200]: Train loss: 71.8919, Valid loss: 73.6332\n",
      "Epoch [47/100], Step[19300]: Train loss: 78.0907, Valid loss: 73.5567\n",
      "Saving model with loss 73.557...\n",
      "Epoch [47/100], Step[19400]: Train loss: 77.1014, Valid loss: 74.2126\n",
      "Epoch [47/100], Step[19500]: Train loss: 86.7054, Valid loss: 73.9655\n",
      "Epoch [47/100], Step[19600]: Train loss: 76.3140, Valid loss: 74.0222\n",
      "Epoch [48/100], Step[19700]: Train loss: 80.5086, Valid loss: 73.7436\n",
      "Epoch [48/100], Step[19800]: Train loss: 74.3292, Valid loss: 73.9123\n",
      "Epoch [48/100], Step[19900]: Train loss: 87.9994, Valid loss: 74.0254\n",
      "Epoch [48/100], Step[20000]: Train loss: 72.0630, Valid loss: 74.1798\n",
      "Epoch [49/100], Step[20100]: Train loss: 75.1929, Valid loss: 73.5291\n",
      "Saving model with loss 73.529...\n",
      "Epoch [49/100], Step[20200]: Train loss: 74.3506, Valid loss: 73.9619\n",
      "Epoch [49/100], Step[20300]: Train loss: 79.0231, Valid loss: 73.9367\n",
      "Epoch [49/100], Step[20400]: Train loss: 77.9609, Valid loss: 74.0670\n",
      "Epoch [50/100], Step[20500]: Train loss: 84.0277, Valid loss: 73.7676\n",
      "Epoch [50/100], Step[20600]: Train loss: 78.9429, Valid loss: 73.8128\n",
      "Epoch [50/100], Step[20700]: Train loss: 78.0696, Valid loss: 74.1414\n",
      "Epoch [50/100], Step[20800]: Train loss: 75.3589, Valid loss: 73.7390\n",
      "Epoch [50/100], Step[20900]: Train loss: 75.4128, Valid loss: 73.7720\n",
      "Epoch [51/100], Step[21000]: Train loss: 85.3010, Valid loss: 73.9276\n",
      "Epoch [51/100], Step[21100]: Train loss: 74.8355, Valid loss: 74.2093\n",
      "Epoch [51/100], Step[21200]: Train loss: 78.1227, Valid loss: 73.9261\n",
      "Epoch [51/100], Step[21300]: Train loss: 81.6269, Valid loss: 73.7107\n",
      "Epoch [52/100], Step[21400]: Train loss: 78.4452, Valid loss: 73.9670\n",
      "Epoch [52/100], Step[21500]: Train loss: 82.8136, Valid loss: 73.9436\n",
      "Epoch [52/100], Step[21600]: Train loss: 90.2615, Valid loss: 74.0279\n",
      "Epoch [52/100], Step[21700]: Train loss: 69.4295, Valid loss: 74.0320\n",
      "Epoch [53/100], Step[21800]: Train loss: 66.7952, Valid loss: 73.7574\n",
      "Epoch [53/100], Step[21900]: Train loss: 76.4730, Valid loss: 73.5679\n",
      "Epoch [53/100], Step[22000]: Train loss: 80.7193, Valid loss: 73.7314\n",
      "Epoch [53/100], Step[22100]: Train loss: 70.5768, Valid loss: 73.8010\n",
      "Epoch [54/100], Step[22200]: Train loss: 78.0404, Valid loss: 73.6980\n",
      "Epoch [54/100], Step[22300]: Train loss: 59.9485, Valid loss: 73.6653\n",
      "Epoch [54/100], Step[22400]: Train loss: 76.0967, Valid loss: 73.8283\n",
      "Epoch [54/100], Step[22500]: Train loss: 73.6268, Valid loss: 73.6886\n",
      "Epoch [55/100], Step[22600]: Train loss: 70.5903, Valid loss: 73.8383\n",
      "Epoch [55/100], Step[22700]: Train loss: 74.8791, Valid loss: 73.8119\n",
      "Epoch [55/100], Step[22800]: Train loss: 74.4091, Valid loss: 73.8566\n",
      "Epoch [55/100], Step[22900]: Train loss: 90.0525, Valid loss: 73.8288\n",
      "Epoch [56/100], Step[23000]: Train loss: 76.6745, Valid loss: 73.9162\n",
      "Epoch [56/100], Step[23100]: Train loss: 77.7925, Valid loss: 73.7972\n",
      "Epoch [56/100], Step[23200]: Train loss: 69.7198, Valid loss: 73.8221\n",
      "Epoch [56/100], Step[23300]: Train loss: 79.1993, Valid loss: 73.9636\n",
      "Epoch [56/100], Step[23400]: Train loss: 78.7312, Valid loss: 73.8306\n",
      "Epoch [57/100], Step[23500]: Train loss: 73.3902, Valid loss: 73.8615\n",
      "Epoch [57/100], Step[23600]: Train loss: 76.1457, Valid loss: 73.7100\n",
      "Epoch [57/100], Step[23700]: Train loss: 76.8806, Valid loss: 73.7341\n",
      "Epoch [57/100], Step[23800]: Train loss: 79.0847, Valid loss: 73.9210\n",
      "Epoch [58/100], Step[23900]: Train loss: 75.9265, Valid loss: 73.5963\n",
      "Epoch [58/100], Step[24000]: Train loss: 74.9528, Valid loss: 73.7990\n",
      "Epoch [58/100], Step[24100]: Train loss: 89.9747, Valid loss: 73.9292\n",
      "Epoch [58/100], Step[24200]: Train loss: 73.1923, Valid loss: 73.9285\n",
      "Epoch [59/100], Step[24300]: Train loss: 77.9544, Valid loss: 73.7623\n",
      "Epoch [59/100], Step[24400]: Train loss: 74.4677, Valid loss: 73.7007\n",
      "Epoch [59/100], Step[24500]: Train loss: 79.2852, Valid loss: 73.8748\n",
      "Epoch [59/100], Step[24600]: Train loss: 76.9127, Valid loss: 73.7041\n",
      "Epoch [60/100], Step[24700]: Train loss: 75.5874, Valid loss: 74.0240\n",
      "Epoch [60/100], Step[24800]: Train loss: 69.9137, Valid loss: 73.8083\n",
      "Epoch [60/100], Step[24900]: Train loss: 73.7986, Valid loss: 73.7051\n",
      "Epoch [60/100], Step[25000]: Train loss: 80.8797, Valid loss: 73.8136\n",
      "Epoch [61/100], Step[25100]: Train loss: 76.3527, Valid loss: 73.7015\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "z_arr = []\n",
    "test_RMSE_arr = []\n",
    "\n",
    "for z in [0, 0.1, 0.9, 1]:\n",
    "    # config\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    config = {\n",
    "        'H': 90,\n",
    "        'z': z,\n",
    "        'optimizer': \"Adam\",\n",
    "        'weight_decay': 0,\n",
    "        'n_epochs': 100,     # Number of epochs.            \n",
    "        'learning_rate': 0.001,              \n",
    "        'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "        'save_path': './models/model7_' + str(z) +'.ckpt'  # Your model will be saved here.\n",
    "    }\n",
    "\n",
    "    # training\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "    step_arr = []\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    trainer(train_loader, valid_loader, model, config, device)\n",
    "\n",
    "    # testing\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "    model.load_state_dict(torch.load(config['save_path']))\n",
    "    preds = predict(test_loader, model, device)\n",
    "    test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "    \n",
    "    # append to array\n",
    "    z_arr.append(z)\n",
    "    test_RMSE_arr.append(test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21c4c0c8-dcf2-497e-b041-32c72c369291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.947004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8.756169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>8.768911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.782481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     z  test RMSE\n",
       "0  0.0   8.947004\n",
       "1  0.1   8.756169\n",
       "2  0.9   8.768911\n",
       "3  1.0   8.782481"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"z\": z_arr,\n",
    "       \"test RMSE\": test_RMSE_arr}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9144281-c71e-4b15-b350-05decee361f7",
   "metadata": {},
   "source": [
    "According to the chart above, z = 0.1 has the best result. Thus, we should pick z = 0.1 as the best model among all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f53b37-781c-43e9-8cc1-7e663b3eab50",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dec2286-9816-4fa6-8169-a35f16555a6a",
   "metadata": {
    "id": "k4Rq8_TztAhq"
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def l2Cust_loss(output, target, z):\n",
    "    c = torch.nn.functional.relu(output - target)\n",
    "    d = torch.nn.functional.relu(target - output)\n",
    "    loss = z * torch.sum((output - target)**2) + (1 - z) * torch.sum(0.5 * c + 0.5 * d)\n",
    "    return loss\n",
    "\n",
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "    # Define your optimization algorithm. \n",
    "    if config['optimizer'] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count, z = config['n_epochs'], math.inf, 0, 0, config['z']\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            model.train() # Set your model to train mode.\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
    "            pred = model(x)             \n",
    "            loss = l2Cust_loss(pred, y, z)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            # loss_record.append(loss.detach().item())\n",
    "            if step % 100 == 0:\n",
    "                mean_train_loss = criterion(pred, y).detach().item()\n",
    "                step_arr.append(step)\n",
    "                train_loss.append(mean_train_loss)\n",
    "\n",
    "                model.eval() # Set your model to evaluation mode.\n",
    "                loss_record = []\n",
    "                for x, y in valid_loader:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        pred = model(x)\n",
    "                        loss = criterion(pred, y)\n",
    "\n",
    "                    loss_record.append(loss.item())\n",
    "\n",
    "                mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "                valid_loss.append(mean_valid_loss)\n",
    "\n",
    "                print(f'Epoch [{epoch+1}/{n_epochs}], Step[{step}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "\n",
    "                if mean_valid_loss < best_loss:\n",
    "                    best_loss = mean_valid_loss\n",
    "                    best_step_count = step\n",
    "                    torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "                    print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1 * 100\n",
    "                \n",
    "                if early_stop_count >= config['early_stop']:\n",
    "                    print('\\nModel is not improving, so we halt the training session.')\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53410e31-854f-4807-bfe3-832b57f82c25",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 124.2908, Valid loss: 111.7897\n",
      "Saving model with loss 111.790...\n",
      "Epoch [1/100], Step[200]: Train loss: 101.9424, Valid loss: 99.5189\n",
      "Saving model with loss 99.519...\n",
      "Epoch [1/100], Step[300]: Train loss: 77.6261, Valid loss: 88.5082\n",
      "Saving model with loss 88.508...\n",
      "Epoch [1/100], Step[400]: Train loss: 92.8713, Valid loss: 86.7517\n",
      "Saving model with loss 86.752...\n",
      "Epoch [2/100], Step[500]: Train loss: 96.7650, Valid loss: 85.9678\n",
      "Saving model with loss 85.968...\n",
      "Epoch [2/100], Step[600]: Train loss: 90.7457, Valid loss: 83.9398\n",
      "Saving model with loss 83.940...\n",
      "Epoch [2/100], Step[700]: Train loss: 80.1885, Valid loss: 84.5056\n",
      "Epoch [2/100], Step[800]: Train loss: 80.2598, Valid loss: 83.2815\n",
      "Saving model with loss 83.282...\n",
      "Epoch [3/100], Step[900]: Train loss: 74.1942, Valid loss: 81.9020\n",
      "Saving model with loss 81.902...\n",
      "Epoch [3/100], Step[1000]: Train loss: 95.5184, Valid loss: 82.3475\n",
      "Epoch [3/100], Step[1100]: Train loss: 89.7762, Valid loss: 81.1822\n",
      "Saving model with loss 81.182...\n",
      "Epoch [3/100], Step[1200]: Train loss: 94.8060, Valid loss: 82.3626\n",
      "Epoch [4/100], Step[1300]: Train loss: 83.5261, Valid loss: 80.7498\n",
      "Saving model with loss 80.750...\n",
      "Epoch [4/100], Step[1400]: Train loss: 83.1319, Valid loss: 82.0002\n",
      "Epoch [4/100], Step[1500]: Train loss: 78.7951, Valid loss: 82.7159\n",
      "Epoch [4/100], Step[1600]: Train loss: 88.7487, Valid loss: 80.4659\n",
      "Saving model with loss 80.466...\n",
      "Epoch [5/100], Step[1700]: Train loss: 74.0181, Valid loss: 80.9766\n",
      "Epoch [5/100], Step[1800]: Train loss: 80.2986, Valid loss: 81.5459\n",
      "Epoch [5/100], Step[1900]: Train loss: 72.2259, Valid loss: 80.0598\n",
      "Saving model with loss 80.060...\n",
      "Epoch [5/100], Step[2000]: Train loss: 99.6081, Valid loss: 81.6925\n",
      "Epoch [6/100], Step[2100]: Train loss: 90.7921, Valid loss: 81.0254\n",
      "Epoch [6/100], Step[2200]: Train loss: 93.5146, Valid loss: 81.6289\n",
      "Epoch [6/100], Step[2300]: Train loss: 97.0540, Valid loss: 81.4614\n",
      "Epoch [6/100], Step[2400]: Train loss: 96.1231, Valid loss: 80.4971\n",
      "Epoch [6/100], Step[2500]: Train loss: 78.7639, Valid loss: 80.4981\n",
      "Epoch [7/100], Step[2600]: Train loss: 84.1142, Valid loss: 80.2075\n",
      "Epoch [7/100], Step[2700]: Train loss: 85.5126, Valid loss: 81.2327\n",
      "Epoch [7/100], Step[2800]: Train loss: 82.0903, Valid loss: 80.1342\n",
      "Epoch [7/100], Step[2900]: Train loss: 82.4568, Valid loss: 79.9237\n",
      "Saving model with loss 79.924...\n",
      "Epoch [8/100], Step[3000]: Train loss: 89.4967, Valid loss: 80.1795\n",
      "Epoch [8/100], Step[3100]: Train loss: 69.8750, Valid loss: 80.0513\n",
      "Epoch [8/100], Step[3200]: Train loss: 102.3517, Valid loss: 79.9937\n",
      "Epoch [8/100], Step[3300]: Train loss: 86.3283, Valid loss: 79.9872\n",
      "Epoch [9/100], Step[3400]: Train loss: 97.8940, Valid loss: 79.8923\n",
      "Saving model with loss 79.892...\n",
      "Epoch [9/100], Step[3500]: Train loss: 101.0189, Valid loss: 80.4292\n",
      "Epoch [9/100], Step[3600]: Train loss: 78.4008, Valid loss: 79.9294\n",
      "Epoch [9/100], Step[3700]: Train loss: 80.4225, Valid loss: 78.7635\n",
      "Saving model with loss 78.763...\n",
      "Epoch [10/100], Step[3800]: Train loss: 93.0085, Valid loss: 79.7222\n",
      "Epoch [10/100], Step[3900]: Train loss: 79.3959, Valid loss: 79.4761\n",
      "Epoch [10/100], Step[4000]: Train loss: 78.3718, Valid loss: 79.4866\n",
      "Epoch [10/100], Step[4100]: Train loss: 75.8515, Valid loss: 79.7007\n",
      "Epoch [11/100], Step[4200]: Train loss: 70.6833, Valid loss: 79.7840\n",
      "Epoch [11/100], Step[4300]: Train loss: 77.1900, Valid loss: 80.3865\n",
      "Epoch [11/100], Step[4400]: Train loss: 95.9082, Valid loss: 79.0791\n",
      "Epoch [11/100], Step[4500]: Train loss: 83.1424, Valid loss: 78.9510\n",
      "Epoch [12/100], Step[4600]: Train loss: 66.5229, Valid loss: 79.9263\n",
      "Epoch [12/100], Step[4700]: Train loss: 96.0542, Valid loss: 79.6580\n",
      "Epoch [12/100], Step[4800]: Train loss: 88.1626, Valid loss: 78.6915\n",
      "Saving model with loss 78.691...\n",
      "Epoch [12/100], Step[4900]: Train loss: 73.8780, Valid loss: 79.5850\n",
      "Epoch [12/100], Step[5000]: Train loss: 76.3511, Valid loss: 79.4592\n",
      "Epoch [13/100], Step[5100]: Train loss: 84.4957, Valid loss: 80.2259\n",
      "Epoch [13/100], Step[5200]: Train loss: 77.4075, Valid loss: 79.6853\n",
      "Epoch [13/100], Step[5300]: Train loss: 81.0329, Valid loss: 79.4858\n",
      "Epoch [13/100], Step[5400]: Train loss: 80.8736, Valid loss: 79.4384\n",
      "Epoch [14/100], Step[5500]: Train loss: 90.2935, Valid loss: 78.8614\n",
      "Epoch [14/100], Step[5600]: Train loss: 78.1745, Valid loss: 78.9953\n",
      "Epoch [14/100], Step[5700]: Train loss: 97.2137, Valid loss: 79.6539\n",
      "Epoch [14/100], Step[5800]: Train loss: 81.0036, Valid loss: 79.8522\n",
      "Epoch [15/100], Step[5900]: Train loss: 79.3922, Valid loss: 79.1774\n",
      "Epoch [15/100], Step[6000]: Train loss: 77.5981, Valid loss: 79.8095\n",
      "Epoch [15/100], Step[6100]: Train loss: 85.9574, Valid loss: 79.1509\n",
      "Epoch [15/100], Step[6200]: Train loss: 70.3075, Valid loss: 79.7823\n",
      "Epoch [16/100], Step[6300]: Train loss: 98.0173, Valid loss: 79.9356\n",
      "Epoch [16/100], Step[6400]: Train loss: 83.3246, Valid loss: 79.2330\n",
      "Epoch [16/100], Step[6500]: Train loss: 90.1471, Valid loss: 79.7578\n",
      "Epoch [16/100], Step[6600]: Train loss: 97.7862, Valid loss: 79.0377\n",
      "Epoch [17/100], Step[6700]: Train loss: 78.3578, Valid loss: 79.0279\n",
      "Epoch [17/100], Step[6800]: Train loss: 78.9776, Valid loss: 79.7563\n",
      "Epoch [17/100], Step[6900]: Train loss: 88.0779, Valid loss: 79.0224\n",
      "Epoch [17/100], Step[7000]: Train loss: 89.4986, Valid loss: 79.6589\n",
      "Epoch [17/100], Step[7100]: Train loss: 80.6386, Valid loss: 79.2928\n",
      "Epoch [18/100], Step[7200]: Train loss: 95.4472, Valid loss: 79.5241\n",
      "Epoch [18/100], Step[7300]: Train loss: 70.8569, Valid loss: 79.3345\n",
      "Epoch [18/100], Step[7400]: Train loss: 78.5724, Valid loss: 79.8901\n",
      "Epoch [18/100], Step[7500]: Train loss: 86.6993, Valid loss: 79.3603\n",
      "Epoch [19/100], Step[7600]: Train loss: 72.5528, Valid loss: 78.6588\n",
      "Saving model with loss 78.659...\n",
      "Epoch [19/100], Step[7700]: Train loss: 75.2203, Valid loss: 79.5531\n",
      "Epoch [19/100], Step[7800]: Train loss: 81.9367, Valid loss: 79.5558\n",
      "Epoch [19/100], Step[7900]: Train loss: 87.6666, Valid loss: 79.2342\n",
      "Epoch [20/100], Step[8000]: Train loss: 83.7259, Valid loss: 79.7288\n",
      "Epoch [20/100], Step[8100]: Train loss: 85.7557, Valid loss: 79.4813\n",
      "Epoch [20/100], Step[8200]: Train loss: 79.3863, Valid loss: 78.8208\n",
      "Epoch [20/100], Step[8300]: Train loss: 98.4052, Valid loss: 79.7282\n",
      "Epoch [21/100], Step[8400]: Train loss: 77.5158, Valid loss: 78.9349\n",
      "Epoch [21/100], Step[8500]: Train loss: 83.1917, Valid loss: 78.4112\n",
      "Saving model with loss 78.411...\n",
      "Epoch [21/100], Step[8600]: Train loss: 97.0552, Valid loss: 79.3829\n",
      "Epoch [21/100], Step[8700]: Train loss: 79.4533, Valid loss: 78.7282\n",
      "Epoch [22/100], Step[8800]: Train loss: 85.9386, Valid loss: 79.3338\n",
      "Epoch [22/100], Step[8900]: Train loss: 87.5057, Valid loss: 79.0512\n",
      "Epoch [22/100], Step[9000]: Train loss: 73.4559, Valid loss: 78.7372\n",
      "Epoch [22/100], Step[9100]: Train loss: 77.1197, Valid loss: 79.1257\n",
      "Epoch [23/100], Step[9200]: Train loss: 84.2876, Valid loss: 78.8086\n",
      "Epoch [23/100], Step[9300]: Train loss: 79.1530, Valid loss: 79.0202\n",
      "Epoch [23/100], Step[9400]: Train loss: 76.8469, Valid loss: 79.4621\n",
      "Epoch [23/100], Step[9500]: Train loss: 78.2189, Valid loss: 78.5236\n",
      "Epoch [23/100], Step[9600]: Train loss: 81.6325, Valid loss: 78.8906\n",
      "Epoch [24/100], Step[9700]: Train loss: 75.8208, Valid loss: 79.0385\n",
      "Epoch [24/100], Step[9800]: Train loss: 93.6144, Valid loss: 78.8161\n",
      "Epoch [24/100], Step[9900]: Train loss: 84.8559, Valid loss: 78.7836\n",
      "Epoch [24/100], Step[10000]: Train loss: 89.5914, Valid loss: 79.4723\n",
      "Epoch [25/100], Step[10100]: Train loss: 98.2877, Valid loss: 78.9961\n",
      "Epoch [25/100], Step[10200]: Train loss: 88.2251, Valid loss: 79.0137\n",
      "Epoch [25/100], Step[10300]: Train loss: 87.8869, Valid loss: 79.3801\n",
      "Epoch [25/100], Step[10400]: Train loss: 73.7442, Valid loss: 79.1833\n",
      "Epoch [26/100], Step[10500]: Train loss: 92.8736, Valid loss: 78.3759\n",
      "Saving model with loss 78.376...\n",
      "Epoch [26/100], Step[10600]: Train loss: 74.0487, Valid loss: 78.5626\n",
      "Epoch [26/100], Step[10700]: Train loss: 86.2264, Valid loss: 79.4328\n",
      "Epoch [26/100], Step[10800]: Train loss: 91.0521, Valid loss: 79.0955\n",
      "Epoch [27/100], Step[10900]: Train loss: 92.0822, Valid loss: 78.6666\n",
      "Epoch [27/100], Step[11000]: Train loss: 93.0055, Valid loss: 78.8418\n",
      "Epoch [27/100], Step[11100]: Train loss: 75.3291, Valid loss: 79.9293\n",
      "Epoch [27/100], Step[11200]: Train loss: 68.9305, Valid loss: 78.8257\n",
      "Epoch [28/100], Step[11300]: Train loss: 91.9018, Valid loss: 78.8864\n",
      "Epoch [28/100], Step[11400]: Train loss: 88.0488, Valid loss: 78.2816\n",
      "Saving model with loss 78.282...\n",
      "Epoch [28/100], Step[11500]: Train loss: 88.5143, Valid loss: 79.6324\n",
      "Epoch [28/100], Step[11600]: Train loss: 90.4490, Valid loss: 77.9534\n",
      "Saving model with loss 77.953...\n",
      "Epoch [28/100], Step[11700]: Train loss: 80.5597, Valid loss: 78.8362\n",
      "Epoch [29/100], Step[11800]: Train loss: 91.1572, Valid loss: 78.5834\n",
      "Epoch [29/100], Step[11900]: Train loss: 82.7552, Valid loss: 79.4705\n",
      "Epoch [29/100], Step[12000]: Train loss: 79.6637, Valid loss: 79.0613\n",
      "Epoch [29/100], Step[12100]: Train loss: 82.7545, Valid loss: 79.4535\n",
      "Epoch [30/100], Step[12200]: Train loss: 87.8638, Valid loss: 79.0376\n",
      "Epoch [30/100], Step[12300]: Train loss: 89.7242, Valid loss: 79.3766\n",
      "Epoch [30/100], Step[12400]: Train loss: 95.1267, Valid loss: 79.3886\n",
      "Epoch [30/100], Step[12500]: Train loss: 82.2720, Valid loss: 79.7358\n",
      "Epoch [31/100], Step[12600]: Train loss: 89.0193, Valid loss: 79.7601\n",
      "Epoch [31/100], Step[12700]: Train loss: 93.7453, Valid loss: 78.9988\n",
      "Epoch [31/100], Step[12800]: Train loss: 79.1532, Valid loss: 79.3433\n",
      "Epoch [31/100], Step[12900]: Train loss: 76.5132, Valid loss: 79.3851\n",
      "Epoch [32/100], Step[13000]: Train loss: 73.8947, Valid loss: 79.2268\n",
      "Epoch [32/100], Step[13100]: Train loss: 82.0214, Valid loss: 79.0224\n",
      "Epoch [32/100], Step[13200]: Train loss: 81.1206, Valid loss: 79.6388\n",
      "Epoch [32/100], Step[13300]: Train loss: 89.5409, Valid loss: 78.4362\n",
      "Epoch [33/100], Step[13400]: Train loss: 74.4280, Valid loss: 79.4496\n",
      "Epoch [33/100], Step[13500]: Train loss: 83.5349, Valid loss: 78.9532\n",
      "Epoch [33/100], Step[13600]: Train loss: 74.9855, Valid loss: 79.3420\n",
      "Epoch [33/100], Step[13700]: Train loss: 79.3254, Valid loss: 79.6498\n",
      "Epoch [34/100], Step[13800]: Train loss: 86.2303, Valid loss: 78.9972\n",
      "Epoch [34/100], Step[13900]: Train loss: 90.8684, Valid loss: 78.6957\n",
      "Epoch [34/100], Step[14000]: Train loss: 87.7213, Valid loss: 78.9198\n",
      "Epoch [34/100], Step[14100]: Train loss: 83.8230, Valid loss: 79.4988\n",
      "Epoch [34/100], Step[14200]: Train loss: 84.9317, Valid loss: 78.7102\n",
      "Epoch [35/100], Step[14300]: Train loss: 91.7855, Valid loss: 78.7012\n",
      "Epoch [35/100], Step[14400]: Train loss: 90.7604, Valid loss: 78.3045\n",
      "Epoch [35/100], Step[14500]: Train loss: 87.5271, Valid loss: 79.3369\n",
      "Epoch [35/100], Step[14600]: Train loss: 84.8192, Valid loss: 79.6498\n",
      "Epoch [36/100], Step[14700]: Train loss: 84.3079, Valid loss: 78.4421\n",
      "Epoch [36/100], Step[14800]: Train loss: 91.0410, Valid loss: 80.4756\n",
      "Epoch [36/100], Step[14900]: Train loss: 92.9921, Valid loss: 79.3792\n",
      "Epoch [36/100], Step[15000]: Train loss: 87.0732, Valid loss: 78.9292\n",
      "Epoch [37/100], Step[15100]: Train loss: 91.4976, Valid loss: 78.7616\n",
      "Epoch [37/100], Step[15200]: Train loss: 97.6008, Valid loss: 79.0141\n",
      "Epoch [37/100], Step[15300]: Train loss: 91.2029, Valid loss: 78.6357\n",
      "Epoch [37/100], Step[15400]: Train loss: 93.9833, Valid loss: 79.3515\n",
      "Epoch [38/100], Step[15500]: Train loss: 72.7221, Valid loss: 79.0282\n",
      "Epoch [38/100], Step[15600]: Train loss: 88.7574, Valid loss: 79.1328\n",
      "Epoch [38/100], Step[15700]: Train loss: 93.2294, Valid loss: 79.0879\n",
      "Epoch [38/100], Step[15800]: Train loss: 89.5962, Valid loss: 78.4383\n",
      "Epoch [39/100], Step[15900]: Train loss: 80.1141, Valid loss: 79.5287\n",
      "Epoch [39/100], Step[16000]: Train loss: 81.3003, Valid loss: 79.2229\n",
      "Epoch [39/100], Step[16100]: Train loss: 76.6817, Valid loss: 78.8549\n",
      "Epoch [39/100], Step[16200]: Train loss: 91.1552, Valid loss: 78.5292\n",
      "Epoch [39/100], Step[16300]: Train loss: 74.8475, Valid loss: 78.9554\n",
      "Epoch [40/100], Step[16400]: Train loss: 101.4133, Valid loss: 79.7995\n",
      "Epoch [40/100], Step[16500]: Train loss: 96.2470, Valid loss: 79.2440\n",
      "Epoch [40/100], Step[16600]: Train loss: 78.2521, Valid loss: 79.2050\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "config = {\n",
    "    'H': 90,\n",
    "    'z': 0,\n",
    "    'optimizer': \"Adam\",\n",
    "    'weight_decay': 0,\n",
    "    'n_epochs': 100,     # Number of epochs.            \n",
    "    'learning_rate': 0.001,              \n",
    "    'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model8_0.ckpt'  # Your model will be saved here.\n",
    "}\n",
    "\n",
    "# training\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "step_arr = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "168836c6-d552-48c8-bdff-6939f08a3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "test_RMSE = mean_squared_error(Y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "114fff1c-bf9b-4a5e-9105-280692613c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_RMSE: 8.957025\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "\n",
    "# Change mse to rmse\n",
    "train_loss = np.sqrt(train_loss)\n",
    "valid_loss = np.sqrt(valid_loss)\n",
    "\n",
    "# Draw test, valid RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(step_arr, train_loss ,color = 'r', label=\"Training_RMSE\")\n",
    "plt.plot(step_arr, valid_loss ,color = 'g', label=\"Validation_RMSE\")\n",
    "plt.title(\"Training vs Validation RMSE\")\n",
    "plt.xlabel(\"step (batches)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "# Print test RMSE\n",
    "print(\"Test_RMSE:\", test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34390a54-4c04-43ab-ac80-5ed55d2cf793",
   "metadata": {},
   "source": [
    "This is not better that Q7 compared with the previous models, but we can still see significant decrease of Validation RMSE with the Training RMSE decreases and finally stablizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef016d7d-aad4-41f1-b701-be30fecf2aa6",
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step[100]: Train loss: 97.7717, Valid loss: 90.6140\n",
      "Saving model with loss 90.614...\n",
      "Epoch [1/100], Step[200]: Train loss: 91.2308, Valid loss: 82.2675\n",
      "Saving model with loss 82.267...\n",
      "Epoch [1/100], Step[300]: Train loss: 85.4218, Valid loss: 81.3424\n",
      "Saving model with loss 81.342...\n",
      "Epoch [1/100], Step[400]: Train loss: 77.6237, Valid loss: 80.7211\n",
      "Saving model with loss 80.721...\n",
      "Epoch [2/100], Step[500]: Train loss: 82.8400, Valid loss: 78.6017\n",
      "Saving model with loss 78.602...\n",
      "Epoch [2/100], Step[600]: Train loss: 84.2157, Valid loss: 78.4620\n",
      "Saving model with loss 78.462...\n",
      "Epoch [2/100], Step[700]: Train loss: 86.2093, Valid loss: 78.1903\n",
      "Saving model with loss 78.190...\n",
      "Epoch [2/100], Step[800]: Train loss: 72.7657, Valid loss: 77.3834\n",
      "Saving model with loss 77.383...\n",
      "Epoch [3/100], Step[900]: Train loss: 69.5948, Valid loss: 76.7159\n",
      "Saving model with loss 76.716...\n",
      "Epoch [3/100], Step[1000]: Train loss: 81.1005, Valid loss: 76.9990\n",
      "Epoch [3/100], Step[1100]: Train loss: 87.1903, Valid loss: 77.5065\n",
      "Epoch [3/100], Step[1200]: Train loss: 81.8063, Valid loss: 77.0796\n",
      "Epoch [4/100], Step[1300]: Train loss: 81.5988, Valid loss: 76.7360\n",
      "Epoch [4/100], Step[1400]: Train loss: 77.0150, Valid loss: 76.7348\n",
      "Epoch [4/100], Step[1500]: Train loss: 80.0420, Valid loss: 76.3504\n",
      "Saving model with loss 76.350...\n",
      "Epoch [4/100], Step[1600]: Train loss: 81.1233, Valid loss: 76.4671\n",
      "Epoch [5/100], Step[1700]: Train loss: 71.6180, Valid loss: 76.3496\n",
      "Saving model with loss 76.350...\n",
      "Epoch [5/100], Step[1800]: Train loss: 85.7661, Valid loss: 76.2941\n",
      "Saving model with loss 76.294...\n",
      "Epoch [5/100], Step[1900]: Train loss: 72.3341, Valid loss: 76.2090\n",
      "Saving model with loss 76.209...\n",
      "Epoch [5/100], Step[2000]: Train loss: 84.7312, Valid loss: 76.1011\n",
      "Saving model with loss 76.101...\n",
      "Epoch [6/100], Step[2100]: Train loss: 82.0214, Valid loss: 75.8856\n",
      "Saving model with loss 75.886...\n",
      "Epoch [6/100], Step[2200]: Train loss: 87.2410, Valid loss: 75.6282\n",
      "Saving model with loss 75.628...\n",
      "Epoch [6/100], Step[2300]: Train loss: 78.7887, Valid loss: 75.6964\n",
      "Epoch [6/100], Step[2400]: Train loss: 78.2625, Valid loss: 75.6411\n",
      "Epoch [6/100], Step[2500]: Train loss: 73.6217, Valid loss: 75.6827\n",
      "Epoch [7/100], Step[2600]: Train loss: 87.4836, Valid loss: 76.2532\n",
      "Epoch [7/100], Step[2700]: Train loss: 91.2923, Valid loss: 75.6110\n",
      "Saving model with loss 75.611...\n",
      "Epoch [7/100], Step[2800]: Train loss: 84.5270, Valid loss: 75.2033\n",
      "Saving model with loss 75.203...\n",
      "Epoch [7/100], Step[2900]: Train loss: 82.2882, Valid loss: 75.5789\n",
      "Epoch [8/100], Step[3000]: Train loss: 68.1939, Valid loss: 75.1895\n",
      "Saving model with loss 75.189...\n",
      "Epoch [8/100], Step[3100]: Train loss: 77.8921, Valid loss: 75.6106\n",
      "Epoch [8/100], Step[3200]: Train loss: 76.5286, Valid loss: 75.1239\n",
      "Saving model with loss 75.124...\n",
      "Epoch [8/100], Step[3300]: Train loss: 87.4392, Valid loss: 75.1651\n",
      "Epoch [9/100], Step[3400]: Train loss: 88.3375, Valid loss: 75.3550\n",
      "Epoch [9/100], Step[3500]: Train loss: 89.5798, Valid loss: 74.9385\n",
      "Saving model with loss 74.938...\n",
      "Epoch [9/100], Step[3600]: Train loss: 85.3641, Valid loss: 75.2452\n",
      "Epoch [9/100], Step[3700]: Train loss: 88.4982, Valid loss: 75.2118\n",
      "Epoch [10/100], Step[3800]: Train loss: 80.4846, Valid loss: 75.7355\n",
      "Epoch [10/100], Step[3900]: Train loss: 93.1529, Valid loss: 75.1254\n",
      "Epoch [10/100], Step[4000]: Train loss: 81.3811, Valid loss: 74.8889\n",
      "Saving model with loss 74.889...\n",
      "Epoch [10/100], Step[4100]: Train loss: 81.1929, Valid loss: 74.8633\n",
      "Saving model with loss 74.863...\n",
      "Epoch [11/100], Step[4200]: Train loss: 82.0478, Valid loss: 74.7034\n",
      "Saving model with loss 74.703...\n",
      "Epoch [11/100], Step[4300]: Train loss: 75.1712, Valid loss: 74.8946\n",
      "Epoch [11/100], Step[4400]: Train loss: 77.4832, Valid loss: 74.8050\n",
      "Epoch [11/100], Step[4500]: Train loss: 71.5083, Valid loss: 74.6632\n",
      "Saving model with loss 74.663...\n",
      "Epoch [12/100], Step[4600]: Train loss: 78.8226, Valid loss: 75.2842\n",
      "Epoch [12/100], Step[4700]: Train loss: 82.6362, Valid loss: 74.6841\n",
      "Epoch [12/100], Step[4800]: Train loss: 77.2860, Valid loss: 74.8161\n",
      "Epoch [12/100], Step[4900]: Train loss: 87.9513, Valid loss: 74.6723\n",
      "Epoch [12/100], Step[5000]: Train loss: 81.5786, Valid loss: 75.0305\n",
      "Epoch [13/100], Step[5100]: Train loss: 86.5559, Valid loss: 74.7768\n",
      "Epoch [13/100], Step[5200]: Train loss: 79.9081, Valid loss: 74.5495\n",
      "Saving model with loss 74.550...\n",
      "Epoch [13/100], Step[5300]: Train loss: 73.0646, Valid loss: 75.1281\n",
      "Epoch [13/100], Step[5400]: Train loss: 78.6943, Valid loss: 74.4951\n",
      "Saving model with loss 74.495...\n",
      "Epoch [14/100], Step[5500]: Train loss: 68.9053, Valid loss: 74.6757\n",
      "Epoch [14/100], Step[5600]: Train loss: 80.0504, Valid loss: 75.2217\n",
      "Epoch [14/100], Step[5700]: Train loss: 90.2665, Valid loss: 74.9322\n",
      "Epoch [14/100], Step[5800]: Train loss: 81.1691, Valid loss: 74.6311\n",
      "Epoch [15/100], Step[5900]: Train loss: 84.6829, Valid loss: 74.4955\n",
      "Epoch [15/100], Step[6000]: Train loss: 67.9251, Valid loss: 74.1678\n",
      "Saving model with loss 74.168...\n",
      "Epoch [15/100], Step[6100]: Train loss: 80.7572, Valid loss: 74.4196\n",
      "Epoch [15/100], Step[6200]: Train loss: 79.2252, Valid loss: 74.5601\n",
      "Epoch [16/100], Step[6300]: Train loss: 82.2356, Valid loss: 74.6350\n",
      "Epoch [16/100], Step[6400]: Train loss: 78.1867, Valid loss: 74.7578\n",
      "Epoch [16/100], Step[6500]: Train loss: 71.7476, Valid loss: 74.7230\n",
      "Epoch [16/100], Step[6600]: Train loss: 83.5496, Valid loss: 74.4077\n",
      "Epoch [17/100], Step[6700]: Train loss: 74.2955, Valid loss: 74.5562\n",
      "Epoch [17/100], Step[6800]: Train loss: 84.3639, Valid loss: 74.9405\n",
      "Epoch [17/100], Step[6900]: Train loss: 69.0829, Valid loss: 74.8890\n",
      "Epoch [17/100], Step[7000]: Train loss: 73.5311, Valid loss: 74.3096\n",
      "Epoch [17/100], Step[7100]: Train loss: 84.7168, Valid loss: 74.5182\n",
      "Epoch [18/100], Step[7200]: Train loss: 80.9870, Valid loss: 74.2857\n",
      "Epoch [18/100], Step[7300]: Train loss: 80.1077, Valid loss: 74.4132\n",
      "Epoch [18/100], Step[7400]: Train loss: 74.8125, Valid loss: 74.2322\n",
      "Epoch [18/100], Step[7500]: Train loss: 78.7801, Valid loss: 74.3902\n",
      "Epoch [19/100], Step[7600]: Train loss: 69.8471, Valid loss: 74.5276\n",
      "Epoch [19/100], Step[7700]: Train loss: 88.2741, Valid loss: 74.4242\n",
      "Epoch [19/100], Step[7800]: Train loss: 66.0281, Valid loss: 74.5785\n",
      "Epoch [19/100], Step[7900]: Train loss: 77.3176, Valid loss: 74.3019\n",
      "Epoch [20/100], Step[8000]: Train loss: 79.5321, Valid loss: 74.4214\n",
      "Epoch [20/100], Step[8100]: Train loss: 73.0028, Valid loss: 74.5883\n",
      "Epoch [20/100], Step[8200]: Train loss: 82.0291, Valid loss: 73.9839\n",
      "Saving model with loss 73.984...\n",
      "Epoch [20/100], Step[8300]: Train loss: 76.1739, Valid loss: 74.2800\n",
      "Epoch [21/100], Step[8400]: Train loss: 80.8415, Valid loss: 74.3164\n",
      "Epoch [21/100], Step[8500]: Train loss: 77.9090, Valid loss: 74.7168\n",
      "Epoch [21/100], Step[8600]: Train loss: 79.7027, Valid loss: 74.1440\n",
      "Epoch [21/100], Step[8700]: Train loss: 80.3103, Valid loss: 73.8233\n",
      "Saving model with loss 73.823...\n",
      "Epoch [22/100], Step[8800]: Train loss: 75.0298, Valid loss: 74.3401\n",
      "Epoch [22/100], Step[8900]: Train loss: 79.4958, Valid loss: 74.5523\n",
      "Epoch [22/100], Step[9000]: Train loss: 78.8065, Valid loss: 74.0662\n",
      "Epoch [22/100], Step[9100]: Train loss: 80.2347, Valid loss: 74.1060\n",
      "Epoch [23/100], Step[9200]: Train loss: 75.0286, Valid loss: 74.2534\n",
      "Epoch [23/100], Step[9300]: Train loss: 67.7297, Valid loss: 74.3144\n",
      "Epoch [23/100], Step[9400]: Train loss: 75.5426, Valid loss: 74.3484\n",
      "Epoch [23/100], Step[9500]: Train loss: 87.1881, Valid loss: 74.3440\n",
      "Epoch [23/100], Step[9600]: Train loss: 81.3207, Valid loss: 74.0203\n",
      "Epoch [24/100], Step[9700]: Train loss: 82.3580, Valid loss: 74.5305\n",
      "Epoch [24/100], Step[9800]: Train loss: 93.8154, Valid loss: 74.3091\n",
      "Epoch [24/100], Step[9900]: Train loss: 79.6851, Valid loss: 74.2235\n",
      "Epoch [24/100], Step[10000]: Train loss: 75.5798, Valid loss: 74.0930\n",
      "Epoch [25/100], Step[10100]: Train loss: 77.0376, Valid loss: 74.4295\n",
      "Epoch [25/100], Step[10200]: Train loss: 74.8172, Valid loss: 74.1110\n",
      "Epoch [25/100], Step[10300]: Train loss: 80.5555, Valid loss: 74.2720\n",
      "Epoch [25/100], Step[10400]: Train loss: 85.0974, Valid loss: 74.1567\n",
      "Epoch [26/100], Step[10500]: Train loss: 82.0123, Valid loss: 74.0266\n",
      "Epoch [26/100], Step[10600]: Train loss: 86.1086, Valid loss: 74.1159\n",
      "Epoch [26/100], Step[10700]: Train loss: 80.7598, Valid loss: 74.2075\n",
      "Epoch [26/100], Step[10800]: Train loss: 87.3289, Valid loss: 74.2892\n",
      "Epoch [27/100], Step[10900]: Train loss: 76.5463, Valid loss: 74.7698\n",
      "Epoch [27/100], Step[11000]: Train loss: 81.2909, Valid loss: 74.0281\n",
      "Epoch [27/100], Step[11100]: Train loss: 82.8075, Valid loss: 73.9563\n",
      "Epoch [27/100], Step[11200]: Train loss: 66.2735, Valid loss: 74.6947\n",
      "Epoch [28/100], Step[11300]: Train loss: 69.8181, Valid loss: 74.2311\n",
      "Epoch [28/100], Step[11400]: Train loss: 70.4554, Valid loss: 73.9848\n",
      "Epoch [28/100], Step[11500]: Train loss: 76.3450, Valid loss: 74.0584\n",
      "Epoch [28/100], Step[11600]: Train loss: 89.1894, Valid loss: 74.1752\n",
      "Epoch [28/100], Step[11700]: Train loss: 92.4826, Valid loss: 73.9738\n",
      "Epoch [29/100], Step[11800]: Train loss: 78.4736, Valid loss: 73.9522\n",
      "Epoch [29/100], Step[11900]: Train loss: 76.6613, Valid loss: 73.8250\n",
      "Epoch [29/100], Step[12000]: Train loss: 83.7942, Valid loss: 74.1120\n",
      "Epoch [29/100], Step[12100]: Train loss: 69.7876, Valid loss: 74.0455\n",
      "Epoch [30/100], Step[12200]: Train loss: 80.1807, Valid loss: 74.5940\n",
      "Epoch [30/100], Step[12300]: Train loss: 76.0445, Valid loss: 74.2884\n",
      "Epoch [30/100], Step[12400]: Train loss: 67.4909, Valid loss: 74.1080\n",
      "Epoch [30/100], Step[12500]: Train loss: 77.0457, Valid loss: 74.0384\n",
      "Epoch [31/100], Step[12600]: Train loss: 76.1303, Valid loss: 74.4167\n",
      "Epoch [31/100], Step[12700]: Train loss: 69.2774, Valid loss: 73.9396\n",
      "Epoch [31/100], Step[12800]: Train loss: 82.3102, Valid loss: 74.0618\n",
      "Epoch [31/100], Step[12900]: Train loss: 74.2760, Valid loss: 74.0817\n",
      "Epoch [32/100], Step[13000]: Train loss: 72.4027, Valid loss: 74.1479\n",
      "Epoch [32/100], Step[13100]: Train loss: 79.0614, Valid loss: 74.1607\n",
      "Epoch [32/100], Step[13200]: Train loss: 84.2882, Valid loss: 74.1165\n",
      "Epoch [32/100], Step[13300]: Train loss: 76.8908, Valid loss: 74.2963\n",
      "Epoch [33/100], Step[13400]: Train loss: 78.9976, Valid loss: 74.0013\n",
      "Epoch [33/100], Step[13500]: Train loss: 85.0591, Valid loss: 74.1864\n",
      "Epoch [33/100], Step[13600]: Train loss: 76.8226, Valid loss: 73.7942\n",
      "Saving model with loss 73.794...\n",
      "Epoch [33/100], Step[13700]: Train loss: 74.8504, Valid loss: 74.0782\n",
      "Epoch [34/100], Step[13800]: Train loss: 71.2631, Valid loss: 73.8041\n",
      "Epoch [34/100], Step[13900]: Train loss: 78.0834, Valid loss: 73.9369\n",
      "Epoch [34/100], Step[14000]: Train loss: 76.3277, Valid loss: 74.0076\n",
      "Epoch [34/100], Step[14100]: Train loss: 81.4138, Valid loss: 73.8891\n",
      "Epoch [34/100], Step[14200]: Train loss: 72.9046, Valid loss: 73.6523\n",
      "Saving model with loss 73.652...\n",
      "Epoch [35/100], Step[14300]: Train loss: 69.8846, Valid loss: 73.7175\n",
      "Epoch [35/100], Step[14400]: Train loss: 79.1555, Valid loss: 74.3107\n",
      "Epoch [35/100], Step[14500]: Train loss: 74.0788, Valid loss: 74.1414\n",
      "Epoch [35/100], Step[14600]: Train loss: 77.3735, Valid loss: 73.7303\n",
      "Epoch [36/100], Step[14700]: Train loss: 77.1360, Valid loss: 74.2405\n",
      "Epoch [36/100], Step[14800]: Train loss: 68.1179, Valid loss: 73.9047\n",
      "Epoch [36/100], Step[14900]: Train loss: 83.5391, Valid loss: 74.0549\n",
      "Epoch [36/100], Step[15000]: Train loss: 80.9335, Valid loss: 74.0177\n",
      "Epoch [37/100], Step[15100]: Train loss: 93.9790, Valid loss: 74.2506\n",
      "Epoch [37/100], Step[15200]: Train loss: 77.1932, Valid loss: 74.1848\n",
      "Epoch [37/100], Step[15300]: Train loss: 100.2893, Valid loss: 73.8891\n",
      "Epoch [37/100], Step[15400]: Train loss: 77.8882, Valid loss: 73.8225\n",
      "Epoch [38/100], Step[15500]: Train loss: 75.7924, Valid loss: 73.9023\n",
      "Epoch [38/100], Step[15600]: Train loss: 76.1528, Valid loss: 73.8229\n",
      "Epoch [38/100], Step[15700]: Train loss: 86.9470, Valid loss: 73.8458\n",
      "Epoch [38/100], Step[15800]: Train loss: 74.3687, Valid loss: 74.0086\n",
      "Epoch [39/100], Step[15900]: Train loss: 78.9598, Valid loss: 73.6737\n",
      "Epoch [39/100], Step[16000]: Train loss: 81.1391, Valid loss: 73.8695\n",
      "Epoch [39/100], Step[16100]: Train loss: 81.4992, Valid loss: 73.9147\n",
      "Epoch [39/100], Step[16200]: Train loss: 81.5497, Valid loss: 73.9085\n",
      "Epoch [39/100], Step[16300]: Train loss: 79.0133, Valid loss: 73.8272\n",
      "Epoch [40/100], Step[16400]: Train loss: 67.4091, Valid loss: 73.8631\n",
      "Epoch [40/100], Step[16500]: Train loss: 69.1210, Valid loss: 74.1502\n",
      "Epoch [40/100], Step[16600]: Train loss: 69.7271, Valid loss: 74.0791\n",
      "Epoch [40/100], Step[16700]: Train loss: 82.9207, Valid loss: 74.1008\n",
      "Epoch [41/100], Step[16800]: Train loss: 69.5574, Valid loss: 74.1767\n",
      "Epoch [41/100], Step[16900]: Train loss: 84.1179, Valid loss: 73.7844\n",
      "Epoch [41/100], Step[17000]: Train loss: 77.4681, Valid loss: 74.2268\n",
      "Epoch [41/100], Step[17100]: Train loss: 81.2177, Valid loss: 73.9332\n",
      "Epoch [42/100], Step[17200]: Train loss: 82.1779, Valid loss: 73.8023\n",
      "Epoch [42/100], Step[17300]: Train loss: 75.7505, Valid loss: 73.9635\n",
      "Epoch [42/100], Step[17400]: Train loss: 85.5570, Valid loss: 74.0364\n",
      "Epoch [42/100], Step[17500]: Train loss: 76.0859, Valid loss: 74.0827\n",
      "Epoch [43/100], Step[17600]: Train loss: 73.5744, Valid loss: 74.0022\n",
      "Epoch [43/100], Step[17700]: Train loss: 71.3760, Valid loss: 73.9991\n",
      "Epoch [43/100], Step[17800]: Train loss: 77.2960, Valid loss: 73.7759\n",
      "Epoch [43/100], Step[17900]: Train loss: 72.0055, Valid loss: 73.7293\n",
      "Epoch [44/100], Step[18000]: Train loss: 76.7706, Valid loss: 74.1469\n",
      "Epoch [44/100], Step[18100]: Train loss: 75.5123, Valid loss: 74.1277\n",
      "Epoch [44/100], Step[18200]: Train loss: 69.8251, Valid loss: 73.9011\n",
      "Epoch [44/100], Step[18300]: Train loss: 84.2998, Valid loss: 73.8196\n",
      "Epoch [45/100], Step[18400]: Train loss: 80.9049, Valid loss: 73.6955\n",
      "Epoch [45/100], Step[18500]: Train loss: 82.3036, Valid loss: 73.6754\n",
      "Epoch [45/100], Step[18600]: Train loss: 81.3378, Valid loss: 73.7577\n",
      "Epoch [45/100], Step[18700]: Train loss: 81.7716, Valid loss: 73.6037\n",
      "Saving model with loss 73.604...\n",
      "Epoch [45/100], Step[18800]: Train loss: 81.5582, Valid loss: 73.8696\n",
      "Epoch [46/100], Step[18900]: Train loss: 77.3786, Valid loss: 73.7511\n",
      "Epoch [46/100], Step[19000]: Train loss: 73.0556, Valid loss: 73.7519\n",
      "Epoch [46/100], Step[19100]: Train loss: 75.3358, Valid loss: 73.7569\n",
      "Epoch [46/100], Step[19200]: Train loss: 72.8928, Valid loss: 73.8303\n",
      "Epoch [47/100], Step[19300]: Train loss: 77.7426, Valid loss: 73.9037\n",
      "Epoch [47/100], Step[19400]: Train loss: 85.7167, Valid loss: 73.5118\n",
      "Saving model with loss 73.512...\n",
      "Epoch [47/100], Step[19500]: Train loss: 80.1521, Valid loss: 74.1791\n",
      "Epoch [47/100], Step[19600]: Train loss: 72.3514, Valid loss: 73.5754\n",
      "Epoch [48/100], Step[19700]: Train loss: 71.1310, Valid loss: 73.7251\n",
      "Epoch [48/100], Step[19800]: Train loss: 88.4956, Valid loss: 73.5028\n",
      "Saving model with loss 73.503...\n",
      "Epoch [48/100], Step[19900]: Train loss: 84.5014, Valid loss: 74.1755\n",
      "Epoch [48/100], Step[20000]: Train loss: 71.9525, Valid loss: 73.8796\n",
      "Epoch [49/100], Step[20100]: Train loss: 76.0019, Valid loss: 74.2718\n",
      "Epoch [49/100], Step[20200]: Train loss: 77.7478, Valid loss: 73.4249\n",
      "Saving model with loss 73.425...\n",
      "Epoch [49/100], Step[20300]: Train loss: 76.2762, Valid loss: 73.6764\n",
      "Epoch [49/100], Step[20400]: Train loss: 71.2208, Valid loss: 73.9402\n",
      "Epoch [50/100], Step[20500]: Train loss: 82.5664, Valid loss: 74.0512\n",
      "Epoch [50/100], Step[20600]: Train loss: 74.5534, Valid loss: 73.7383\n",
      "Epoch [50/100], Step[20700]: Train loss: 82.4304, Valid loss: 73.7334\n",
      "Epoch [50/100], Step[20800]: Train loss: 81.0358, Valid loss: 73.6282\n",
      "Epoch [50/100], Step[20900]: Train loss: 68.3647, Valid loss: 73.5184\n",
      "Epoch [51/100], Step[21000]: Train loss: 85.1215, Valid loss: 74.0368\n",
      "Epoch [51/100], Step[21100]: Train loss: 63.7221, Valid loss: 74.1097\n",
      "Epoch [51/100], Step[21200]: Train loss: 73.9607, Valid loss: 73.5189\n",
      "Epoch [51/100], Step[21300]: Train loss: 92.0872, Valid loss: 73.6045\n",
      "Epoch [52/100], Step[21400]: Train loss: 72.4646, Valid loss: 73.4826\n",
      "Epoch [52/100], Step[21500]: Train loss: 74.4960, Valid loss: 73.9729\n",
      "Epoch [52/100], Step[21600]: Train loss: 91.9492, Valid loss: 73.9618\n",
      "Epoch [52/100], Step[21700]: Train loss: 68.3603, Valid loss: 73.6973\n",
      "Epoch [53/100], Step[21800]: Train loss: 78.7905, Valid loss: 73.7926\n",
      "Epoch [53/100], Step[21900]: Train loss: 75.4826, Valid loss: 73.7327\n",
      "Epoch [53/100], Step[22000]: Train loss: 85.2918, Valid loss: 73.5826\n",
      "Epoch [53/100], Step[22100]: Train loss: 75.1395, Valid loss: 73.8937\n",
      "Epoch [54/100], Step[22200]: Train loss: 81.0699, Valid loss: 73.7866\n",
      "Epoch [54/100], Step[22300]: Train loss: 75.2246, Valid loss: 73.8884\n",
      "Epoch [54/100], Step[22400]: Train loss: 75.6451, Valid loss: 73.5550\n",
      "Epoch [54/100], Step[22500]: Train loss: 75.1773, Valid loss: 73.8416\n",
      "Epoch [55/100], Step[22600]: Train loss: 74.9311, Valid loss: 73.7547\n",
      "Epoch [55/100], Step[22700]: Train loss: 73.1036, Valid loss: 73.8805\n",
      "Epoch [55/100], Step[22800]: Train loss: 81.4868, Valid loss: 74.0184\n",
      "Epoch [55/100], Step[22900]: Train loss: 78.6543, Valid loss: 73.8935\n",
      "Epoch [56/100], Step[23000]: Train loss: 81.7504, Valid loss: 73.4434\n",
      "Epoch [56/100], Step[23100]: Train loss: 76.4717, Valid loss: 73.6560\n",
      "Epoch [56/100], Step[23200]: Train loss: 71.0414, Valid loss: 74.0885\n",
      "Epoch [56/100], Step[23300]: Train loss: 71.1177, Valid loss: 73.5470\n",
      "Epoch [56/100], Step[23400]: Train loss: 76.3826, Valid loss: 73.5482\n",
      "Epoch [57/100], Step[23500]: Train loss: 64.3082, Valid loss: 74.0713\n",
      "Epoch [57/100], Step[23600]: Train loss: 82.3212, Valid loss: 73.8878\n",
      "Epoch [57/100], Step[23700]: Train loss: 68.1914, Valid loss: 73.8754\n",
      "Epoch [57/100], Step[23800]: Train loss: 72.6709, Valid loss: 73.8168\n",
      "Epoch [58/100], Step[23900]: Train loss: 76.0649, Valid loss: 73.6501\n",
      "Epoch [58/100], Step[24000]: Train loss: 82.3244, Valid loss: 73.5601\n",
      "Epoch [58/100], Step[24100]: Train loss: 68.9589, Valid loss: 74.1967\n",
      "Epoch [58/100], Step[24200]: Train loss: 68.1155, Valid loss: 73.8970\n",
      "Epoch [59/100], Step[24300]: Train loss: 80.5036, Valid loss: 73.6559\n",
      "Epoch [59/100], Step[24400]: Train loss: 70.9440, Valid loss: 73.4865\n",
      "Epoch [59/100], Step[24500]: Train loss: 81.3164, Valid loss: 73.7920\n",
      "Epoch [59/100], Step[24600]: Train loss: 79.3250, Valid loss: 73.8090\n",
      "Epoch [60/100], Step[24700]: Train loss: 67.7127, Valid loss: 73.5817\n",
      "Epoch [60/100], Step[24800]: Train loss: 67.9041, Valid loss: 73.9598\n",
      "Epoch [60/100], Step[24900]: Train loss: 80.1343, Valid loss: 73.8337\n",
      "Epoch [60/100], Step[25000]: Train loss: 73.4916, Valid loss: 73.7840\n",
      "Epoch [61/100], Step[25100]: Train loss: 75.2435, Valid loss: 73.9356\n",
      "Epoch [61/100], Step[25200]: Train loss: 73.1480, Valid loss: 73.7700\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 84.4962, Valid loss: 90.3594\n",
      "Saving model with loss 90.359...\n",
      "Epoch [1/100], Step[200]: Train loss: 86.1786, Valid loss: 83.4524\n",
      "Saving model with loss 83.452...\n",
      "Epoch [1/100], Step[300]: Train loss: 77.7392, Valid loss: 81.1527\n",
      "Saving model with loss 81.153...\n",
      "Epoch [1/100], Step[400]: Train loss: 76.2237, Valid loss: 79.6295\n",
      "Saving model with loss 79.630...\n",
      "Epoch [2/100], Step[500]: Train loss: 88.8194, Valid loss: 79.4550\n",
      "Saving model with loss 79.455...\n",
      "Epoch [2/100], Step[600]: Train loss: 93.9930, Valid loss: 77.9243\n",
      "Saving model with loss 77.924...\n",
      "Epoch [2/100], Step[700]: Train loss: 85.1379, Valid loss: 78.2575\n",
      "Epoch [2/100], Step[800]: Train loss: 75.1118, Valid loss: 77.9856\n",
      "Epoch [3/100], Step[900]: Train loss: 79.9340, Valid loss: 77.5895\n",
      "Saving model with loss 77.589...\n",
      "Epoch [3/100], Step[1000]: Train loss: 77.0733, Valid loss: 77.2156\n",
      "Saving model with loss 77.216...\n",
      "Epoch [3/100], Step[1100]: Train loss: 101.5132, Valid loss: 77.1942\n",
      "Saving model with loss 77.194...\n",
      "Epoch [3/100], Step[1200]: Train loss: 88.5711, Valid loss: 76.7026\n",
      "Saving model with loss 76.703...\n",
      "Epoch [4/100], Step[1300]: Train loss: 71.4909, Valid loss: 76.5304\n",
      "Saving model with loss 76.530...\n",
      "Epoch [4/100], Step[1400]: Train loss: 92.2307, Valid loss: 76.4765\n",
      "Saving model with loss 76.477...\n",
      "Epoch [4/100], Step[1500]: Train loss: 72.7767, Valid loss: 76.5171\n",
      "Epoch [4/100], Step[1600]: Train loss: 73.7347, Valid loss: 76.6241\n",
      "Epoch [5/100], Step[1700]: Train loss: 91.9935, Valid loss: 76.1482\n",
      "Saving model with loss 76.148...\n",
      "Epoch [5/100], Step[1800]: Train loss: 77.6732, Valid loss: 76.6541\n",
      "Epoch [5/100], Step[1900]: Train loss: 73.2859, Valid loss: 76.0651\n",
      "Saving model with loss 76.065...\n",
      "Epoch [5/100], Step[2000]: Train loss: 98.6900, Valid loss: 76.0761\n",
      "Epoch [6/100], Step[2100]: Train loss: 85.3549, Valid loss: 76.2937\n",
      "Epoch [6/100], Step[2200]: Train loss: 89.1121, Valid loss: 76.1478\n",
      "Epoch [6/100], Step[2300]: Train loss: 82.5755, Valid loss: 76.0666\n",
      "Epoch [6/100], Step[2400]: Train loss: 78.7607, Valid loss: 75.8552\n",
      "Saving model with loss 75.855...\n",
      "Epoch [6/100], Step[2500]: Train loss: 91.4829, Valid loss: 76.1229\n",
      "Epoch [7/100], Step[2600]: Train loss: 74.2040, Valid loss: 75.6423\n",
      "Saving model with loss 75.642...\n",
      "Epoch [7/100], Step[2700]: Train loss: 87.2348, Valid loss: 75.7263\n",
      "Epoch [7/100], Step[2800]: Train loss: 78.3956, Valid loss: 75.5342\n",
      "Saving model with loss 75.534...\n",
      "Epoch [7/100], Step[2900]: Train loss: 82.2663, Valid loss: 75.6198\n",
      "Epoch [8/100], Step[3000]: Train loss: 92.0210, Valid loss: 75.4955\n",
      "Saving model with loss 75.496...\n",
      "Epoch [8/100], Step[3100]: Train loss: 82.8800, Valid loss: 75.0920\n",
      "Saving model with loss 75.092...\n",
      "Epoch [8/100], Step[3200]: Train loss: 68.2058, Valid loss: 75.6613\n",
      "Epoch [8/100], Step[3300]: Train loss: 80.9754, Valid loss: 75.4522\n",
      "Epoch [9/100], Step[3400]: Train loss: 77.7697, Valid loss: 75.0085\n",
      "Saving model with loss 75.009...\n",
      "Epoch [9/100], Step[3500]: Train loss: 78.1566, Valid loss: 74.9422\n",
      "Saving model with loss 74.942...\n",
      "Epoch [9/100], Step[3600]: Train loss: 78.2264, Valid loss: 75.3652\n",
      "Epoch [9/100], Step[3700]: Train loss: 78.5427, Valid loss: 75.0472\n",
      "Epoch [10/100], Step[3800]: Train loss: 76.0935, Valid loss: 74.9947\n",
      "Epoch [10/100], Step[3900]: Train loss: 81.3024, Valid loss: 75.1647\n",
      "Epoch [10/100], Step[4000]: Train loss: 93.2639, Valid loss: 75.0268\n",
      "Epoch [10/100], Step[4100]: Train loss: 88.3240, Valid loss: 74.9584\n",
      "Epoch [11/100], Step[4200]: Train loss: 80.8094, Valid loss: 75.0741\n",
      "Epoch [11/100], Step[4300]: Train loss: 87.4344, Valid loss: 75.4554\n",
      "Epoch [11/100], Step[4400]: Train loss: 81.5359, Valid loss: 75.4171\n",
      "Epoch [11/100], Step[4500]: Train loss: 72.1563, Valid loss: 75.1139\n",
      "Epoch [12/100], Step[4600]: Train loss: 83.1192, Valid loss: 75.0137\n",
      "Epoch [12/100], Step[4700]: Train loss: 85.5340, Valid loss: 74.7252\n",
      "Saving model with loss 74.725...\n",
      "Epoch [12/100], Step[4800]: Train loss: 82.6988, Valid loss: 75.1849\n",
      "Epoch [12/100], Step[4900]: Train loss: 83.3312, Valid loss: 75.1936\n",
      "Epoch [12/100], Step[5000]: Train loss: 80.2249, Valid loss: 74.8653\n",
      "Epoch [13/100], Step[5100]: Train loss: 77.6704, Valid loss: 75.1777\n",
      "Epoch [13/100], Step[5200]: Train loss: 80.1415, Valid loss: 74.5188\n",
      "Saving model with loss 74.519...\n",
      "Epoch [13/100], Step[5300]: Train loss: 83.0237, Valid loss: 75.3950\n",
      "Epoch [13/100], Step[5400]: Train loss: 79.0235, Valid loss: 74.7325\n",
      "Epoch [14/100], Step[5500]: Train loss: 84.6037, Valid loss: 74.6516\n",
      "Epoch [14/100], Step[5600]: Train loss: 86.1422, Valid loss: 74.5445\n",
      "Epoch [14/100], Step[5700]: Train loss: 65.5856, Valid loss: 74.7979\n",
      "Epoch [14/100], Step[5800]: Train loss: 88.9570, Valid loss: 74.7454\n",
      "Epoch [15/100], Step[5900]: Train loss: 74.2078, Valid loss: 74.6184\n",
      "Epoch [15/100], Step[6000]: Train loss: 80.1302, Valid loss: 74.7449\n",
      "Epoch [15/100], Step[6100]: Train loss: 76.1256, Valid loss: 74.6423\n",
      "Epoch [15/100], Step[6200]: Train loss: 87.7184, Valid loss: 74.2117\n",
      "Saving model with loss 74.212...\n",
      "Epoch [16/100], Step[6300]: Train loss: 84.0310, Valid loss: 74.3232\n",
      "Epoch [16/100], Step[6400]: Train loss: 75.9921, Valid loss: 74.6137\n",
      "Epoch [16/100], Step[6500]: Train loss: 91.8311, Valid loss: 74.4682\n",
      "Epoch [16/100], Step[6600]: Train loss: 73.5931, Valid loss: 74.8716\n",
      "Epoch [17/100], Step[6700]: Train loss: 82.2447, Valid loss: 74.2568\n",
      "Epoch [17/100], Step[6800]: Train loss: 78.7092, Valid loss: 74.4441\n",
      "Epoch [17/100], Step[6900]: Train loss: 74.3577, Valid loss: 74.5076\n",
      "Epoch [17/100], Step[7000]: Train loss: 86.5233, Valid loss: 74.6002\n",
      "Epoch [17/100], Step[7100]: Train loss: 77.9085, Valid loss: 74.7257\n",
      "Epoch [18/100], Step[7200]: Train loss: 82.9751, Valid loss: 75.0752\n",
      "Epoch [18/100], Step[7300]: Train loss: 88.1773, Valid loss: 74.4308\n",
      "Epoch [18/100], Step[7400]: Train loss: 68.8438, Valid loss: 74.4519\n",
      "Epoch [18/100], Step[7500]: Train loss: 84.5667, Valid loss: 74.3601\n",
      "Epoch [19/100], Step[7600]: Train loss: 86.2284, Valid loss: 74.5236\n",
      "Epoch [19/100], Step[7700]: Train loss: 85.5886, Valid loss: 74.5078\n",
      "Epoch [19/100], Step[7800]: Train loss: 69.1998, Valid loss: 74.2212\n",
      "Epoch [19/100], Step[7900]: Train loss: 80.8729, Valid loss: 74.1900\n",
      "Saving model with loss 74.190...\n",
      "Epoch [20/100], Step[8000]: Train loss: 73.4484, Valid loss: 74.3969\n",
      "Epoch [20/100], Step[8100]: Train loss: 80.5987, Valid loss: 74.6102\n",
      "Epoch [20/100], Step[8200]: Train loss: 79.8590, Valid loss: 74.3790\n",
      "Epoch [20/100], Step[8300]: Train loss: 74.5656, Valid loss: 74.1581\n",
      "Saving model with loss 74.158...\n",
      "Epoch [21/100], Step[8400]: Train loss: 74.4356, Valid loss: 74.3864\n",
      "Epoch [21/100], Step[8500]: Train loss: 73.9838, Valid loss: 74.5298\n",
      "Epoch [21/100], Step[8600]: Train loss: 74.8088, Valid loss: 74.3007\n",
      "Epoch [21/100], Step[8700]: Train loss: 70.2834, Valid loss: 74.3989\n",
      "Epoch [22/100], Step[8800]: Train loss: 66.8734, Valid loss: 74.6031\n",
      "Epoch [22/100], Step[8900]: Train loss: 87.6581, Valid loss: 74.4478\n",
      "Epoch [22/100], Step[9000]: Train loss: 70.4891, Valid loss: 74.2292\n",
      "Epoch [22/100], Step[9100]: Train loss: 83.8679, Valid loss: 74.2307\n",
      "Epoch [23/100], Step[9200]: Train loss: 76.0861, Valid loss: 74.4398\n",
      "Epoch [23/100], Step[9300]: Train loss: 79.5141, Valid loss: 74.7689\n",
      "Epoch [23/100], Step[9400]: Train loss: 72.9900, Valid loss: 74.2108\n",
      "Epoch [23/100], Step[9500]: Train loss: 92.4837, Valid loss: 74.4111\n",
      "Epoch [23/100], Step[9600]: Train loss: 79.1571, Valid loss: 74.1214\n",
      "Saving model with loss 74.121...\n",
      "Epoch [24/100], Step[9700]: Train loss: 77.6895, Valid loss: 74.4992\n",
      "Epoch [24/100], Step[9800]: Train loss: 81.8313, Valid loss: 74.2312\n",
      "Epoch [24/100], Step[9900]: Train loss: 71.3201, Valid loss: 74.6151\n",
      "Epoch [24/100], Step[10000]: Train loss: 84.4517, Valid loss: 74.3956\n",
      "Epoch [25/100], Step[10100]: Train loss: 75.3013, Valid loss: 74.1427\n",
      "Epoch [25/100], Step[10200]: Train loss: 80.8621, Valid loss: 74.2101\n",
      "Epoch [25/100], Step[10300]: Train loss: 87.2729, Valid loss: 74.0917\n",
      "Saving model with loss 74.092...\n",
      "Epoch [25/100], Step[10400]: Train loss: 87.8829, Valid loss: 73.7954\n",
      "Saving model with loss 73.795...\n",
      "Epoch [26/100], Step[10500]: Train loss: 80.4501, Valid loss: 73.9935\n",
      "Epoch [26/100], Step[10600]: Train loss: 77.4536, Valid loss: 74.5919\n",
      "Epoch [26/100], Step[10700]: Train loss: 71.1246, Valid loss: 74.3201\n",
      "Epoch [26/100], Step[10800]: Train loss: 75.8821, Valid loss: 73.9280\n",
      "Epoch [27/100], Step[10900]: Train loss: 71.3306, Valid loss: 73.9643\n",
      "Epoch [27/100], Step[11000]: Train loss: 79.7170, Valid loss: 74.2797\n",
      "Epoch [27/100], Step[11100]: Train loss: 75.2570, Valid loss: 73.9808\n",
      "Epoch [27/100], Step[11200]: Train loss: 81.4565, Valid loss: 74.2815\n",
      "Epoch [28/100], Step[11300]: Train loss: 81.1242, Valid loss: 74.4008\n",
      "Epoch [28/100], Step[11400]: Train loss: 68.7866, Valid loss: 74.0897\n",
      "Epoch [28/100], Step[11500]: Train loss: 84.4284, Valid loss: 74.0833\n",
      "Epoch [28/100], Step[11600]: Train loss: 76.4576, Valid loss: 74.0617\n",
      "Epoch [28/100], Step[11700]: Train loss: 73.0421, Valid loss: 73.9248\n",
      "Epoch [29/100], Step[11800]: Train loss: 75.6900, Valid loss: 73.8337\n",
      "Epoch [29/100], Step[11900]: Train loss: 73.2530, Valid loss: 73.9330\n",
      "Epoch [29/100], Step[12000]: Train loss: 74.3730, Valid loss: 74.1903\n",
      "Epoch [29/100], Step[12100]: Train loss: 67.8251, Valid loss: 73.9737\n",
      "Epoch [30/100], Step[12200]: Train loss: 75.7305, Valid loss: 73.8721\n",
      "Epoch [30/100], Step[12300]: Train loss: 71.2481, Valid loss: 73.9440\n",
      "Epoch [30/100], Step[12400]: Train loss: 84.1697, Valid loss: 73.6770\n",
      "Saving model with loss 73.677...\n",
      "Epoch [30/100], Step[12500]: Train loss: 78.9962, Valid loss: 74.1306\n",
      "Epoch [31/100], Step[12600]: Train loss: 69.0497, Valid loss: 74.0418\n",
      "Epoch [31/100], Step[12700]: Train loss: 71.9089, Valid loss: 73.8201\n",
      "Epoch [31/100], Step[12800]: Train loss: 81.5478, Valid loss: 74.0743\n",
      "Epoch [31/100], Step[12900]: Train loss: 74.9017, Valid loss: 73.8315\n",
      "Epoch [32/100], Step[13000]: Train loss: 78.2820, Valid loss: 73.8351\n",
      "Epoch [32/100], Step[13100]: Train loss: 70.3916, Valid loss: 73.8515\n",
      "Epoch [32/100], Step[13200]: Train loss: 75.4847, Valid loss: 73.7062\n",
      "Epoch [32/100], Step[13300]: Train loss: 72.7598, Valid loss: 73.8109\n",
      "Epoch [33/100], Step[13400]: Train loss: 76.6777, Valid loss: 74.0287\n",
      "Epoch [33/100], Step[13500]: Train loss: 77.3160, Valid loss: 74.2111\n",
      "Epoch [33/100], Step[13600]: Train loss: 73.3392, Valid loss: 74.1617\n",
      "Epoch [33/100], Step[13700]: Train loss: 87.3730, Valid loss: 73.8963\n",
      "Epoch [34/100], Step[13800]: Train loss: 69.1335, Valid loss: 74.2057\n",
      "Epoch [34/100], Step[13900]: Train loss: 84.4042, Valid loss: 74.3176\n",
      "Epoch [34/100], Step[14000]: Train loss: 85.4919, Valid loss: 73.8956\n",
      "Epoch [34/100], Step[14100]: Train loss: 84.3307, Valid loss: 73.7163\n",
      "Epoch [34/100], Step[14200]: Train loss: 78.2084, Valid loss: 73.9991\n",
      "Epoch [35/100], Step[14300]: Train loss: 81.2872, Valid loss: 73.8693\n",
      "Epoch [35/100], Step[14400]: Train loss: 86.8574, Valid loss: 73.6769\n",
      "Saving model with loss 73.677...\n",
      "Epoch [35/100], Step[14500]: Train loss: 88.5281, Valid loss: 73.8096\n",
      "Epoch [35/100], Step[14600]: Train loss: 80.1283, Valid loss: 73.6269\n",
      "Saving model with loss 73.627...\n",
      "Epoch [36/100], Step[14700]: Train loss: 74.7634, Valid loss: 73.9429\n",
      "Epoch [36/100], Step[14800]: Train loss: 89.4127, Valid loss: 74.0134\n",
      "Epoch [36/100], Step[14900]: Train loss: 81.2080, Valid loss: 74.1185\n",
      "Epoch [36/100], Step[15000]: Train loss: 73.4820, Valid loss: 73.7552\n",
      "Epoch [37/100], Step[15100]: Train loss: 74.6630, Valid loss: 73.6840\n",
      "Epoch [37/100], Step[15200]: Train loss: 86.7248, Valid loss: 73.4200\n",
      "Saving model with loss 73.420...\n",
      "Epoch [37/100], Step[15300]: Train loss: 78.6096, Valid loss: 73.7266\n",
      "Epoch [37/100], Step[15400]: Train loss: 79.4734, Valid loss: 73.4528\n",
      "Epoch [38/100], Step[15500]: Train loss: 86.2452, Valid loss: 73.8158\n",
      "Epoch [38/100], Step[15600]: Train loss: 70.7003, Valid loss: 73.8560\n",
      "Epoch [38/100], Step[15700]: Train loss: 71.7542, Valid loss: 73.8861\n",
      "Epoch [38/100], Step[15800]: Train loss: 71.7139, Valid loss: 74.0083\n",
      "Epoch [39/100], Step[15900]: Train loss: 79.4262, Valid loss: 74.1629\n",
      "Epoch [39/100], Step[16000]: Train loss: 72.2386, Valid loss: 73.6675\n",
      "Epoch [39/100], Step[16100]: Train loss: 83.0053, Valid loss: 74.0194\n",
      "Epoch [39/100], Step[16200]: Train loss: 62.5835, Valid loss: 73.7708\n",
      "Epoch [39/100], Step[16300]: Train loss: 74.9808, Valid loss: 74.0427\n",
      "Epoch [40/100], Step[16400]: Train loss: 71.9263, Valid loss: 73.9624\n",
      "Epoch [40/100], Step[16500]: Train loss: 83.9810, Valid loss: 73.6883\n",
      "Epoch [40/100], Step[16600]: Train loss: 85.5986, Valid loss: 73.7193\n",
      "Epoch [40/100], Step[16700]: Train loss: 79.4863, Valid loss: 73.8985\n",
      "Epoch [41/100], Step[16800]: Train loss: 81.9899, Valid loss: 73.8477\n",
      "Epoch [41/100], Step[16900]: Train loss: 66.4776, Valid loss: 73.9649\n",
      "Epoch [41/100], Step[17000]: Train loss: 82.0517, Valid loss: 74.0631\n",
      "Epoch [41/100], Step[17100]: Train loss: 66.4740, Valid loss: 73.7454\n",
      "Epoch [42/100], Step[17200]: Train loss: 95.1275, Valid loss: 73.6371\n",
      "Epoch [42/100], Step[17300]: Train loss: 74.2150, Valid loss: 74.1739\n",
      "Epoch [42/100], Step[17400]: Train loss: 79.7443, Valid loss: 73.8488\n",
      "Epoch [42/100], Step[17500]: Train loss: 75.5404, Valid loss: 73.7851\n",
      "Epoch [43/100], Step[17600]: Train loss: 76.1536, Valid loss: 73.8182\n",
      "Epoch [43/100], Step[17700]: Train loss: 75.2464, Valid loss: 74.1109\n",
      "Epoch [43/100], Step[17800]: Train loss: 73.3489, Valid loss: 73.9740\n",
      "Epoch [43/100], Step[17900]: Train loss: 72.7199, Valid loss: 73.8960\n",
      "Epoch [44/100], Step[18000]: Train loss: 69.5853, Valid loss: 73.7083\n",
      "Epoch [44/100], Step[18100]: Train loss: 73.6877, Valid loss: 73.4631\n",
      "Epoch [44/100], Step[18200]: Train loss: 84.6971, Valid loss: 73.7279\n",
      "Epoch [44/100], Step[18300]: Train loss: 72.1188, Valid loss: 73.7899\n",
      "Epoch [45/100], Step[18400]: Train loss: 75.7187, Valid loss: 73.5121\n",
      "Epoch [45/100], Step[18500]: Train loss: 89.0437, Valid loss: 74.0664\n",
      "Epoch [45/100], Step[18600]: Train loss: 86.8961, Valid loss: 73.8121\n",
      "Epoch [45/100], Step[18700]: Train loss: 76.8662, Valid loss: 73.9388\n",
      "Epoch [45/100], Step[18800]: Train loss: 76.8768, Valid loss: 73.8107\n",
      "Epoch [46/100], Step[18900]: Train loss: 67.9240, Valid loss: 73.7520\n",
      "Epoch [46/100], Step[19000]: Train loss: 70.3679, Valid loss: 73.9074\n",
      "Epoch [46/100], Step[19100]: Train loss: 74.3406, Valid loss: 73.8300\n",
      "Epoch [46/100], Step[19200]: Train loss: 78.5411, Valid loss: 73.8002\n",
      "Epoch [47/100], Step[19300]: Train loss: 90.1964, Valid loss: 74.0316\n",
      "Epoch [47/100], Step[19400]: Train loss: 78.2035, Valid loss: 73.7951\n",
      "Epoch [47/100], Step[19500]: Train loss: 69.3525, Valid loss: 74.1913\n",
      "Epoch [47/100], Step[19600]: Train loss: 87.5414, Valid loss: 74.0281\n",
      "Epoch [48/100], Step[19700]: Train loss: 77.6476, Valid loss: 73.8127\n",
      "Epoch [48/100], Step[19800]: Train loss: 78.6944, Valid loss: 74.0249\n",
      "Epoch [48/100], Step[19900]: Train loss: 70.1521, Valid loss: 73.8441\n",
      "Epoch [48/100], Step[20000]: Train loss: 88.6967, Valid loss: 73.7920\n",
      "Epoch [49/100], Step[20100]: Train loss: 75.5888, Valid loss: 73.8375\n",
      "Epoch [49/100], Step[20200]: Train loss: 73.2792, Valid loss: 73.7758\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 95.3562, Valid loss: 89.8479\n",
      "Saving model with loss 89.848...\n",
      "Epoch [1/100], Step[200]: Train loss: 81.6933, Valid loss: 82.1584\n",
      "Saving model with loss 82.158...\n",
      "Epoch [1/100], Step[300]: Train loss: 85.2986, Valid loss: 80.6815\n",
      "Saving model with loss 80.682...\n",
      "Epoch [1/100], Step[400]: Train loss: 84.1880, Valid loss: 79.2944\n",
      "Saving model with loss 79.294...\n",
      "Epoch [2/100], Step[500]: Train loss: 87.8409, Valid loss: 78.7804\n",
      "Saving model with loss 78.780...\n",
      "Epoch [2/100], Step[600]: Train loss: 73.7774, Valid loss: 78.7577\n",
      "Saving model with loss 78.758...\n",
      "Epoch [2/100], Step[700]: Train loss: 85.1121, Valid loss: 78.4998\n",
      "Saving model with loss 78.500...\n",
      "Epoch [2/100], Step[800]: Train loss: 79.7140, Valid loss: 77.7243\n",
      "Saving model with loss 77.724...\n",
      "Epoch [3/100], Step[900]: Train loss: 87.0903, Valid loss: 77.2515\n",
      "Saving model with loss 77.251...\n",
      "Epoch [3/100], Step[1000]: Train loss: 80.2520, Valid loss: 77.2407\n",
      "Saving model with loss 77.241...\n",
      "Epoch [3/100], Step[1100]: Train loss: 89.5566, Valid loss: 77.1736\n",
      "Saving model with loss 77.174...\n",
      "Epoch [3/100], Step[1200]: Train loss: 84.2701, Valid loss: 76.9301\n",
      "Saving model with loss 76.930...\n",
      "Epoch [4/100], Step[1300]: Train loss: 73.6308, Valid loss: 77.1883\n",
      "Epoch [4/100], Step[1400]: Train loss: 93.6774, Valid loss: 76.5122\n",
      "Saving model with loss 76.512...\n",
      "Epoch [4/100], Step[1500]: Train loss: 84.3887, Valid loss: 76.2310\n",
      "Saving model with loss 76.231...\n",
      "Epoch [4/100], Step[1600]: Train loss: 93.3384, Valid loss: 76.1231\n",
      "Saving model with loss 76.123...\n",
      "Epoch [5/100], Step[1700]: Train loss: 81.6047, Valid loss: 76.0925\n",
      "Saving model with loss 76.093...\n",
      "Epoch [5/100], Step[1800]: Train loss: 79.6124, Valid loss: 75.9596\n",
      "Saving model with loss 75.960...\n",
      "Epoch [5/100], Step[1900]: Train loss: 86.7317, Valid loss: 76.3046\n",
      "Epoch [5/100], Step[2000]: Train loss: 80.6288, Valid loss: 76.0005\n",
      "Epoch [6/100], Step[2100]: Train loss: 85.0261, Valid loss: 76.0594\n",
      "Epoch [6/100], Step[2200]: Train loss: 78.1524, Valid loss: 75.9619\n",
      "Epoch [6/100], Step[2300]: Train loss: 83.1278, Valid loss: 75.9994\n",
      "Epoch [6/100], Step[2400]: Train loss: 79.4478, Valid loss: 76.0617\n",
      "Epoch [6/100], Step[2500]: Train loss: 77.0408, Valid loss: 75.6851\n",
      "Saving model with loss 75.685...\n",
      "Epoch [7/100], Step[2600]: Train loss: 76.3820, Valid loss: 75.1926\n",
      "Saving model with loss 75.193...\n",
      "Epoch [7/100], Step[2700]: Train loss: 83.3565, Valid loss: 75.8187\n",
      "Epoch [7/100], Step[2800]: Train loss: 86.1046, Valid loss: 75.5137\n",
      "Epoch [7/100], Step[2900]: Train loss: 86.6645, Valid loss: 76.0551\n",
      "Epoch [8/100], Step[3000]: Train loss: 75.0083, Valid loss: 75.1123\n",
      "Saving model with loss 75.112...\n",
      "Epoch [8/100], Step[3100]: Train loss: 76.9663, Valid loss: 75.4218\n",
      "Epoch [8/100], Step[3200]: Train loss: 74.5380, Valid loss: 75.3265\n",
      "Epoch [8/100], Step[3300]: Train loss: 77.1791, Valid loss: 75.3270\n",
      "Epoch [9/100], Step[3400]: Train loss: 79.8849, Valid loss: 75.4178\n",
      "Epoch [9/100], Step[3500]: Train loss: 69.2992, Valid loss: 75.5700\n",
      "Epoch [9/100], Step[3600]: Train loss: 73.0023, Valid loss: 75.3633\n",
      "Epoch [9/100], Step[3700]: Train loss: 89.8110, Valid loss: 75.5523\n",
      "Epoch [10/100], Step[3800]: Train loss: 84.3313, Valid loss: 75.2347\n",
      "Epoch [10/100], Step[3900]: Train loss: 94.1740, Valid loss: 75.1309\n",
      "Epoch [10/100], Step[4000]: Train loss: 79.6050, Valid loss: 74.9446\n",
      "Saving model with loss 74.945...\n",
      "Epoch [10/100], Step[4100]: Train loss: 74.9900, Valid loss: 75.2091\n",
      "Epoch [11/100], Step[4200]: Train loss: 87.0433, Valid loss: 75.0733\n",
      "Epoch [11/100], Step[4300]: Train loss: 72.3188, Valid loss: 75.0461\n",
      "Epoch [11/100], Step[4400]: Train loss: 80.3110, Valid loss: 75.0532\n",
      "Epoch [11/100], Step[4500]: Train loss: 71.5488, Valid loss: 74.7715\n",
      "Saving model with loss 74.771...\n",
      "Epoch [12/100], Step[4600]: Train loss: 80.5418, Valid loss: 75.4377\n",
      "Epoch [12/100], Step[4700]: Train loss: 85.5635, Valid loss: 74.7209\n",
      "Saving model with loss 74.721...\n",
      "Epoch [12/100], Step[4800]: Train loss: 85.5199, Valid loss: 75.0042\n",
      "Epoch [12/100], Step[4900]: Train loss: 80.1672, Valid loss: 74.7759\n",
      "Epoch [12/100], Step[5000]: Train loss: 88.8494, Valid loss: 74.7565\n",
      "Epoch [13/100], Step[5100]: Train loss: 80.1784, Valid loss: 75.0503\n",
      "Epoch [13/100], Step[5200]: Train loss: 83.4714, Valid loss: 74.8068\n",
      "Epoch [13/100], Step[5300]: Train loss: 90.2727, Valid loss: 74.8314\n",
      "Epoch [13/100], Step[5400]: Train loss: 74.5323, Valid loss: 74.8809\n",
      "Epoch [14/100], Step[5500]: Train loss: 79.6658, Valid loss: 74.9435\n",
      "Epoch [14/100], Step[5600]: Train loss: 82.6245, Valid loss: 74.5611\n",
      "Saving model with loss 74.561...\n",
      "Epoch [14/100], Step[5700]: Train loss: 81.9506, Valid loss: 74.4448\n",
      "Saving model with loss 74.445...\n",
      "Epoch [14/100], Step[5800]: Train loss: 69.8432, Valid loss: 74.7573\n",
      "Epoch [15/100], Step[5900]: Train loss: 69.3995, Valid loss: 74.5601\n",
      "Epoch [15/100], Step[6000]: Train loss: 72.8259, Valid loss: 74.4810\n",
      "Epoch [15/100], Step[6100]: Train loss: 82.9635, Valid loss: 74.5843\n",
      "Epoch [15/100], Step[6200]: Train loss: 83.8880, Valid loss: 74.6332\n",
      "Epoch [16/100], Step[6300]: Train loss: 68.4147, Valid loss: 74.5564\n",
      "Epoch [16/100], Step[6400]: Train loss: 72.4478, Valid loss: 74.2287\n",
      "Saving model with loss 74.229...\n",
      "Epoch [16/100], Step[6500]: Train loss: 78.2741, Valid loss: 74.3568\n",
      "Epoch [16/100], Step[6600]: Train loss: 73.4808, Valid loss: 74.3964\n",
      "Epoch [17/100], Step[6700]: Train loss: 77.2319, Valid loss: 74.3193\n",
      "Epoch [17/100], Step[6800]: Train loss: 78.5808, Valid loss: 74.4986\n",
      "Epoch [17/100], Step[6900]: Train loss: 82.4595, Valid loss: 74.1768\n",
      "Saving model with loss 74.177...\n",
      "Epoch [17/100], Step[7000]: Train loss: 77.0112, Valid loss: 74.3626\n",
      "Epoch [17/100], Step[7100]: Train loss: 79.9800, Valid loss: 74.2855\n",
      "Epoch [18/100], Step[7200]: Train loss: 79.6143, Valid loss: 74.1679\n",
      "Saving model with loss 74.168...\n",
      "Epoch [18/100], Step[7300]: Train loss: 75.5501, Valid loss: 74.4129\n",
      "Epoch [18/100], Step[7400]: Train loss: 89.2130, Valid loss: 74.3786\n",
      "Epoch [18/100], Step[7500]: Train loss: 70.0592, Valid loss: 74.5089\n",
      "Epoch [19/100], Step[7600]: Train loss: 84.9721, Valid loss: 74.1746\n",
      "Epoch [19/100], Step[7700]: Train loss: 72.7589, Valid loss: 74.1527\n",
      "Saving model with loss 74.153...\n",
      "Epoch [19/100], Step[7800]: Train loss: 81.9952, Valid loss: 74.2908\n",
      "Epoch [19/100], Step[7900]: Train loss: 70.8044, Valid loss: 74.3896\n",
      "Epoch [20/100], Step[8000]: Train loss: 80.0097, Valid loss: 74.0286\n",
      "Saving model with loss 74.029...\n",
      "Epoch [20/100], Step[8100]: Train loss: 65.3267, Valid loss: 74.3694\n",
      "Epoch [20/100], Step[8200]: Train loss: 83.2150, Valid loss: 74.5292\n",
      "Epoch [20/100], Step[8300]: Train loss: 72.8368, Valid loss: 74.3098\n",
      "Epoch [21/100], Step[8400]: Train loss: 71.1053, Valid loss: 74.5646\n",
      "Epoch [21/100], Step[8500]: Train loss: 100.2588, Valid loss: 74.3971\n",
      "Epoch [21/100], Step[8600]: Train loss: 68.0330, Valid loss: 74.6647\n",
      "Epoch [21/100], Step[8700]: Train loss: 77.6557, Valid loss: 74.4091\n",
      "Epoch [22/100], Step[8800]: Train loss: 76.7666, Valid loss: 74.3620\n",
      "Epoch [22/100], Step[8900]: Train loss: 74.7236, Valid loss: 74.5425\n",
      "Epoch [22/100], Step[9000]: Train loss: 83.3017, Valid loss: 74.6275\n",
      "Epoch [22/100], Step[9100]: Train loss: 77.3153, Valid loss: 74.4803\n",
      "Epoch [23/100], Step[9200]: Train loss: 84.6780, Valid loss: 74.1215\n",
      "Epoch [23/100], Step[9300]: Train loss: 86.1492, Valid loss: 74.2574\n",
      "Epoch [23/100], Step[9400]: Train loss: 72.1076, Valid loss: 74.1619\n",
      "Epoch [23/100], Step[9500]: Train loss: 73.0226, Valid loss: 74.5904\n",
      "Epoch [23/100], Step[9600]: Train loss: 83.6857, Valid loss: 74.0828\n",
      "Epoch [24/100], Step[9700]: Train loss: 85.3284, Valid loss: 74.0719\n",
      "Epoch [24/100], Step[9800]: Train loss: 78.2730, Valid loss: 74.1213\n",
      "Epoch [24/100], Step[9900]: Train loss: 69.9380, Valid loss: 74.2943\n",
      "Epoch [24/100], Step[10000]: Train loss: 74.0840, Valid loss: 74.2875\n",
      "Epoch [25/100], Step[10100]: Train loss: 67.3590, Valid loss: 73.9821\n",
      "Saving model with loss 73.982...\n",
      "Epoch [25/100], Step[10200]: Train loss: 68.0938, Valid loss: 74.2349\n",
      "Epoch [25/100], Step[10300]: Train loss: 81.9551, Valid loss: 73.9911\n",
      "Epoch [25/100], Step[10400]: Train loss: 73.0562, Valid loss: 74.3071\n",
      "Epoch [26/100], Step[10500]: Train loss: 77.6570, Valid loss: 74.2481\n",
      "Epoch [26/100], Step[10600]: Train loss: 76.0090, Valid loss: 74.0455\n",
      "Epoch [26/100], Step[10700]: Train loss: 90.2048, Valid loss: 74.3316\n",
      "Epoch [26/100], Step[10800]: Train loss: 82.3880, Valid loss: 73.9640\n",
      "Saving model with loss 73.964...\n",
      "Epoch [27/100], Step[10900]: Train loss: 81.7858, Valid loss: 74.1919\n",
      "Epoch [27/100], Step[11000]: Train loss: 73.2444, Valid loss: 74.5695\n",
      "Epoch [27/100], Step[11100]: Train loss: 74.8170, Valid loss: 73.9916\n",
      "Epoch [27/100], Step[11200]: Train loss: 87.2508, Valid loss: 74.2098\n",
      "Epoch [28/100], Step[11300]: Train loss: 68.4138, Valid loss: 74.1124\n",
      "Epoch [28/100], Step[11400]: Train loss: 79.4591, Valid loss: 74.2862\n",
      "Epoch [28/100], Step[11500]: Train loss: 79.9117, Valid loss: 74.2288\n",
      "Epoch [28/100], Step[11600]: Train loss: 71.9659, Valid loss: 74.4742\n",
      "Epoch [28/100], Step[11700]: Train loss: 68.6894, Valid loss: 74.6102\n",
      "Epoch [29/100], Step[11800]: Train loss: 74.9218, Valid loss: 74.3463\n",
      "Epoch [29/100], Step[11900]: Train loss: 78.0573, Valid loss: 74.1374\n",
      "Epoch [29/100], Step[12000]: Train loss: 71.1364, Valid loss: 74.4008\n",
      "Epoch [29/100], Step[12100]: Train loss: 71.5433, Valid loss: 74.5457\n",
      "Epoch [30/100], Step[12200]: Train loss: 78.3381, Valid loss: 74.4401\n",
      "Epoch [30/100], Step[12300]: Train loss: 84.2297, Valid loss: 74.2760\n",
      "Epoch [30/100], Step[12400]: Train loss: 98.4762, Valid loss: 73.9984\n",
      "Epoch [30/100], Step[12500]: Train loss: 71.6835, Valid loss: 74.2675\n",
      "Epoch [31/100], Step[12600]: Train loss: 68.1686, Valid loss: 74.2264\n",
      "Epoch [31/100], Step[12700]: Train loss: 74.9708, Valid loss: 74.2603\n",
      "Epoch [31/100], Step[12800]: Train loss: 83.9073, Valid loss: 74.1469\n",
      "Epoch [31/100], Step[12900]: Train loss: 74.4947, Valid loss: 74.2051\n",
      "Epoch [32/100], Step[13000]: Train loss: 79.2855, Valid loss: 74.4070\n",
      "Epoch [32/100], Step[13100]: Train loss: 76.1769, Valid loss: 74.0759\n",
      "Epoch [32/100], Step[13200]: Train loss: 64.1608, Valid loss: 74.2526\n",
      "Epoch [32/100], Step[13300]: Train loss: 73.3547, Valid loss: 74.0107\n",
      "Epoch [33/100], Step[13400]: Train loss: 80.4583, Valid loss: 74.2678\n",
      "Epoch [33/100], Step[13500]: Train loss: 83.4658, Valid loss: 74.2649\n",
      "Epoch [33/100], Step[13600]: Train loss: 86.1247, Valid loss: 74.2358\n",
      "Epoch [33/100], Step[13700]: Train loss: 77.2777, Valid loss: 74.1731\n",
      "Epoch [34/100], Step[13800]: Train loss: 74.1021, Valid loss: 74.0768\n",
      "Epoch [34/100], Step[13900]: Train loss: 73.0814, Valid loss: 74.1564\n",
      "Epoch [34/100], Step[14000]: Train loss: 75.5119, Valid loss: 74.1680\n",
      "Epoch [34/100], Step[14100]: Train loss: 75.5039, Valid loss: 74.1367\n",
      "Epoch [34/100], Step[14200]: Train loss: 84.5144, Valid loss: 74.3269\n",
      "Epoch [35/100], Step[14300]: Train loss: 75.6472, Valid loss: 74.1265\n",
      "Epoch [35/100], Step[14400]: Train loss: 74.0342, Valid loss: 73.8070\n",
      "Saving model with loss 73.807...\n",
      "Epoch [35/100], Step[14500]: Train loss: 74.1102, Valid loss: 74.1031\n",
      "Epoch [35/100], Step[14600]: Train loss: 87.4234, Valid loss: 74.2255\n",
      "Epoch [36/100], Step[14700]: Train loss: 80.2597, Valid loss: 74.0114\n",
      "Epoch [36/100], Step[14800]: Train loss: 77.2828, Valid loss: 74.0148\n",
      "Epoch [36/100], Step[14900]: Train loss: 71.5284, Valid loss: 73.8098\n",
      "Epoch [36/100], Step[15000]: Train loss: 82.3585, Valid loss: 74.3716\n",
      "Epoch [37/100], Step[15100]: Train loss: 84.8118, Valid loss: 74.1015\n",
      "Epoch [37/100], Step[15200]: Train loss: 91.5922, Valid loss: 73.8739\n",
      "Epoch [37/100], Step[15300]: Train loss: 72.7654, Valid loss: 74.2999\n",
      "Epoch [37/100], Step[15400]: Train loss: 69.2782, Valid loss: 74.1909\n",
      "Epoch [38/100], Step[15500]: Train loss: 73.6004, Valid loss: 73.7640\n",
      "Saving model with loss 73.764...\n",
      "Epoch [38/100], Step[15600]: Train loss: 79.4258, Valid loss: 73.8526\n",
      "Epoch [38/100], Step[15700]: Train loss: 80.5794, Valid loss: 74.1713\n",
      "Epoch [38/100], Step[15800]: Train loss: 81.3760, Valid loss: 74.2740\n",
      "Epoch [39/100], Step[15900]: Train loss: 72.7575, Valid loss: 74.2417\n",
      "Epoch [39/100], Step[16000]: Train loss: 77.4983, Valid loss: 74.1393\n",
      "Epoch [39/100], Step[16100]: Train loss: 77.8355, Valid loss: 73.5994\n",
      "Saving model with loss 73.599...\n",
      "Epoch [39/100], Step[16200]: Train loss: 70.4587, Valid loss: 73.9559\n",
      "Epoch [39/100], Step[16300]: Train loss: 77.7786, Valid loss: 73.9433\n",
      "Epoch [40/100], Step[16400]: Train loss: 81.5726, Valid loss: 73.7629\n",
      "Epoch [40/100], Step[16500]: Train loss: 61.9642, Valid loss: 73.9262\n",
      "Epoch [40/100], Step[16600]: Train loss: 85.7978, Valid loss: 74.2016\n",
      "Epoch [40/100], Step[16700]: Train loss: 74.6514, Valid loss: 74.1314\n",
      "Epoch [41/100], Step[16800]: Train loss: 81.0599, Valid loss: 73.7750\n",
      "Epoch [41/100], Step[16900]: Train loss: 72.9582, Valid loss: 74.0525\n",
      "Epoch [41/100], Step[17000]: Train loss: 80.8874, Valid loss: 73.9820\n",
      "Epoch [41/100], Step[17100]: Train loss: 83.9537, Valid loss: 74.1756\n",
      "Epoch [42/100], Step[17200]: Train loss: 81.8740, Valid loss: 73.8587\n",
      "Epoch [42/100], Step[17300]: Train loss: 70.3900, Valid loss: 73.6178\n",
      "Epoch [42/100], Step[17400]: Train loss: 87.7223, Valid loss: 73.6867\n",
      "Epoch [42/100], Step[17500]: Train loss: 81.4637, Valid loss: 73.8036\n",
      "Epoch [43/100], Step[17600]: Train loss: 72.7792, Valid loss: 73.8338\n",
      "Epoch [43/100], Step[17700]: Train loss: 73.4450, Valid loss: 73.6304\n",
      "Epoch [43/100], Step[17800]: Train loss: 79.6601, Valid loss: 73.6926\n",
      "Epoch [43/100], Step[17900]: Train loss: 70.5863, Valid loss: 73.6028\n",
      "Epoch [44/100], Step[18000]: Train loss: 81.9922, Valid loss: 74.0820\n",
      "Epoch [44/100], Step[18100]: Train loss: 66.4219, Valid loss: 73.8268\n",
      "Epoch [44/100], Step[18200]: Train loss: 72.1865, Valid loss: 73.7690\n",
      "Epoch [44/100], Step[18300]: Train loss: 89.9049, Valid loss: 73.8079\n",
      "Epoch [45/100], Step[18400]: Train loss: 82.2993, Valid loss: 73.8519\n",
      "Epoch [45/100], Step[18500]: Train loss: 85.3315, Valid loss: 73.7276\n",
      "Epoch [45/100], Step[18600]: Train loss: 75.1692, Valid loss: 73.8755\n",
      "Epoch [45/100], Step[18700]: Train loss: 82.5015, Valid loss: 73.8250\n",
      "Epoch [45/100], Step[18800]: Train loss: 69.6486, Valid loss: 73.9738\n",
      "Epoch [46/100], Step[18900]: Train loss: 72.7988, Valid loss: 73.6561\n",
      "Epoch [46/100], Step[19000]: Train loss: 78.4734, Valid loss: 73.7396\n",
      "Epoch [46/100], Step[19100]: Train loss: 70.2523, Valid loss: 74.3087\n",
      "Epoch [46/100], Step[19200]: Train loss: 68.2144, Valid loss: 74.2517\n",
      "Epoch [47/100], Step[19300]: Train loss: 78.9736, Valid loss: 74.0677\n",
      "Epoch [47/100], Step[19400]: Train loss: 87.6008, Valid loss: 73.8405\n",
      "Epoch [47/100], Step[19500]: Train loss: 85.7739, Valid loss: 73.7580\n",
      "Epoch [47/100], Step[19600]: Train loss: 71.7165, Valid loss: 73.9542\n",
      "Epoch [48/100], Step[19700]: Train loss: 82.5274, Valid loss: 73.6617\n",
      "Epoch [48/100], Step[19800]: Train loss: 65.7512, Valid loss: 73.8159\n",
      "Epoch [48/100], Step[19900]: Train loss: 73.1426, Valid loss: 74.1420\n",
      "Epoch [48/100], Step[20000]: Train loss: 82.5329, Valid loss: 73.7131\n",
      "Epoch [49/100], Step[20100]: Train loss: 74.1728, Valid loss: 73.8275\n",
      "Epoch [49/100], Step[20200]: Train loss: 74.1052, Valid loss: 73.6606\n",
      "Epoch [49/100], Step[20300]: Train loss: 73.6919, Valid loss: 73.5672\n",
      "Saving model with loss 73.567...\n",
      "Epoch [49/100], Step[20400]: Train loss: 79.5472, Valid loss: 73.6963\n",
      "Epoch [50/100], Step[20500]: Train loss: 68.3661, Valid loss: 73.6057\n",
      "Epoch [50/100], Step[20600]: Train loss: 76.9212, Valid loss: 74.0420\n",
      "Epoch [50/100], Step[20700]: Train loss: 73.2619, Valid loss: 73.7311\n",
      "Epoch [50/100], Step[20800]: Train loss: 83.0090, Valid loss: 73.9354\n",
      "Epoch [50/100], Step[20900]: Train loss: 79.3755, Valid loss: 73.5832\n",
      "Epoch [51/100], Step[21000]: Train loss: 82.4171, Valid loss: 73.7853\n",
      "Epoch [51/100], Step[21100]: Train loss: 87.3928, Valid loss: 73.6080\n",
      "Epoch [51/100], Step[21200]: Train loss: 74.5196, Valid loss: 73.7534\n",
      "Epoch [51/100], Step[21300]: Train loss: 74.2154, Valid loss: 73.5076\n",
      "Saving model with loss 73.508...\n",
      "Epoch [52/100], Step[21400]: Train loss: 79.9037, Valid loss: 73.4278\n",
      "Saving model with loss 73.428...\n",
      "Epoch [52/100], Step[21500]: Train loss: 83.4874, Valid loss: 73.5456\n",
      "Epoch [52/100], Step[21600]: Train loss: 73.4553, Valid loss: 73.8954\n",
      "Epoch [52/100], Step[21700]: Train loss: 85.0825, Valid loss: 73.6562\n",
      "Epoch [53/100], Step[21800]: Train loss: 93.6435, Valid loss: 73.7336\n",
      "Epoch [53/100], Step[21900]: Train loss: 87.4096, Valid loss: 73.5185\n",
      "Epoch [53/100], Step[22000]: Train loss: 72.9289, Valid loss: 73.8389\n",
      "Epoch [53/100], Step[22100]: Train loss: 93.1297, Valid loss: 73.4838\n",
      "Epoch [54/100], Step[22200]: Train loss: 79.3229, Valid loss: 73.6566\n",
      "Epoch [54/100], Step[22300]: Train loss: 78.0658, Valid loss: 73.6910\n",
      "Epoch [54/100], Step[22400]: Train loss: 65.4513, Valid loss: 73.4748\n",
      "Epoch [54/100], Step[22500]: Train loss: 73.6632, Valid loss: 73.3961\n",
      "Saving model with loss 73.396...\n",
      "Epoch [55/100], Step[22600]: Train loss: 81.9165, Valid loss: 73.7182\n",
      "Epoch [55/100], Step[22700]: Train loss: 67.2060, Valid loss: 73.6914\n",
      "Epoch [55/100], Step[22800]: Train loss: 78.0711, Valid loss: 74.0617\n",
      "Epoch [55/100], Step[22900]: Train loss: 77.3443, Valid loss: 73.4576\n",
      "Epoch [56/100], Step[23000]: Train loss: 83.8177, Valid loss: 73.6169\n",
      "Epoch [56/100], Step[23100]: Train loss: 71.1495, Valid loss: 73.6583\n",
      "Epoch [56/100], Step[23200]: Train loss: 67.0518, Valid loss: 73.6100\n",
      "Epoch [56/100], Step[23300]: Train loss: 73.1025, Valid loss: 73.7180\n",
      "Epoch [56/100], Step[23400]: Train loss: 79.3728, Valid loss: 73.6275\n",
      "Epoch [57/100], Step[23500]: Train loss: 71.9532, Valid loss: 73.9626\n",
      "Epoch [57/100], Step[23600]: Train loss: 83.4755, Valid loss: 73.7340\n",
      "Epoch [57/100], Step[23700]: Train loss: 75.8323, Valid loss: 73.7364\n",
      "Epoch [57/100], Step[23800]: Train loss: 79.8169, Valid loss: 73.6781\n",
      "Epoch [58/100], Step[23900]: Train loss: 79.2128, Valid loss: 73.9228\n",
      "Epoch [58/100], Step[24000]: Train loss: 76.7823, Valid loss: 73.7326\n",
      "Epoch [58/100], Step[24100]: Train loss: 77.2168, Valid loss: 73.7841\n",
      "Epoch [58/100], Step[24200]: Train loss: 68.2651, Valid loss: 73.9385\n",
      "Epoch [59/100], Step[24300]: Train loss: 68.0076, Valid loss: 73.4448\n",
      "Epoch [59/100], Step[24400]: Train loss: 80.9879, Valid loss: 73.4169\n",
      "Epoch [59/100], Step[24500]: Train loss: 76.0262, Valid loss: 73.4922\n",
      "Epoch [59/100], Step[24600]: Train loss: 76.1123, Valid loss: 73.6161\n",
      "Epoch [60/100], Step[24700]: Train loss: 78.1738, Valid loss: 73.7531\n",
      "Epoch [60/100], Step[24800]: Train loss: 78.7592, Valid loss: 73.6104\n",
      "Epoch [60/100], Step[24900]: Train loss: 78.6795, Valid loss: 73.6220\n",
      "Epoch [60/100], Step[25000]: Train loss: 79.1243, Valid loss: 73.8686\n",
      "Epoch [61/100], Step[25100]: Train loss: 72.2581, Valid loss: 73.7594\n",
      "Epoch [61/100], Step[25200]: Train loss: 88.2963, Valid loss: 73.9155\n",
      "Epoch [61/100], Step[25300]: Train loss: 76.6060, Valid loss: 73.6030\n",
      "Epoch [61/100], Step[25400]: Train loss: 94.6132, Valid loss: 73.7675\n",
      "Epoch [62/100], Step[25500]: Train loss: 73.8803, Valid loss: 73.3306\n",
      "Saving model with loss 73.331...\n",
      "Epoch [62/100], Step[25600]: Train loss: 73.4782, Valid loss: 73.4980\n",
      "Epoch [62/100], Step[25700]: Train loss: 69.2026, Valid loss: 73.4634\n",
      "Epoch [62/100], Step[25800]: Train loss: 80.8788, Valid loss: 73.7918\n",
      "Epoch [62/100], Step[25900]: Train loss: 75.5187, Valid loss: 73.9023\n",
      "Epoch [63/100], Step[26000]: Train loss: 76.5673, Valid loss: 73.9446\n",
      "Epoch [63/100], Step[26100]: Train loss: 71.2167, Valid loss: 73.6146\n",
      "Epoch [63/100], Step[26200]: Train loss: 71.7092, Valid loss: 73.7002\n",
      "Epoch [63/100], Step[26300]: Train loss: 77.1529, Valid loss: 73.5643\n",
      "Epoch [64/100], Step[26400]: Train loss: 78.1811, Valid loss: 73.4572\n",
      "Epoch [64/100], Step[26500]: Train loss: 82.5569, Valid loss: 73.7612\n",
      "Epoch [64/100], Step[26600]: Train loss: 77.4453, Valid loss: 73.8231\n",
      "Epoch [64/100], Step[26700]: Train loss: 78.9286, Valid loss: 73.7207\n",
      "Epoch [65/100], Step[26800]: Train loss: 75.5305, Valid loss: 73.6327\n",
      "Epoch [65/100], Step[26900]: Train loss: 75.8321, Valid loss: 73.6560\n",
      "Epoch [65/100], Step[27000]: Train loss: 71.3154, Valid loss: 73.4755\n",
      "Epoch [65/100], Step[27100]: Train loss: 88.8315, Valid loss: 73.9503\n",
      "Epoch [66/100], Step[27200]: Train loss: 78.6830, Valid loss: 73.2805\n",
      "Saving model with loss 73.281...\n",
      "Epoch [66/100], Step[27300]: Train loss: 83.1826, Valid loss: 73.8323\n",
      "Epoch [66/100], Step[27400]: Train loss: 69.5276, Valid loss: 73.5529\n",
      "Epoch [66/100], Step[27500]: Train loss: 81.8688, Valid loss: 73.8368\n",
      "Epoch [67/100], Step[27600]: Train loss: 65.8873, Valid loss: 73.7207\n",
      "Epoch [67/100], Step[27700]: Train loss: 80.7792, Valid loss: 73.7590\n",
      "Epoch [67/100], Step[27800]: Train loss: 85.6962, Valid loss: 73.3726\n",
      "Epoch [67/100], Step[27900]: Train loss: 75.9725, Valid loss: 73.5672\n",
      "Epoch [67/100], Step[28000]: Train loss: 81.7851, Valid loss: 73.7842\n",
      "Epoch [68/100], Step[28100]: Train loss: 71.1815, Valid loss: 73.5839\n",
      "Epoch [68/100], Step[28200]: Train loss: 84.5854, Valid loss: 73.6263\n",
      "Epoch [68/100], Step[28300]: Train loss: 73.8884, Valid loss: 73.7580\n",
      "Epoch [68/100], Step[28400]: Train loss: 90.5664, Valid loss: 73.3843\n",
      "Epoch [69/100], Step[28500]: Train loss: 80.5115, Valid loss: 73.7448\n",
      "Epoch [69/100], Step[28600]: Train loss: 70.7128, Valid loss: 73.6980\n",
      "Epoch [69/100], Step[28700]: Train loss: 71.6498, Valid loss: 73.6079\n",
      "Epoch [69/100], Step[28800]: Train loss: 69.1261, Valid loss: 73.8603\n",
      "Epoch [70/100], Step[28900]: Train loss: 85.4327, Valid loss: 73.6399\n",
      "Epoch [70/100], Step[29000]: Train loss: 62.8575, Valid loss: 73.7041\n",
      "Epoch [70/100], Step[29100]: Train loss: 87.4012, Valid loss: 73.4781\n",
      "Epoch [70/100], Step[29200]: Train loss: 73.2350, Valid loss: 73.6448\n",
      "Epoch [71/100], Step[29300]: Train loss: 76.9844, Valid loss: 73.6940\n",
      "Epoch [71/100], Step[29400]: Train loss: 74.8686, Valid loss: 73.6873\n",
      "Epoch [71/100], Step[29500]: Train loss: 87.0631, Valid loss: 73.8371\n",
      "Epoch [71/100], Step[29600]: Train loss: 79.4106, Valid loss: 74.0480\n",
      "Epoch [72/100], Step[29700]: Train loss: 70.5203, Valid loss: 73.6534\n",
      "Epoch [72/100], Step[29800]: Train loss: 80.5983, Valid loss: 73.7476\n",
      "Epoch [72/100], Step[29900]: Train loss: 83.6459, Valid loss: 73.8102\n",
      "Epoch [72/100], Step[30000]: Train loss: 78.9916, Valid loss: 73.7736\n",
      "Epoch [73/100], Step[30100]: Train loss: 64.1473, Valid loss: 73.6635\n",
      "Epoch [73/100], Step[30200]: Train loss: 87.0245, Valid loss: 73.8387\n",
      "Epoch [73/100], Step[30300]: Train loss: 70.9923, Valid loss: 73.8338\n",
      "Epoch [73/100], Step[30400]: Train loss: 78.2254, Valid loss: 73.5427\n",
      "Epoch [73/100], Step[30500]: Train loss: 75.8425, Valid loss: 73.4332\n",
      "Epoch [74/100], Step[30600]: Train loss: 85.3194, Valid loss: 73.8402\n",
      "Epoch [74/100], Step[30700]: Train loss: 82.8717, Valid loss: 73.6572\n",
      "Epoch [74/100], Step[30800]: Train loss: 76.0585, Valid loss: 73.5845\n",
      "Epoch [74/100], Step[30900]: Train loss: 76.0204, Valid loss: 73.5197\n",
      "Epoch [75/100], Step[31000]: Train loss: 80.5923, Valid loss: 73.6055\n",
      "Epoch [75/100], Step[31100]: Train loss: 80.3621, Valid loss: 73.1859\n",
      "Saving model with loss 73.186...\n",
      "Epoch [75/100], Step[31200]: Train loss: 79.7890, Valid loss: 73.4822\n",
      "Epoch [75/100], Step[31300]: Train loss: 79.1277, Valid loss: 73.5266\n",
      "Epoch [76/100], Step[31400]: Train loss: 68.7394, Valid loss: 73.4523\n",
      "Epoch [76/100], Step[31500]: Train loss: 72.7022, Valid loss: 73.6168\n",
      "Epoch [76/100], Step[31600]: Train loss: 75.4723, Valid loss: 73.3561\n",
      "Epoch [76/100], Step[31700]: Train loss: 81.3480, Valid loss: 73.5715\n",
      "Epoch [77/100], Step[31800]: Train loss: 79.9337, Valid loss: 73.6508\n",
      "Epoch [77/100], Step[31900]: Train loss: 84.8378, Valid loss: 73.3360\n",
      "Epoch [77/100], Step[32000]: Train loss: 87.7845, Valid loss: 73.0996\n",
      "Saving model with loss 73.100...\n",
      "Epoch [77/100], Step[32100]: Train loss: 81.0407, Valid loss: 73.4106\n",
      "Epoch [78/100], Step[32200]: Train loss: 74.3788, Valid loss: 73.7651\n",
      "Epoch [78/100], Step[32300]: Train loss: 73.1376, Valid loss: 73.5942\n",
      "Epoch [78/100], Step[32400]: Train loss: 83.4767, Valid loss: 73.5374\n",
      "Epoch [78/100], Step[32500]: Train loss: 70.6540, Valid loss: 73.5151\n",
      "Epoch [78/100], Step[32600]: Train loss: 85.0421, Valid loss: 73.5281\n",
      "Epoch [79/100], Step[32700]: Train loss: 74.7817, Valid loss: 73.5612\n",
      "Epoch [79/100], Step[32800]: Train loss: 79.9961, Valid loss: 73.4937\n",
      "Epoch [79/100], Step[32900]: Train loss: 82.9361, Valid loss: 73.3478\n",
      "Epoch [79/100], Step[33000]: Train loss: 77.6025, Valid loss: 73.5154\n",
      "Epoch [80/100], Step[33100]: Train loss: 69.7919, Valid loss: 73.5619\n",
      "Epoch [80/100], Step[33200]: Train loss: 74.0108, Valid loss: 73.3184\n",
      "Epoch [80/100], Step[33300]: Train loss: 78.6078, Valid loss: 73.2619\n",
      "Epoch [80/100], Step[33400]: Train loss: 73.0764, Valid loss: 73.4653\n",
      "Epoch [81/100], Step[33500]: Train loss: 78.8392, Valid loss: 73.1946\n",
      "Epoch [81/100], Step[33600]: Train loss: 73.1468, Valid loss: 73.4645\n",
      "Epoch [81/100], Step[33700]: Train loss: 78.5219, Valid loss: 73.7423\n",
      "Epoch [81/100], Step[33800]: Train loss: 72.1471, Valid loss: 73.6169\n",
      "Epoch [82/100], Step[33900]: Train loss: 86.8890, Valid loss: 73.5277\n",
      "Epoch [82/100], Step[34000]: Train loss: 77.7165, Valid loss: 73.5859\n",
      "Epoch [82/100], Step[34100]: Train loss: 71.4984, Valid loss: 73.6444\n",
      "Epoch [82/100], Step[34200]: Train loss: 80.2979, Valid loss: 73.5711\n",
      "Epoch [83/100], Step[34300]: Train loss: 78.6493, Valid loss: 73.3814\n",
      "Epoch [83/100], Step[34400]: Train loss: 76.6090, Valid loss: 73.7269\n",
      "Epoch [83/100], Step[34500]: Train loss: 76.6216, Valid loss: 73.5876\n",
      "Epoch [83/100], Step[34600]: Train loss: 87.0553, Valid loss: 73.1851\n",
      "Epoch [84/100], Step[34700]: Train loss: 72.0733, Valid loss: 73.1963\n",
      "Epoch [84/100], Step[34800]: Train loss: 73.8038, Valid loss: 73.7367\n",
      "Epoch [84/100], Step[34900]: Train loss: 79.7982, Valid loss: 73.5653\n",
      "Epoch [84/100], Step[35000]: Train loss: 69.6851, Valid loss: 73.3528\n",
      "Epoch [84/100], Step[35100]: Train loss: 75.4327, Valid loss: 73.3170\n",
      "Epoch [85/100], Step[35200]: Train loss: 82.0792, Valid loss: 73.4266\n",
      "Epoch [85/100], Step[35300]: Train loss: 87.0056, Valid loss: 73.4654\n",
      "Epoch [85/100], Step[35400]: Train loss: 66.2230, Valid loss: 73.7057\n",
      "Epoch [85/100], Step[35500]: Train loss: 79.9918, Valid loss: 73.4786\n",
      "Epoch [86/100], Step[35600]: Train loss: 82.7384, Valid loss: 73.6888\n",
      "Epoch [86/100], Step[35700]: Train loss: 85.2924, Valid loss: 73.8934\n",
      "Epoch [86/100], Step[35800]: Train loss: 79.1087, Valid loss: 73.5266\n",
      "Epoch [86/100], Step[35900]: Train loss: 70.7689, Valid loss: 73.5910\n",
      "Epoch [87/100], Step[36000]: Train loss: 78.4163, Valid loss: 73.4154\n",
      "Epoch [87/100], Step[36100]: Train loss: 87.9475, Valid loss: 73.4514\n",
      "Epoch [87/100], Step[36200]: Train loss: 80.0736, Valid loss: 73.5294\n",
      "Epoch [87/100], Step[36300]: Train loss: 71.8137, Valid loss: 73.6821\n",
      "Epoch [88/100], Step[36400]: Train loss: 71.9369, Valid loss: 73.7356\n",
      "Epoch [88/100], Step[36500]: Train loss: 72.6765, Valid loss: 73.3722\n",
      "Epoch [88/100], Step[36600]: Train loss: 72.9347, Valid loss: 73.2645\n",
      "Epoch [88/100], Step[36700]: Train loss: 79.5419, Valid loss: 73.3714\n",
      "Epoch [89/100], Step[36800]: Train loss: 71.8887, Valid loss: 73.5510\n",
      "Epoch [89/100], Step[36900]: Train loss: 81.0106, Valid loss: 73.3863\n",
      "Epoch [89/100], Step[37000]: Train loss: 84.8564, Valid loss: 73.7251\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "Epoch [1/100], Step[100]: Train loss: 93.1773, Valid loss: 88.9628\n",
      "Saving model with loss 88.963...\n",
      "Epoch [1/100], Step[200]: Train loss: 83.0521, Valid loss: 83.3567\n",
      "Saving model with loss 83.357...\n",
      "Epoch [1/100], Step[300]: Train loss: 85.3677, Valid loss: 80.2324\n",
      "Saving model with loss 80.232...\n",
      "Epoch [1/100], Step[400]: Train loss: 90.1594, Valid loss: 80.1946\n",
      "Saving model with loss 80.195...\n",
      "Epoch [2/100], Step[500]: Train loss: 87.2268, Valid loss: 79.1755\n",
      "Saving model with loss 79.176...\n",
      "Epoch [2/100], Step[600]: Train loss: 90.0538, Valid loss: 77.9605\n",
      "Saving model with loss 77.961...\n",
      "Epoch [2/100], Step[700]: Train loss: 91.5231, Valid loss: 78.2785\n",
      "Epoch [2/100], Step[800]: Train loss: 79.0959, Valid loss: 77.8576\n",
      "Saving model with loss 77.858...\n",
      "Epoch [3/100], Step[900]: Train loss: 82.1497, Valid loss: 77.3006\n",
      "Saving model with loss 77.301...\n",
      "Epoch [3/100], Step[1000]: Train loss: 87.5019, Valid loss: 77.8817\n",
      "Epoch [3/100], Step[1100]: Train loss: 73.9473, Valid loss: 76.6293\n",
      "Saving model with loss 76.629...\n",
      "Epoch [3/100], Step[1200]: Train loss: 85.7333, Valid loss: 77.1180\n",
      "Epoch [4/100], Step[1300]: Train loss: 74.6125, Valid loss: 76.3185\n",
      "Saving model with loss 76.318...\n",
      "Epoch [4/100], Step[1400]: Train loss: 94.7475, Valid loss: 76.5281\n",
      "Epoch [4/100], Step[1500]: Train loss: 95.2580, Valid loss: 76.4882\n",
      "Epoch [4/100], Step[1600]: Train loss: 84.7053, Valid loss: 75.7776\n",
      "Saving model with loss 75.778...\n",
      "Epoch [5/100], Step[1700]: Train loss: 87.5703, Valid loss: 76.1393\n",
      "Epoch [5/100], Step[1800]: Train loss: 85.8549, Valid loss: 75.9311\n",
      "Epoch [5/100], Step[1900]: Train loss: 74.1160, Valid loss: 76.0815\n",
      "Epoch [5/100], Step[2000]: Train loss: 82.5559, Valid loss: 75.8874\n",
      "Epoch [6/100], Step[2100]: Train loss: 79.8705, Valid loss: 76.1426\n",
      "Epoch [6/100], Step[2200]: Train loss: 83.7567, Valid loss: 76.1057\n",
      "Epoch [6/100], Step[2300]: Train loss: 74.3392, Valid loss: 76.0604\n",
      "Epoch [6/100], Step[2400]: Train loss: 74.6224, Valid loss: 76.2695\n",
      "Epoch [6/100], Step[2500]: Train loss: 93.7224, Valid loss: 75.8163\n",
      "Epoch [7/100], Step[2600]: Train loss: 82.7593, Valid loss: 75.4476\n",
      "Saving model with loss 75.448...\n",
      "Epoch [7/100], Step[2700]: Train loss: 83.1117, Valid loss: 75.5678\n",
      "Epoch [7/100], Step[2800]: Train loss: 72.4304, Valid loss: 75.5073\n",
      "Epoch [7/100], Step[2900]: Train loss: 76.4475, Valid loss: 75.6724\n",
      "Epoch [8/100], Step[3000]: Train loss: 82.3769, Valid loss: 75.5225\n",
      "Epoch [8/100], Step[3100]: Train loss: 75.6699, Valid loss: 75.5558\n",
      "Epoch [8/100], Step[3200]: Train loss: 95.6986, Valid loss: 75.4192\n",
      "Saving model with loss 75.419...\n",
      "Epoch [8/100], Step[3300]: Train loss: 82.8678, Valid loss: 75.3910\n",
      "Saving model with loss 75.391...\n",
      "Epoch [9/100], Step[3400]: Train loss: 73.6495, Valid loss: 75.3696\n",
      "Saving model with loss 75.370...\n",
      "Epoch [9/100], Step[3500]: Train loss: 71.4130, Valid loss: 75.5388\n",
      "Epoch [9/100], Step[3600]: Train loss: 77.9921, Valid loss: 75.5498\n",
      "Epoch [9/100], Step[3700]: Train loss: 86.6708, Valid loss: 75.0646\n",
      "Saving model with loss 75.065...\n",
      "Epoch [10/100], Step[3800]: Train loss: 75.5376, Valid loss: 75.7482\n",
      "Epoch [10/100], Step[3900]: Train loss: 82.0320, Valid loss: 75.4271\n",
      "Epoch [10/100], Step[4000]: Train loss: 77.3363, Valid loss: 75.1331\n",
      "Epoch [10/100], Step[4100]: Train loss: 95.0563, Valid loss: 75.2045\n",
      "Epoch [11/100], Step[4200]: Train loss: 77.0413, Valid loss: 74.8343\n",
      "Saving model with loss 74.834...\n",
      "Epoch [11/100], Step[4300]: Train loss: 75.9685, Valid loss: 75.1054\n",
      "Epoch [11/100], Step[4400]: Train loss: 74.7236, Valid loss: 74.8750\n",
      "Epoch [11/100], Step[4500]: Train loss: 71.0044, Valid loss: 74.7300\n",
      "Saving model with loss 74.730...\n",
      "Epoch [12/100], Step[4600]: Train loss: 94.9529, Valid loss: 75.0304\n",
      "Epoch [12/100], Step[4700]: Train loss: 85.6398, Valid loss: 75.0701\n",
      "Epoch [12/100], Step[4800]: Train loss: 82.3048, Valid loss: 74.9339\n",
      "Epoch [12/100], Step[4900]: Train loss: 80.6335, Valid loss: 75.1881\n",
      "Epoch [12/100], Step[5000]: Train loss: 75.4123, Valid loss: 74.9112\n",
      "Epoch [13/100], Step[5100]: Train loss: 93.4891, Valid loss: 74.8306\n",
      "Epoch [13/100], Step[5200]: Train loss: 88.0281, Valid loss: 74.8419\n",
      "Epoch [13/100], Step[5300]: Train loss: 76.6098, Valid loss: 74.8238\n",
      "Epoch [13/100], Step[5400]: Train loss: 81.8190, Valid loss: 74.8332\n",
      "Epoch [14/100], Step[5500]: Train loss: 71.3415, Valid loss: 74.8427\n",
      "Epoch [14/100], Step[5600]: Train loss: 79.5680, Valid loss: 74.5607\n",
      "Saving model with loss 74.561...\n",
      "Epoch [14/100], Step[5700]: Train loss: 76.6962, Valid loss: 74.7481\n",
      "Epoch [14/100], Step[5800]: Train loss: 77.1435, Valid loss: 74.7833\n",
      "Epoch [15/100], Step[5900]: Train loss: 76.5720, Valid loss: 74.4724\n",
      "Saving model with loss 74.472...\n",
      "Epoch [15/100], Step[6000]: Train loss: 81.6405, Valid loss: 74.8535\n",
      "Epoch [15/100], Step[6100]: Train loss: 66.1432, Valid loss: 74.5198\n",
      "Epoch [15/100], Step[6200]: Train loss: 72.1725, Valid loss: 74.5103\n",
      "Epoch [16/100], Step[6300]: Train loss: 90.7887, Valid loss: 74.9182\n",
      "Epoch [16/100], Step[6400]: Train loss: 81.8965, Valid loss: 74.7710\n",
      "Epoch [16/100], Step[6500]: Train loss: 70.9698, Valid loss: 75.1835\n",
      "Epoch [16/100], Step[6600]: Train loss: 89.4757, Valid loss: 74.3723\n",
      "Saving model with loss 74.372...\n",
      "Epoch [17/100], Step[6700]: Train loss: 90.1206, Valid loss: 74.9123\n",
      "Epoch [17/100], Step[6800]: Train loss: 81.4366, Valid loss: 74.3593\n",
      "Saving model with loss 74.359...\n",
      "Epoch [17/100], Step[6900]: Train loss: 81.4398, Valid loss: 74.7877\n",
      "Epoch [17/100], Step[7000]: Train loss: 75.3846, Valid loss: 74.4968\n",
      "Epoch [17/100], Step[7100]: Train loss: 76.7385, Valid loss: 74.7192\n",
      "Epoch [18/100], Step[7200]: Train loss: 86.6804, Valid loss: 74.7629\n",
      "Epoch [18/100], Step[7300]: Train loss: 74.0990, Valid loss: 74.5021\n",
      "Epoch [18/100], Step[7400]: Train loss: 73.4411, Valid loss: 74.6353\n",
      "Epoch [18/100], Step[7500]: Train loss: 87.7753, Valid loss: 74.9488\n",
      "Epoch [19/100], Step[7600]: Train loss: 83.8812, Valid loss: 74.2710\n",
      "Saving model with loss 74.271...\n",
      "Epoch [19/100], Step[7700]: Train loss: 72.3305, Valid loss: 74.6555\n",
      "Epoch [19/100], Step[7800]: Train loss: 89.0856, Valid loss: 74.6430\n",
      "Epoch [19/100], Step[7900]: Train loss: 88.5946, Valid loss: 74.5114\n",
      "Epoch [20/100], Step[8000]: Train loss: 81.7141, Valid loss: 74.5621\n",
      "Epoch [20/100], Step[8100]: Train loss: 74.0813, Valid loss: 74.7978\n",
      "Epoch [20/100], Step[8200]: Train loss: 79.0760, Valid loss: 74.4315\n",
      "Epoch [20/100], Step[8300]: Train loss: 82.3740, Valid loss: 74.7804\n",
      "Epoch [21/100], Step[8400]: Train loss: 77.4759, Valid loss: 74.1428\n",
      "Saving model with loss 74.143...\n",
      "Epoch [21/100], Step[8500]: Train loss: 73.9146, Valid loss: 74.5199\n",
      "Epoch [21/100], Step[8600]: Train loss: 85.6757, Valid loss: 74.2179\n",
      "Epoch [21/100], Step[8700]: Train loss: 73.5812, Valid loss: 74.5924\n",
      "Epoch [22/100], Step[8800]: Train loss: 79.8488, Valid loss: 74.4106\n",
      "Epoch [22/100], Step[8900]: Train loss: 76.8692, Valid loss: 74.4926\n",
      "Epoch [22/100], Step[9000]: Train loss: 74.2701, Valid loss: 74.5137\n",
      "Epoch [22/100], Step[9100]: Train loss: 87.3833, Valid loss: 74.2675\n",
      "Epoch [23/100], Step[9200]: Train loss: 88.4343, Valid loss: 73.8429\n",
      "Saving model with loss 73.843...\n",
      "Epoch [23/100], Step[9300]: Train loss: 81.1395, Valid loss: 74.3186\n",
      "Epoch [23/100], Step[9400]: Train loss: 77.0914, Valid loss: 74.2290\n",
      "Epoch [23/100], Step[9500]: Train loss: 79.6375, Valid loss: 74.2930\n",
      "Epoch [23/100], Step[9600]: Train loss: 90.5606, Valid loss: 74.6098\n",
      "Epoch [24/100], Step[9700]: Train loss: 63.5952, Valid loss: 73.9322\n",
      "Epoch [24/100], Step[9800]: Train loss: 77.5350, Valid loss: 74.2148\n",
      "Epoch [24/100], Step[9900]: Train loss: 65.4331, Valid loss: 74.0497\n",
      "Epoch [24/100], Step[10000]: Train loss: 70.2581, Valid loss: 74.4019\n",
      "Epoch [25/100], Step[10100]: Train loss: 80.3894, Valid loss: 73.9312\n",
      "Epoch [25/100], Step[10200]: Train loss: 73.4241, Valid loss: 74.1638\n",
      "Epoch [25/100], Step[10300]: Train loss: 92.3216, Valid loss: 74.7917\n",
      "Epoch [25/100], Step[10400]: Train loss: 76.1846, Valid loss: 74.6877\n",
      "Epoch [26/100], Step[10500]: Train loss: 82.7158, Valid loss: 74.5357\n",
      "Epoch [26/100], Step[10600]: Train loss: 75.7930, Valid loss: 74.5006\n",
      "Epoch [26/100], Step[10700]: Train loss: 77.3823, Valid loss: 74.5271\n",
      "Epoch [26/100], Step[10800]: Train loss: 74.7730, Valid loss: 74.6016\n",
      "Epoch [27/100], Step[10900]: Train loss: 77.4746, Valid loss: 74.2644\n",
      "Epoch [27/100], Step[11000]: Train loss: 82.7119, Valid loss: 74.2869\n",
      "Epoch [27/100], Step[11100]: Train loss: 80.7373, Valid loss: 74.8974\n",
      "Epoch [27/100], Step[11200]: Train loss: 71.5740, Valid loss: 74.2762\n",
      "Epoch [28/100], Step[11300]: Train loss: 83.0070, Valid loss: 74.1028\n",
      "Epoch [28/100], Step[11400]: Train loss: 71.6918, Valid loss: 74.4255\n",
      "Epoch [28/100], Step[11500]: Train loss: 76.6070, Valid loss: 74.4122\n",
      "Epoch [28/100], Step[11600]: Train loss: 72.7175, Valid loss: 73.9741\n",
      "Epoch [28/100], Step[11700]: Train loss: 71.8942, Valid loss: 74.1209\n",
      "Epoch [29/100], Step[11800]: Train loss: 84.6427, Valid loss: 74.3603\n",
      "Epoch [29/100], Step[11900]: Train loss: 75.7036, Valid loss: 74.1163\n",
      "Epoch [29/100], Step[12000]: Train loss: 75.2146, Valid loss: 73.6936\n",
      "Saving model with loss 73.694...\n",
      "Epoch [29/100], Step[12100]: Train loss: 75.1534, Valid loss: 73.8031\n",
      "Epoch [30/100], Step[12200]: Train loss: 77.4131, Valid loss: 74.0162\n",
      "Epoch [30/100], Step[12300]: Train loss: 74.2465, Valid loss: 74.2256\n",
      "Epoch [30/100], Step[12400]: Train loss: 75.1027, Valid loss: 74.1547\n",
      "Epoch [30/100], Step[12500]: Train loss: 69.5914, Valid loss: 73.9048\n",
      "Epoch [31/100], Step[12600]: Train loss: 73.2342, Valid loss: 74.4210\n",
      "Epoch [31/100], Step[12700]: Train loss: 67.6595, Valid loss: 74.2480\n",
      "Epoch [31/100], Step[12800]: Train loss: 72.3614, Valid loss: 73.9032\n",
      "Epoch [31/100], Step[12900]: Train loss: 82.5115, Valid loss: 74.3616\n",
      "Epoch [32/100], Step[13000]: Train loss: 78.4196, Valid loss: 74.5851\n",
      "Epoch [32/100], Step[13100]: Train loss: 78.2613, Valid loss: 74.3440\n",
      "Epoch [32/100], Step[13200]: Train loss: 80.0988, Valid loss: 74.3457\n",
      "Epoch [32/100], Step[13300]: Train loss: 73.2603, Valid loss: 74.1536\n",
      "Epoch [33/100], Step[13400]: Train loss: 80.1663, Valid loss: 74.0699\n",
      "Epoch [33/100], Step[13500]: Train loss: 83.6137, Valid loss: 74.2118\n",
      "Epoch [33/100], Step[13600]: Train loss: 84.4579, Valid loss: 74.1196\n",
      "Epoch [33/100], Step[13700]: Train loss: 75.1255, Valid loss: 73.7729\n",
      "Epoch [34/100], Step[13800]: Train loss: 78.8782, Valid loss: 74.0628\n",
      "Epoch [34/100], Step[13900]: Train loss: 84.3189, Valid loss: 74.4374\n",
      "Epoch [34/100], Step[14000]: Train loss: 70.3360, Valid loss: 74.0667\n",
      "Epoch [34/100], Step[14100]: Train loss: 75.1831, Valid loss: 73.7123\n",
      "Epoch [34/100], Step[14200]: Train loss: 70.7353, Valid loss: 73.9896\n",
      "Epoch [35/100], Step[14300]: Train loss: 77.7861, Valid loss: 74.1392\n",
      "Epoch [35/100], Step[14400]: Train loss: 77.1735, Valid loss: 73.9846\n",
      "Epoch [35/100], Step[14500]: Train loss: 70.8065, Valid loss: 74.1099\n",
      "Epoch [35/100], Step[14600]: Train loss: 74.6927, Valid loss: 74.1117\n",
      "Epoch [36/100], Step[14700]: Train loss: 81.6716, Valid loss: 74.5647\n",
      "Epoch [36/100], Step[14800]: Train loss: 73.4502, Valid loss: 74.3734\n",
      "Epoch [36/100], Step[14900]: Train loss: 81.7907, Valid loss: 74.0536\n",
      "Epoch [36/100], Step[15000]: Train loss: 79.6887, Valid loss: 73.9629\n",
      "Epoch [37/100], Step[15100]: Train loss: 75.9863, Valid loss: 74.1097\n",
      "Epoch [37/100], Step[15200]: Train loss: 82.6744, Valid loss: 74.2511\n",
      "Epoch [37/100], Step[15300]: Train loss: 65.4515, Valid loss: 74.3448\n",
      "Epoch [37/100], Step[15400]: Train loss: 84.3591, Valid loss: 73.9907\n",
      "Epoch [38/100], Step[15500]: Train loss: 75.0828, Valid loss: 73.9468\n",
      "Epoch [38/100], Step[15600]: Train loss: 69.9455, Valid loss: 74.2263\n",
      "Epoch [38/100], Step[15700]: Train loss: 79.8876, Valid loss: 74.0394\n",
      "Epoch [38/100], Step[15800]: Train loss: 75.3990, Valid loss: 73.7968\n",
      "Epoch [39/100], Step[15900]: Train loss: 68.5179, Valid loss: 73.8101\n",
      "Epoch [39/100], Step[16000]: Train loss: 78.6360, Valid loss: 73.9352\n",
      "Epoch [39/100], Step[16100]: Train loss: 67.5501, Valid loss: 74.0525\n",
      "Epoch [39/100], Step[16200]: Train loss: 82.7478, Valid loss: 73.6892\n",
      "Saving model with loss 73.689...\n",
      "Epoch [39/100], Step[16300]: Train loss: 74.4677, Valid loss: 73.9780\n",
      "Epoch [40/100], Step[16400]: Train loss: 66.8446, Valid loss: 73.8449\n",
      "Epoch [40/100], Step[16500]: Train loss: 78.7338, Valid loss: 73.8541\n",
      "Epoch [40/100], Step[16600]: Train loss: 82.8988, Valid loss: 73.7683\n",
      "Epoch [40/100], Step[16700]: Train loss: 78.4387, Valid loss: 73.9014\n",
      "Epoch [41/100], Step[16800]: Train loss: 74.9118, Valid loss: 73.6143\n",
      "Saving model with loss 73.614...\n",
      "Epoch [41/100], Step[16900]: Train loss: 84.1466, Valid loss: 73.7096\n",
      "Epoch [41/100], Step[17000]: Train loss: 84.2500, Valid loss: 73.7372\n",
      "Epoch [41/100], Step[17100]: Train loss: 82.7104, Valid loss: 73.7615\n",
      "Epoch [42/100], Step[17200]: Train loss: 67.8143, Valid loss: 74.0300\n",
      "Epoch [42/100], Step[17300]: Train loss: 73.2788, Valid loss: 74.0028\n",
      "Epoch [42/100], Step[17400]: Train loss: 80.6028, Valid loss: 74.0549\n",
      "Epoch [42/100], Step[17500]: Train loss: 82.7451, Valid loss: 74.0250\n",
      "Epoch [43/100], Step[17600]: Train loss: 73.2695, Valid loss: 73.8988\n",
      "Epoch [43/100], Step[17700]: Train loss: 70.9529, Valid loss: 73.7661\n",
      "Epoch [43/100], Step[17800]: Train loss: 76.8299, Valid loss: 73.8794\n",
      "Epoch [43/100], Step[17900]: Train loss: 79.0179, Valid loss: 73.7944\n",
      "Epoch [44/100], Step[18000]: Train loss: 78.5287, Valid loss: 74.0974\n",
      "Epoch [44/100], Step[18100]: Train loss: 78.4233, Valid loss: 73.9992\n",
      "Epoch [44/100], Step[18200]: Train loss: 78.6213, Valid loss: 74.0093\n",
      "Epoch [44/100], Step[18300]: Train loss: 87.3943, Valid loss: 74.3734\n",
      "Epoch [45/100], Step[18400]: Train loss: 63.8837, Valid loss: 74.1738\n",
      "Epoch [45/100], Step[18500]: Train loss: 77.2307, Valid loss: 73.6495\n",
      "Epoch [45/100], Step[18600]: Train loss: 72.3274, Valid loss: 73.8286\n",
      "Epoch [45/100], Step[18700]: Train loss: 73.0535, Valid loss: 73.7888\n",
      "Epoch [45/100], Step[18800]: Train loss: 81.7119, Valid loss: 74.2018\n",
      "Epoch [46/100], Step[18900]: Train loss: 81.1162, Valid loss: 73.6681\n",
      "Epoch [46/100], Step[19000]: Train loss: 88.5210, Valid loss: 73.9077\n",
      "Epoch [46/100], Step[19100]: Train loss: 76.9430, Valid loss: 74.0167\n",
      "Epoch [46/100], Step[19200]: Train loss: 80.4897, Valid loss: 73.9481\n",
      "Epoch [47/100], Step[19300]: Train loss: 77.5155, Valid loss: 74.5494\n",
      "Epoch [47/100], Step[19400]: Train loss: 79.9798, Valid loss: 73.7560\n",
      "Epoch [47/100], Step[19500]: Train loss: 76.4445, Valid loss: 74.0155\n",
      "Epoch [47/100], Step[19600]: Train loss: 77.1671, Valid loss: 74.2605\n",
      "Epoch [48/100], Step[19700]: Train loss: 85.3963, Valid loss: 73.7692\n",
      "Epoch [48/100], Step[19800]: Train loss: 73.3192, Valid loss: 74.0655\n",
      "Epoch [48/100], Step[19900]: Train loss: 74.8339, Valid loss: 73.9300\n",
      "Epoch [48/100], Step[20000]: Train loss: 72.1849, Valid loss: 73.6231\n",
      "Epoch [49/100], Step[20100]: Train loss: 84.6623, Valid loss: 73.9394\n",
      "Epoch [49/100], Step[20200]: Train loss: 68.3587, Valid loss: 74.1071\n",
      "Epoch [49/100], Step[20300]: Train loss: 82.5125, Valid loss: 73.8359\n",
      "Epoch [49/100], Step[20400]: Train loss: 76.7746, Valid loss: 73.8071\n",
      "Epoch [50/100], Step[20500]: Train loss: 69.7503, Valid loss: 73.7270\n",
      "Epoch [50/100], Step[20600]: Train loss: 73.0153, Valid loss: 73.5590\n",
      "Saving model with loss 73.559...\n",
      "Epoch [50/100], Step[20700]: Train loss: 70.8683, Valid loss: 74.0221\n",
      "Epoch [50/100], Step[20800]: Train loss: 84.2714, Valid loss: 73.9034\n",
      "Epoch [50/100], Step[20900]: Train loss: 74.1885, Valid loss: 73.6100\n",
      "Epoch [51/100], Step[21000]: Train loss: 74.3211, Valid loss: 73.7857\n",
      "Epoch [51/100], Step[21100]: Train loss: 71.5754, Valid loss: 73.8500\n",
      "Epoch [51/100], Step[21200]: Train loss: 83.3037, Valid loss: 73.9641\n",
      "Epoch [51/100], Step[21300]: Train loss: 74.0332, Valid loss: 73.7031\n",
      "Epoch [52/100], Step[21400]: Train loss: 73.2773, Valid loss: 73.8274\n",
      "Epoch [52/100], Step[21500]: Train loss: 76.4191, Valid loss: 73.9924\n",
      "Epoch [52/100], Step[21600]: Train loss: 86.4971, Valid loss: 73.8302\n",
      "Epoch [52/100], Step[21700]: Train loss: 84.1663, Valid loss: 73.8156\n",
      "Epoch [53/100], Step[21800]: Train loss: 73.7533, Valid loss: 73.7878\n",
      "Epoch [53/100], Step[21900]: Train loss: 67.1937, Valid loss: 73.7663\n",
      "Epoch [53/100], Step[22000]: Train loss: 83.9604, Valid loss: 74.1143\n",
      "Epoch [53/100], Step[22100]: Train loss: 82.4995, Valid loss: 73.7704\n",
      "Epoch [54/100], Step[22200]: Train loss: 83.5568, Valid loss: 73.6933\n",
      "Epoch [54/100], Step[22300]: Train loss: 80.6810, Valid loss: 74.0888\n",
      "Epoch [54/100], Step[22400]: Train loss: 76.7492, Valid loss: 74.0731\n",
      "Epoch [54/100], Step[22500]: Train loss: 81.6337, Valid loss: 73.8578\n",
      "Epoch [55/100], Step[22600]: Train loss: 83.2768, Valid loss: 73.7253\n",
      "Epoch [55/100], Step[22700]: Train loss: 61.8904, Valid loss: 73.7611\n",
      "Epoch [55/100], Step[22800]: Train loss: 75.2020, Valid loss: 73.8449\n",
      "Epoch [55/100], Step[22900]: Train loss: 66.9258, Valid loss: 73.5235\n",
      "Saving model with loss 73.523...\n",
      "Epoch [56/100], Step[23000]: Train loss: 77.7577, Valid loss: 73.5961\n",
      "Epoch [56/100], Step[23100]: Train loss: 67.3467, Valid loss: 73.8822\n",
      "Epoch [56/100], Step[23200]: Train loss: 80.3338, Valid loss: 73.5061\n",
      "Saving model with loss 73.506...\n",
      "Epoch [56/100], Step[23300]: Train loss: 91.0569, Valid loss: 73.8344\n",
      "Epoch [56/100], Step[23400]: Train loss: 73.5042, Valid loss: 73.8252\n",
      "Epoch [57/100], Step[23500]: Train loss: 80.2659, Valid loss: 73.9856\n",
      "Epoch [57/100], Step[23600]: Train loss: 79.2638, Valid loss: 73.6182\n",
      "Epoch [57/100], Step[23700]: Train loss: 82.5842, Valid loss: 73.9856\n",
      "Epoch [57/100], Step[23800]: Train loss: 72.4332, Valid loss: 73.8343\n",
      "Epoch [58/100], Step[23900]: Train loss: 68.0498, Valid loss: 74.0573\n",
      "Epoch [58/100], Step[24000]: Train loss: 78.4069, Valid loss: 73.9465\n",
      "Epoch [58/100], Step[24100]: Train loss: 81.6556, Valid loss: 73.7094\n",
      "Epoch [58/100], Step[24200]: Train loss: 74.1873, Valid loss: 73.8821\n",
      "Epoch [59/100], Step[24300]: Train loss: 72.5504, Valid loss: 73.6425\n",
      "Epoch [59/100], Step[24400]: Train loss: 82.1095, Valid loss: 73.9031\n",
      "Epoch [59/100], Step[24500]: Train loss: 84.3543, Valid loss: 73.7582\n",
      "Epoch [59/100], Step[24600]: Train loss: 83.8371, Valid loss: 73.8268\n",
      "Epoch [60/100], Step[24700]: Train loss: 75.7597, Valid loss: 73.7201\n",
      "Epoch [60/100], Step[24800]: Train loss: 75.8010, Valid loss: 74.0364\n",
      "Epoch [60/100], Step[24900]: Train loss: 80.5521, Valid loss: 73.6774\n",
      "Epoch [60/100], Step[25000]: Train loss: 72.3673, Valid loss: 73.7009\n",
      "Epoch [61/100], Step[25100]: Train loss: 79.8328, Valid loss: 73.7619\n",
      "Epoch [61/100], Step[25200]: Train loss: 80.1889, Valid loss: 73.6968\n",
      "Epoch [61/100], Step[25300]: Train loss: 76.6068, Valid loss: 73.6152\n",
      "Epoch [61/100], Step[25400]: Train loss: 80.5905, Valid loss: 73.6000\n",
      "Epoch [62/100], Step[25500]: Train loss: 70.1562, Valid loss: 73.8194\n",
      "Epoch [62/100], Step[25600]: Train loss: 76.5072, Valid loss: 73.8588\n",
      "Epoch [62/100], Step[25700]: Train loss: 81.3859, Valid loss: 74.3812\n",
      "Epoch [62/100], Step[25800]: Train loss: 79.2049, Valid loss: 73.7799\n",
      "Epoch [62/100], Step[25900]: Train loss: 72.1911, Valid loss: 73.7206\n",
      "Epoch [63/100], Step[26000]: Train loss: 74.7980, Valid loss: 73.8858\n",
      "Epoch [63/100], Step[26100]: Train loss: 75.1058, Valid loss: 73.7973\n",
      "Epoch [63/100], Step[26200]: Train loss: 81.0406, Valid loss: 73.6413\n",
      "Epoch [63/100], Step[26300]: Train loss: 84.7625, Valid loss: 74.0495\n",
      "Epoch [64/100], Step[26400]: Train loss: 74.4440, Valid loss: 73.3187\n",
      "Saving model with loss 73.319...\n",
      "Epoch [64/100], Step[26500]: Train loss: 80.5225, Valid loss: 73.8833\n",
      "Epoch [64/100], Step[26600]: Train loss: 80.2304, Valid loss: 73.5601\n",
      "Epoch [64/100], Step[26700]: Train loss: 77.0350, Valid loss: 73.8297\n",
      "Epoch [65/100], Step[26800]: Train loss: 67.1589, Valid loss: 73.6833\n",
      "Epoch [65/100], Step[26900]: Train loss: 71.9258, Valid loss: 73.4618\n",
      "Epoch [65/100], Step[27000]: Train loss: 70.3770, Valid loss: 73.3809\n",
      "Epoch [65/100], Step[27100]: Train loss: 68.3496, Valid loss: 73.4061\n",
      "Epoch [66/100], Step[27200]: Train loss: 85.8710, Valid loss: 73.4219\n",
      "Epoch [66/100], Step[27300]: Train loss: 68.4755, Valid loss: 73.5354\n",
      "Epoch [66/100], Step[27400]: Train loss: 74.4512, Valid loss: 73.4938\n",
      "Epoch [66/100], Step[27500]: Train loss: 71.6494, Valid loss: 74.0627\n",
      "Epoch [67/100], Step[27600]: Train loss: 80.0391, Valid loss: 73.6143\n",
      "Epoch [67/100], Step[27700]: Train loss: 84.4568, Valid loss: 73.6865\n",
      "Epoch [67/100], Step[27800]: Train loss: 75.4951, Valid loss: 73.8465\n",
      "Epoch [67/100], Step[27900]: Train loss: 75.6392, Valid loss: 73.9674\n",
      "Epoch [67/100], Step[28000]: Train loss: 77.1594, Valid loss: 73.8519\n",
      "Epoch [68/100], Step[28100]: Train loss: 85.0396, Valid loss: 73.7902\n",
      "Epoch [68/100], Step[28200]: Train loss: 69.6469, Valid loss: 73.7941\n",
      "Epoch [68/100], Step[28300]: Train loss: 75.2132, Valid loss: 73.7040\n",
      "Epoch [68/100], Step[28400]: Train loss: 84.7949, Valid loss: 73.7282\n",
      "Epoch [69/100], Step[28500]: Train loss: 72.0597, Valid loss: 73.7667\n",
      "Epoch [69/100], Step[28600]: Train loss: 78.6539, Valid loss: 73.6712\n",
      "Epoch [69/100], Step[28700]: Train loss: 75.5305, Valid loss: 73.9172\n",
      "Epoch [69/100], Step[28800]: Train loss: 77.3487, Valid loss: 73.6353\n",
      "Epoch [70/100], Step[28900]: Train loss: 71.5374, Valid loss: 73.3249\n",
      "Epoch [70/100], Step[29000]: Train loss: 84.7793, Valid loss: 73.3859\n",
      "Epoch [70/100], Step[29100]: Train loss: 84.6701, Valid loss: 73.4252\n",
      "Epoch [70/100], Step[29200]: Train loss: 66.2723, Valid loss: 73.9903\n",
      "Epoch [71/100], Step[29300]: Train loss: 68.4882, Valid loss: 73.5765\n",
      "Epoch [71/100], Step[29400]: Train loss: 78.3161, Valid loss: 73.7299\n",
      "Epoch [71/100], Step[29500]: Train loss: 84.6496, Valid loss: 73.8186\n",
      "Epoch [71/100], Step[29600]: Train loss: 72.2705, Valid loss: 73.6480\n",
      "Epoch [72/100], Step[29700]: Train loss: 80.5281, Valid loss: 73.7736\n",
      "Epoch [72/100], Step[29800]: Train loss: 71.5854, Valid loss: 73.6092\n",
      "Epoch [72/100], Step[29900]: Train loss: 76.7980, Valid loss: 73.4914\n",
      "Epoch [72/100], Step[30000]: Train loss: 77.2405, Valid loss: 73.3211\n",
      "Epoch [73/100], Step[30100]: Train loss: 69.9011, Valid loss: 73.5955\n",
      "Epoch [73/100], Step[30200]: Train loss: 70.8980, Valid loss: 73.6012\n",
      "Epoch [73/100], Step[30300]: Train loss: 81.0225, Valid loss: 73.4193\n",
      "Epoch [73/100], Step[30400]: Train loss: 72.5011, Valid loss: 73.7615\n",
      "Epoch [73/100], Step[30500]: Train loss: 79.6694, Valid loss: 73.2863\n",
      "Saving model with loss 73.286...\n",
      "Epoch [74/100], Step[30600]: Train loss: 67.1331, Valid loss: 73.7060\n",
      "Epoch [74/100], Step[30700]: Train loss: 71.0022, Valid loss: 73.6036\n",
      "Epoch [74/100], Step[30800]: Train loss: 69.9012, Valid loss: 73.7000\n",
      "Epoch [74/100], Step[30900]: Train loss: 76.5190, Valid loss: 73.6804\n",
      "Epoch [75/100], Step[31000]: Train loss: 82.6067, Valid loss: 73.8483\n",
      "Epoch [75/100], Step[31100]: Train loss: 79.3071, Valid loss: 73.4617\n",
      "Epoch [75/100], Step[31200]: Train loss: 85.9737, Valid loss: 73.4696\n",
      "Epoch [75/100], Step[31300]: Train loss: 76.3498, Valid loss: 73.6059\n",
      "Epoch [76/100], Step[31400]: Train loss: 82.5658, Valid loss: 73.6759\n",
      "Epoch [76/100], Step[31500]: Train loss: 79.3928, Valid loss: 73.2992\n",
      "Epoch [76/100], Step[31600]: Train loss: 78.5467, Valid loss: 73.3750\n",
      "Epoch [76/100], Step[31700]: Train loss: 79.9000, Valid loss: 73.7350\n",
      "Epoch [77/100], Step[31800]: Train loss: 80.3475, Valid loss: 73.6159\n",
      "Epoch [77/100], Step[31900]: Train loss: 77.6574, Valid loss: 74.3503\n",
      "Epoch [77/100], Step[32000]: Train loss: 76.4782, Valid loss: 73.5059\n",
      "Epoch [77/100], Step[32100]: Train loss: 74.0421, Valid loss: 73.9265\n",
      "Epoch [78/100], Step[32200]: Train loss: 66.9189, Valid loss: 73.7344\n",
      "Epoch [78/100], Step[32300]: Train loss: 74.5894, Valid loss: 73.4115\n",
      "Epoch [78/100], Step[32400]: Train loss: 77.6236, Valid loss: 73.8679\n",
      "Epoch [78/100], Step[32500]: Train loss: 73.9931, Valid loss: 73.7869\n",
      "Epoch [78/100], Step[32600]: Train loss: 76.5071, Valid loss: 73.7107\n",
      "Epoch [79/100], Step[32700]: Train loss: 76.4793, Valid loss: 73.9584\n",
      "Epoch [79/100], Step[32800]: Train loss: 70.8551, Valid loss: 73.6669\n",
      "Epoch [79/100], Step[32900]: Train loss: 84.5483, Valid loss: 73.5588\n",
      "Epoch [79/100], Step[33000]: Train loss: 89.4804, Valid loss: 73.3441\n",
      "Epoch [80/100], Step[33100]: Train loss: 72.5270, Valid loss: 73.3381\n",
      "Epoch [80/100], Step[33200]: Train loss: 67.9552, Valid loss: 73.6702\n",
      "Epoch [80/100], Step[33300]: Train loss: 87.9546, Valid loss: 73.4969\n",
      "Epoch [80/100], Step[33400]: Train loss: 80.5445, Valid loss: 73.5014\n",
      "Epoch [81/100], Step[33500]: Train loss: 67.7541, Valid loss: 73.6713\n",
      "Epoch [81/100], Step[33600]: Train loss: 83.8923, Valid loss: 74.0061\n",
      "Epoch [81/100], Step[33700]: Train loss: 78.6775, Valid loss: 73.7351\n",
      "Epoch [81/100], Step[33800]: Train loss: 81.1724, Valid loss: 73.4269\n",
      "Epoch [82/100], Step[33900]: Train loss: 73.5792, Valid loss: 73.3820\n",
      "Epoch [82/100], Step[34000]: Train loss: 71.4256, Valid loss: 73.6052\n",
      "Epoch [82/100], Step[34100]: Train loss: 84.0841, Valid loss: 73.4056\n",
      "Epoch [82/100], Step[34200]: Train loss: 76.6360, Valid loss: 74.0735\n",
      "Epoch [83/100], Step[34300]: Train loss: 77.5453, Valid loss: 73.7687\n",
      "Epoch [83/100], Step[34400]: Train loss: 71.7640, Valid loss: 73.9440\n",
      "Epoch [83/100], Step[34500]: Train loss: 68.4538, Valid loss: 73.4077\n",
      "Epoch [83/100], Step[34600]: Train loss: 66.3079, Valid loss: 73.4916\n",
      "Epoch [84/100], Step[34700]: Train loss: 75.9894, Valid loss: 73.9718\n",
      "Epoch [84/100], Step[34800]: Train loss: 83.0316, Valid loss: 73.6962\n",
      "Epoch [84/100], Step[34900]: Train loss: 75.5686, Valid loss: 73.3006\n",
      "Epoch [84/100], Step[35000]: Train loss: 87.8094, Valid loss: 73.7506\n",
      "Epoch [84/100], Step[35100]: Train loss: 80.5307, Valid loss: 73.3558\n",
      "Epoch [85/100], Step[35200]: Train loss: 84.2871, Valid loss: 73.1247\n",
      "Saving model with loss 73.125...\n",
      "Epoch [85/100], Step[35300]: Train loss: 73.7734, Valid loss: 73.4148\n",
      "Epoch [85/100], Step[35400]: Train loss: 80.9393, Valid loss: 73.9624\n",
      "Epoch [85/100], Step[35500]: Train loss: 80.7998, Valid loss: 73.4923\n",
      "Epoch [86/100], Step[35600]: Train loss: 84.0169, Valid loss: 73.7977\n",
      "Epoch [86/100], Step[35700]: Train loss: 87.3241, Valid loss: 73.9156\n",
      "Epoch [86/100], Step[35800]: Train loss: 73.3741, Valid loss: 73.5275\n",
      "Epoch [86/100], Step[35900]: Train loss: 79.2716, Valid loss: 73.2344\n",
      "Epoch [87/100], Step[36000]: Train loss: 65.3795, Valid loss: 73.5564\n",
      "Epoch [87/100], Step[36100]: Train loss: 81.0623, Valid loss: 73.4121\n",
      "Epoch [87/100], Step[36200]: Train loss: 83.1276, Valid loss: 73.4538\n",
      "Epoch [87/100], Step[36300]: Train loss: 75.6796, Valid loss: 73.2570\n",
      "Epoch [88/100], Step[36400]: Train loss: 77.7106, Valid loss: 73.3779\n",
      "Epoch [88/100], Step[36500]: Train loss: 72.3041, Valid loss: 73.6119\n",
      "Epoch [88/100], Step[36600]: Train loss: 79.7313, Valid loss: 73.1971\n",
      "Epoch [88/100], Step[36700]: Train loss: 77.9141, Valid loss: 73.2267\n",
      "Epoch [89/100], Step[36800]: Train loss: 66.8112, Valid loss: 73.6259\n",
      "Epoch [89/100], Step[36900]: Train loss: 74.7865, Valid loss: 73.2659\n",
      "Epoch [89/100], Step[37000]: Train loss: 67.8262, Valid loss: 73.4685\n",
      "Epoch [89/100], Step[37100]: Train loss: 77.8534, Valid loss: 73.3416\n",
      "Epoch [89/100], Step[37200]: Train loss: 70.5669, Valid loss: 73.3810\n",
      "Epoch [90/100], Step[37300]: Train loss: 68.9115, Valid loss: 73.2775\n",
      "Epoch [90/100], Step[37400]: Train loss: 75.0964, Valid loss: 73.3232\n",
      "Epoch [90/100], Step[37500]: Train loss: 73.8151, Valid loss: 73.9865\n",
      "Epoch [90/100], Step[37600]: Train loss: 65.4628, Valid loss: 73.0774\n",
      "Saving model with loss 73.077...\n",
      "Epoch [91/100], Step[37700]: Train loss: 91.2772, Valid loss: 73.5966\n",
      "Epoch [91/100], Step[37800]: Train loss: 88.3338, Valid loss: 73.2525\n",
      "Epoch [91/100], Step[37900]: Train loss: 81.7385, Valid loss: 73.5902\n",
      "Epoch [91/100], Step[38000]: Train loss: 85.3704, Valid loss: 73.6534\n",
      "Epoch [92/100], Step[38100]: Train loss: 76.7122, Valid loss: 73.4499\n",
      "Epoch [92/100], Step[38200]: Train loss: 82.3605, Valid loss: 73.6366\n",
      "Epoch [92/100], Step[38300]: Train loss: 75.9192, Valid loss: 73.5212\n",
      "Epoch [92/100], Step[38400]: Train loss: 67.3313, Valid loss: 73.7950\n",
      "Epoch [93/100], Step[38500]: Train loss: 80.7871, Valid loss: 73.4099\n",
      "Epoch [93/100], Step[38600]: Train loss: 77.4584, Valid loss: 73.3673\n",
      "Epoch [93/100], Step[38700]: Train loss: 79.2568, Valid loss: 73.2756\n",
      "Epoch [93/100], Step[38800]: Train loss: 71.5506, Valid loss: 73.5003\n",
      "Epoch [94/100], Step[38900]: Train loss: 73.8157, Valid loss: 73.6057\n",
      "Epoch [94/100], Step[39000]: Train loss: 70.9571, Valid loss: 73.5283\n",
      "Epoch [94/100], Step[39100]: Train loss: 77.8182, Valid loss: 73.5045\n",
      "Epoch [94/100], Step[39200]: Train loss: 80.5852, Valid loss: 73.4392\n",
      "Epoch [95/100], Step[39300]: Train loss: 80.5674, Valid loss: 73.9173\n",
      "Epoch [95/100], Step[39400]: Train loss: 67.7416, Valid loss: 73.2164\n",
      "Epoch [95/100], Step[39500]: Train loss: 82.2138, Valid loss: 73.4643\n",
      "Epoch [95/100], Step[39600]: Train loss: 84.3144, Valid loss: 73.5048\n",
      "Epoch [95/100], Step[39700]: Train loss: 83.0214, Valid loss: 73.5902\n",
      "Epoch [96/100], Step[39800]: Train loss: 73.2699, Valid loss: 73.3447\n",
      "Epoch [96/100], Step[39900]: Train loss: 76.0911, Valid loss: 73.5278\n",
      "Epoch [96/100], Step[40000]: Train loss: 74.7903, Valid loss: 73.3719\n",
      "Epoch [96/100], Step[40100]: Train loss: 87.8478, Valid loss: 73.7582\n",
      "Epoch [97/100], Step[40200]: Train loss: 81.5214, Valid loss: 73.4701\n",
      "Epoch [97/100], Step[40300]: Train loss: 73.6548, Valid loss: 73.3105\n",
      "Epoch [97/100], Step[40400]: Train loss: 80.0279, Valid loss: 73.2715\n",
      "Epoch [97/100], Step[40500]: Train loss: 72.6088, Valid loss: 73.6098\n",
      "Epoch [98/100], Step[40600]: Train loss: 70.7261, Valid loss: 73.5113\n",
      "Epoch [98/100], Step[40700]: Train loss: 71.4168, Valid loss: 73.4074\n",
      "Epoch [98/100], Step[40800]: Train loss: 74.2637, Valid loss: 73.7865\n",
      "Epoch [98/100], Step[40900]: Train loss: 77.0263, Valid loss: 73.7347\n",
      "Epoch [99/100], Step[41000]: Train loss: 86.1680, Valid loss: 73.6008\n",
      "Epoch [99/100], Step[41100]: Train loss: 73.1934, Valid loss: 73.4893\n",
      "Epoch [99/100], Step[41200]: Train loss: 75.3994, Valid loss: 73.4011\n",
      "Epoch [99/100], Step[41300]: Train loss: 76.0943, Valid loss: 74.0823\n",
      "Epoch [100/100], Step[41400]: Train loss: 71.9237, Valid loss: 73.2386\n",
      "Epoch [100/100], Step[41500]: Train loss: 77.5465, Valid loss: 73.4318\n",
      "Epoch [100/100], Step[41600]: Train loss: 75.1419, Valid loss: 73.6472\n",
      "Epoch [100/100], Step[41700]: Train loss: 80.4466, Valid loss: 73.3384\n",
      "Epoch [100/100], Step[41800]: Train loss: 80.1688, Valid loss: 73.6876\n"
     ]
    }
   ],
   "source": [
    "z_arr = []\n",
    "test_RMSE_arr = []\n",
    "\n",
    "for z in [0.1, 0.5, 0.9, 1]:\n",
    "    # config\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    config = {\n",
    "        'H': 90,\n",
    "        'z': z,\n",
    "        'optimizer': \"Adam\",\n",
    "        'weight_decay': 0,\n",
    "        'n_epochs': 100,     # Number of epochs.            \n",
    "        'learning_rate': 0.001,              \n",
    "        'early_stop': 5000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "        'save_path': './models/model8_' + str(z) +'.ckpt'  # Your model will be saved here.\n",
    "    }\n",
    "\n",
    "    # training\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "    step_arr = []\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    trainer(train_loader, valid_loader, model, config, device)\n",
    "\n",
    "    # testing\n",
    "    model = My_Model(input_dim=X_subtrain.shape[1]).to(device)\n",
    "    model.load_state_dict(torch.load(config['save_path']))\n",
    "    preds = predict(test_loader, model, device)\n",
    "    test_RMSE = mean_squared_error(Y_test, preds, squared=False)\n",
    "    \n",
    "    # append to array\n",
    "    z_arr.append(z)\n",
    "    test_RMSE_arr.append(test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30de3e39-b188-4be7-90fa-d82e267e9951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>8.789698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>8.784971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>8.774449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.773116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     z  test RMSE\n",
       "0  0.1   8.789698\n",
       "1  0.5   8.784971\n",
       "2  0.9   8.774449\n",
       "3  1.0   8.773116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"z\": z_arr,\n",
    "       \"test RMSE\": test_RMSE_arr}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb888e9-f8d1-471d-8680-77365a9a10fb",
   "metadata": {},
   "source": [
    "According to the chart above, bigger z implies to lower test RMSE. Thus, we should pick z = 1 as the best model among all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ca1d1-674a-4a90-b9dc-8f1aeac44bc4",
   "metadata": {},
   "source": [
    "#### Code Reference: https://colab.research.google.com/drive/1FTcG6CE-HILnvFztEFKdauMlPKfQvm5Z#scrollTo=YdttVRkAfu2t (NTUEE MACHINE LEARNING 2022 SPRING https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
